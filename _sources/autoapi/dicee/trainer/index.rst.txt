dicee.trainer
=============

.. py:module:: dicee.trainer


Submodules
----------

.. toctree::
   :maxdepth: 1

   /autoapi/dicee/trainer/dice_trainer/index
   /autoapi/dicee/trainer/torch_trainer/index
   /autoapi/dicee/trainer/torch_trainer_ddp/index


Classes
-------

.. autoapisummary::

   dicee.trainer.DICE_Trainer


Package Contents
----------------

.. py:class:: DICE_Trainer(args, is_continual_training, storage_path, evaluator=None)

   DICE_Trainer implement
    1- Pytorch Lightning trainer (https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html)
    2- Multi-GPU Trainer(https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html)
    3- CPU Trainer

    Parameter
    ---------
    args

    is_continual_training:bool

    storage_path:str

    evaluator:

    Returns
    -------
    report:dict



   .. py:attribute:: report


   .. py:attribute:: args


   .. py:attribute:: trainer
      :value: None



   .. py:attribute:: is_continual_training


   .. py:attribute:: storage_path


   .. py:attribute:: evaluator


   .. py:attribute:: form_of_labelling
      :value: None



   .. py:method:: continual_start()

      (1) Initialize training.
      (2) Load model
      (3) Load trainer
      (3) Fit model

      Parameter
      ---------

      :returns: * *model*
                * **form_of_labelling** (*str*)



   .. py:method:: initialize_trainer(callbacks: List) -> lightning.Trainer

      Initialize Trainer from input arguments



   .. py:method:: initialize_or_load_model()


   .. py:method:: init_dataloader(dataset: torch.utils.data.Dataset) -> torch.utils.data.DataLoader


   .. py:method:: init_dataset() -> torch.utils.data.Dataset


   .. py:method:: start(knowledge_graph: Union[dicee.knowledge_graph.KG, numpy.memmap]) -> Tuple[dicee.models.base_model.BaseKGE, str]

      in DDP setup, we need to load the memory map of already read/index KG.
      Ther



   .. py:method:: k_fold_cross_validation(dataset) -> Tuple[dicee.models.base_model.BaseKGE, str]

      Perform K-fold Cross-Validation

      1. Obtain K train and test splits.
      2. For each split,
          2.1 initialize trainer and model
          2.2. Train model with configuration provided in args.
          2.3. Compute the mean reciprocal rank (MRR) score of the model on the test respective split.
      3. Report the mean and average MRR .

      :param self:
      :param dataset:
      :return: model



