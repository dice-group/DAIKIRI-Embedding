dicee.trainer.torch_trainer_ddp
===============================

.. py:module:: dicee.trainer.torch_trainer_ddp


Classes
-------

.. autoapisummary::

   dicee.trainer.torch_trainer_ddp.AbstractTrainer
   dicee.trainer.torch_trainer_ddp.TorchDDPTrainer
   dicee.trainer.torch_trainer_ddp.NodeTrainer
   dicee.trainer.torch_trainer_ddp.DDPTrainer


Functions
---------

.. autoapisummary::

   dicee.trainer.torch_trainer_ddp.efficient_zero_grad
   dicee.trainer.torch_trainer_ddp.print_peak_memory


Module Contents
---------------

.. py:class:: AbstractTrainer(args, callbacks)

   Abstract class for Trainer class for knowledge graph embedding models


   Parameter
   ---------
   args : str
       ?

   callbacks: list
           ?


   .. py:method:: on_fit_start(*args, **kwargs)

      A function to call callbacks before the training starts.

      Parameter
      ---------
      args

      kwargs


      :rtype: None



   .. py:method:: on_fit_end(*args, **kwargs)

      A function to call callbacks at the ned of the training.

      Parameter
      ---------
      args

      kwargs


      :rtype: None



   .. py:method:: on_train_epoch_end(*args, **kwargs)

      A function to call callbacks at the end of an epoch.

      Parameter
      ---------
      args

      kwargs


      :rtype: None



   .. py:method:: on_train_batch_end(*args, **kwargs)

      A function to call callbacks at the end of each mini-batch during training.

      Parameter
      ---------
      args

      kwargs


      :rtype: None



   .. py:method:: save_checkpoint(full_path: str, model) -> None
      :staticmethod:


      A static function to save a model into disk

      Parameter
      ---------
      full_path : str

      model:


      :rtype: None



.. py:function:: efficient_zero_grad(model)

.. py:function:: print_peak_memory(prefix, device)

.. py:class:: TorchDDPTrainer(args, callbacks)

   Bases: :py:obj:`dicee.abstracts.AbstractTrainer`


    A Trainer based on torch.nn.parallel.DistributedDataParallel

    Arguments
   ----------
   train_set_idx
       Indexed triples for the training.
   entity_idxs
       mapping.
   relation_idxs
       mapping.
   form
       ?
   store
        ?
   label_smoothing_rate
        Using hard targets (0,1) drives weights to infinity.
        An outlier produces enormous gradients.

   :rtype: torch.utils.data.Dataset


   .. py:method:: fit(*args, **kwargs)

      Train model



.. py:class:: NodeTrainer(trainer, model: torch.nn.Module, train_dataset_loader: torch.utils.data.DataLoader, optimizer: torch.optim.Optimizer, callbacks, num_epochs: int)

   .. py:method:: extract_input_outputs(z: list)


   .. py:method:: train()

      Training loop for DDP



.. py:class:: DDPTrainer(model: torch.nn.Module, train_dataset_loader: torch.utils.data.DataLoader, optimizer: torch.optim.Optimizer, gpu_id: int, callbacks, num_epochs)

   .. py:method:: extract_input_outputs(z: list)


   .. py:method:: train()


