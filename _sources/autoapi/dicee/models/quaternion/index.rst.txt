:py:mod:`dicee.models.quaternion`
=================================

.. py:module:: dicee.models.quaternion


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   dicee.models.quaternion.QMult
   dicee.models.quaternion.ConvQ
   dicee.models.quaternion.AConvQ



Functions
~~~~~~~~~

.. autoapisummary::

   dicee.models.quaternion.quaternion_mul_with_unit_norm



.. py:function:: quaternion_mul_with_unit_norm(*, Q_1: Tuple[float, float, float, float], Q_2: Tuple[float, float, float, float]) -> Tuple[float, float, float, float]

   Performs the multiplication of two quaternions with unit norm.

   :param Q_1: The first quaternion represented as a tuple of four real numbers (a_h, b_h, c_h, d_h).
   :type Q_1: Tuple[float, float, float, float]
   :param Q_2: The second quaternion represented as a tuple of four real numbers (a_r, b_r, c_r, d_r).
   :type Q_2: Tuple[float, float, float, float]

   :returns: The result of the quaternion multiplication, represented as a tuple of four real numbers (r_val, i_val, j_val, k_val).
   :rtype: Tuple[float, float, float, float]

   .. rubric:: Notes

   The function assumes that the input quaternions have unit norm. It first normalizes the second quaternion to eliminate the scaling effect, and then performs the Hamilton product of the two quaternions.


.. py:class:: QMult(args: dict)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   QMult extends the base knowledge graph embedding model by integrating quaternion
   algebra. This model leverages the properties of quaternions to represent and process
   the embeddings of entities and relations in a knowledge graph, aiming to capture
   complex interactions and patterns.

   :param args: A dictionary of arguments containing hyperparameters and settings for the model,
                such as embedding dimensions and learning rate.
   :type args: dict

   .. attribute:: name

      The name identifier for the QMult model.

      :type: str

   .. method:: quaternion_normalizer(x: torch.FloatTensor) -> torch.FloatTensor

      Normalizes the length of relation vectors.


   .. method:: score(head_ent_emb: torch.FloatTensor, rel_ent_emb: torch.FloatTensor, tail_ent_emb: torch.FloatTensor) -> torch.FloatTensor

      Computes the score of a triple using quaternion multiplication.


   .. method:: k_vs_all_score(bpe_head_ent_emb: torch.FloatTensor, bpe_rel_ent_emb: torch.FloatTensor, E: torch.FloatTensor) -> torch.FloatTensor

      Computes scores in a K-vs-All setting using quaternion embeddings.


   .. method:: forward_k_vs_all(x: torch.FloatTensor) -> torch.FloatTensor

      Performs a forward pass for K-vs-All scoring, returning scores for all entities.


   .. method:: forward_k_vs_sample(x: torch.FloatTensor, target_entity_idx: int) -> torch.FloatTensor

      Performs a forward pass for K-vs-Sample scoring, returning scores for the specified entities.


   .. method:: quaternion_multiplication_followed_by_inner_product(h: torch.FloatTensor, r: torch.FloatTensor, t: torch.FloatTensor) -> torch.FloatTensor

      Performs quaternion multiplication followed by inner product, returning triple scores.


   .. py:method:: quaternion_multiplication_followed_by_inner_product(h: torch.FloatTensor, r: torch.FloatTensor, t: torch.FloatTensor) -> torch.FloatTensor

      Performs quaternion multiplication followed by inner product.

      :param h: The head representations. Shape: (`*batch_dims`, dim)
      :type h: torch.FloatTensor
      :param r: The relation representations. Shape: (`*batch_dims`, dim)
      :type r: torch.FloatTensor
      :param t: The tail representations. Shape: (`*batch_dims`, dim)
      :type t: torch.FloatTensor

      :returns: Triple scores.
      :rtype: torch.FloatTensor


   .. py:method:: quaternion_normalizer(x: torch.FloatTensor) -> torch.FloatTensor
      :staticmethod:

      TODO: Add mathematical format for sphinx.
      Normalize the length of relation vectors, if the forward constraint has not been applied yet.

      The absolute value of a quaternion is calculated as follows:
      .. math::

          |a + bi + cj + dk| = \sqrt{a^2 + b^2 + c^2 + d^2}

      The L2 norm of a quaternion vector is computed as:
      .. math::
          \|x\|^2 = \sum_{i=1}^d |x_i|^2
                   = \sum_{i=1}^d (x_i.re^2 + x_i.im_1^2 + x_i.im_2^2 + x_i.im_3^2)
      :param x: The vector containing quaternion values.
      :type x: torch.FloatTensor

      :returns: The normalized vector.
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      This function normalizes the length of relation vectors represented as quaternions. It ensures that
      the absolute value of each quaternion in the vector is equal to 1, preserving the unit length.


   .. py:method:: score(head_ent_emb: torch.FloatTensor, rel_ent_emb: torch.FloatTensor, tail_ent_emb: torch.FloatTensor) -> torch.FloatTensor

      Compute scores for a batch of triples using octonion-based embeddings.

      This method computes scores for a batch of triples using octonion-based embeddings of head entities,
      relation embeddings, and tail entities. It supports both explicit and non-explicit scoring methods.

      :param head_ent_emb: Tensor containing the octonion-based embeddings of head entities.
      :type head_ent_emb: torch.FloatTensor
      :param rel_ent_emb: Tensor containing the octonion-based embeddings of relations.
      :type rel_ent_emb: torch.FloatTensor
      :param tail_ent_emb: Tensor containing the octonion-based embeddings of tail entities.
      :type tail_ent_emb: torch.FloatTensor

      :returns: Scores for the given batch of triples.
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      If no normalization is set, this method applies quaternion normalization to relation embeddings.

      If the scoring method is explicit, it computes the scores using quaternion multiplication followed by
      an inner product of the real and imaginary parts of the resulting quaternions.

      If the scoring method is non-explicit, it directly computes the inner product of the real and
      imaginary parts of the octonion-based embeddings.


   .. py:method:: k_vs_all_score(bpe_head_ent_emb: torch.FloatTensor, bpe_rel_ent_emb: torch.FloatTensor, E: torch.FloatTensor) -> torch.FloatTensor

      Computes scores in a K-vs-All setting using quaternion embeddings for a batch of head entities and relations.

      This method involves splitting the head entity and relation embeddings into quaternion components,
      optionally normalizing the relation embeddings, performing quaternion multiplication, and then
      calculating the score by performing an inner product with all tail entity embeddings.

      :param bpe_head_ent_emb: Batched embeddings of head entities, each represented as a quaternion.
      :type bpe_head_ent_emb: torch.FloatTensor
      :param bpe_rel_ent_emb: Batched embeddings of relations, each represented as a quaternion.
      :type bpe_rel_ent_emb: torch.FloatTensor
      :param E: Embeddings of all possible tail entities.
      :type E: torch.FloatTensor

      :returns: Scores for all possible triples formed with the given head entities and relations against all entities.
                The shape of the output is (size of batch, number of entities).
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      The method is particularly useful in scenarios like link prediction, where the goal is to rank all possible
      tail entities for a given head entity and relation. Quaternion algebra is used to enhance the interaction
      modeling between entities and relations.


   .. py:method:: forward_k_vs_all(x: torch.FloatTensor) -> torch.FloatTensor

      Computes scores for all entities in a K-vs-All setting given a batch of head entities and relations.

      This method retrieves embeddings for the head entities and relations from the input tensor `x`,
      applies necessary dropout and normalization, and then uses the `k_vs_all_score` method to compute
      the scores against all possible tail entities in the knowledge graph.

      :param x: A tensor containing indices for head entities and relations. The tensor is expected to have
                a specific format suitable for the model's embedding retrieval process.
      :type x: torch.FloatTensor

      :returns: A tensor of scores, where each row corresponds to the scores of all tail entities for a
                single head entity and relation pair. The shape of the tensor is (size of the batch, number of entities).
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      This method is typically used in evaluating the model's performance in link prediction tasks,
      where it's important to rank the likelihood of every possible tail entity for a given head entity
      and relation.


   .. py:method:: forward_k_vs_sample(x: torch.FloatTensor, target_entity_idx: int) -> torch.FloatTensor

      Computes scores for a batch of triples against a sampled subset of entities in a K-vs-Sample setting.

      Given a batch of head entities and relations (h,r), this method computes the scores for all possible triples
      formed with these head entities and relations against a subset of entities, i.e., [score(h,r,x)|x \in Entities] => [0.0,0.1,...,0.8], shape=> (1, |Entities|). TODO: Add mathematical format for sphinx.
      The subset of entities is specified by the `target_entity_idx`, which is an integer index representing a specific entity.
      Given a batch of head entities and relations => shape (size of batch,| Entities|).

      :param x: A tensor containing indices for head entities and relations. The tensor is expected to have
                a specific format suitable for the model's embedding retrieval process.
      :type x: torch.FloatTensor
      :param target_entity_idx: Index of the target entity against which the scores are to be computed.
      :type target_entity_idx: int

      :returns: A tensor of scores where each element corresponds to the score of the target entity
                for a single head entity and relation pair. The shape of the tensor is (size of the batch, 1).
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      This method is particularly useful in scenarios like link prediction, where it's necessary to
      evaluate the likelihood of a specific relationship between a given head entity and a particular
      target entity.



.. py:class:: ConvQ(args)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   Convolutional Quaternion Knowledge Graph Embeddings (ConvQ) is a model that extends
   the base knowledge graph embedding approach by using quaternion algebra and convolutional
   neural networks. This model aims to capture complex interactions in knowledge graphs
   by applying convolutions to quaternion-based entity and relation embeddings.

   :param args: A dictionary of arguments containing hyperparameters and settings for the model,
                such as embedding dimensions, number of output channels, kernel size, and dropout rates.
   :type args: dict

   .. attribute:: name

      The name identifier for the ConvQ model.

      :type: str

   .. attribute:: entity_embeddings

      Embedding layer for entities in the knowledge graph.

      :type: torch.nn.Embedding

   .. attribute:: relation_embeddings

      Embedding layer for relations in the knowledge graph.

      :type: torch.nn.Embedding

   .. attribute:: conv2d

      A 2D convolutional layer used for processing quaternion embeddings.

      :type: torch.nn.Conv2d

   .. attribute:: fc_num_input

      The number of input features for the fully connected layer.

      :type: int

   .. attribute:: fc1

      A fully connected linear layer for compressing the output of the convolutional layer.

      :type: torch.nn.Linear

   .. attribute:: bn_conv1

      First batch normalization layer applied after the convolutional operation.

      :type: torch.nn.BatchNorm2d

   .. attribute:: bn_conv2

      Second normalization layer applied after the fully connected layer.

      :type: Normalizer

   .. attribute:: feature_map_dropout

      Dropout layer applied to the output of the convolutional layer.

      :type: torch.nn.Dropout2d

   .. method:: residual_convolution(Q_1, Q_2)

      Performs a residual convolution operation on two sets of quaternion embeddings.


   .. method:: forward_triples(indexed_triple: torch.FloatTensor) -> torch.FloatTensor

      Computes scores for a batch of triples using convolutional operations on quaternion embeddings.


   .. method:: forward_k_vs_all(x: torch.FloatTensor) -> torch.FloatTensor

      Computes scores for all entities in a K-vs-All setting given a batch of head entities and relations.


   .. rubric:: Notes

   ConvQ leverages the properties of quaternions, a number system that extends complex numbers,
   to represent and process the embeddings of entities and relations. The convolutional layers
   aim to capture spatial relationships and complex patterns in the embeddings.

   .. py:method:: residual_convolution(Q_1: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor], Q_2: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      Performs a residual convolution operation on two sets of quaternion embeddings.

      The method combines two quaternion embeddings and applies a convolutional operation
      followed by batch normalization, dropout, and a fully connected layer.

      :param Q_1: The first set of quaternion embeddings.
      :type Q_1: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]
      :param Q_2: The second set of quaternion embeddings.
      :type Q_2: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      :returns: The resulting quaternion embeddings after the convolutional operation.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]


   .. py:method:: forward_triples(indexed_triple: torch.FloatTensor) -> torch.FloatTensor

      Computes scores for a batch of triples using convolutional operations on quaternion embeddings.

      The method processes head, relation, and tail embeddings using quaternion algebra and
      convolutional layers and computes the scores of the triples.

      :param indexed_triple: Tensor containing indices for head entities, relations, and tail entities.
      :type indexed_triple: torch.FloatTensor

      :returns: Scores for the given batch of triples.
      :rtype: torch.FloatTensor


   .. py:method:: forward_k_vs_all(x: torch.FloatTensor) -> torch.FloatTensor

      Computes scores for all entities in a K-vs-All setting given a batch of head entities and relations.

      This method retrieves embeddings for the head entities and relations from the input tensor `x`,
      applies necessary dropout and normalization, and then computes scores against all entities in
      the knowledge graph.

      :param x: A tensor containing indices for head entities and relations.
      :type x: torch.FloatTensor

      :returns: Scores for all entities for the given batch of head entities and relations.
      :rtype: torch.FloatTensor



.. py:class:: AConvQ(args)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   Additive Convolutional Quaternion Knowledge Graph Embeddings (AConvQ) model integrates
   quaternion algebra with convolutional neural networks for knowledge graph embeddings.
   This model is designed to capture complex interactions in knowledge graphs by applying
   additive convolutions to quaternion-based entity and relation embeddings.

   .. attribute:: name

      The name identifier for the AConvQ model.

      :type: str

   .. attribute:: entity_embeddings

      Embedding layer for entities in the knowledge graph.

      :type: torch.nn.Embedding

   .. attribute:: relation_embeddings

      Embedding layer for relations in the knowledge graph.

      :type: torch.nn.Embedding

   .. attribute:: conv2d

      A 2D convolutional layer used for processing quaternion embeddings.

      :type: torch.nn.Conv2d

   .. attribute:: fc_num_input

      The number of input features for the fully connected layer.

      :type: int

   .. attribute:: fc1

      A fully connected linear layer for compressing the output of the convolutional layer.

      :type: torch.nn.Linear

   .. attribute:: bn_conv1

      Batch normalization layer applied after the convolutional operation.

      :type: torch.nn.BatchNorm2d

   .. attribute:: bn_conv2

      Normalization layer applied after the fully connected layer.

      :type: Normalizer

   .. attribute:: feature_map_dropout

      Dropout layer applied to the output of the convolutional layer.

      :type: torch.nn.Dropout2d

   .. method:: residual_convolution(Q_1, Q_2)

      Performs an additive residual convolution operation on two sets of quaternion embeddings.


   .. method:: forward_triples(indexed_triple: torch.FloatTensor) -> torch.FloatTensor

      Computes scores for a batch of triples using additive convolutional operations on quaternion embeddings.


   .. method:: forward_k_vs_all(x: torch.FloatTensor) -> torch.FloatTensor

      Computes scores for all entities in a K-vs-All setting given a batch of head entities and relations.


   .. py:method:: residual_convolution(Q_1: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor], Q_2: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      Performs a residual convolution operation on two sets of quaternion embeddings.

      The method combines two quaternion embeddings and applies a convolutional operation
      followed by batch normalization, dropout, and a fully connected layer.

      :param Q_1: The first set of quaternion embeddings.
      :type Q_1: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]
      :param Q_2: The second set of quaternion embeddings.
      :type Q_2: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      :returns: The resulting quaternion embeddings after the convolutional operation.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]


   .. py:method:: forward_triples(indexed_triple: torch.FloatTensor) -> torch.FloatTensor

      Computes scores for a batch of triples using convolutional operations on quaternion embeddings.

      The method processes head, relation, and tail embeddings using quaternion algebra and
      convolutional layers and computes the scores of the triples.

      :param indexed_triple: Tensor containing indices for head entities, relations, and tail entities.
      :type indexed_triple: torch.FloatTensor

      :returns: Scores for the given batch of triples.
      :rtype: torch.FloatTensor


   .. py:method:: forward_k_vs_all(x: torch.FloatTensor) -> torch.FloatTensor

      Computes scores for all entities in a K-vs-All setting given a batch of head entities and relations.

      This method retrieves embeddings for the head entities and relations from the input tensor `x`,
      applies necessary dropout and normalization, and then computes scores against all entities in
      the knowledge graph.

      :param x: A tensor containing indices for head entities and relations.
      :type x: torch.FloatTensor

      :returns: Scores for all entities for the given batch of head entities and relations.
      :rtype: torch.FloatTensor



