:py:mod:`dicee.models`
======================

.. py:module:: dicee.models


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   base_model/index.rst
   clifford/index.rst
   complex/index.rst
   dualE/index.rst
   function_space/index.rst
   octonion/index.rst
   pykeen_models/index.rst
   quaternion/index.rst
   real/index.rst
   static_funcs/index.rst
   transformers/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   dicee.models.BaseKGELightning
   dicee.models.BaseKGE
   dicee.models.IdentityClass
   dicee.models.BaseKGE
   dicee.models.DistMult
   dicee.models.TransE
   dicee.models.Shallom
   dicee.models.Pyke
   dicee.models.BaseKGE
   dicee.models.ConEx
   dicee.models.AConEx
   dicee.models.ComplEx
   dicee.models.BaseKGE
   dicee.models.IdentityClass
   dicee.models.QMult
   dicee.models.ConvQ
   dicee.models.AConvQ
   dicee.models.BaseKGE
   dicee.models.IdentityClass
   dicee.models.OMult
   dicee.models.ConvO
   dicee.models.AConvO
   dicee.models.Keci
   dicee.models.KeciBase
   dicee.models.CMult
   dicee.models.DeCaL
   dicee.models.BaseKGE
   dicee.models.PykeenKGE
   dicee.models.BaseKGE
   dicee.models.FMult
   dicee.models.GFMult
   dicee.models.FMult2
   dicee.models.LFMult1
   dicee.models.LFMult
   dicee.models.DualE



Functions
~~~~~~~~~

.. autoapisummary::

   dicee.models.quaternion_mul
   dicee.models.quaternion_mul_with_unit_norm
   dicee.models.octonion_mul
   dicee.models.octonion_mul_norm



.. py:class:: BaseKGELightning(*args, **kwargs)


   Bases: :py:obj:`lightning.LightningModule`

   Base class for all neural network modules.

   Your models should also subclass this class.

   Modules can also contain other Modules, allowing to nest them in
   a tree structure. You can assign the submodules as regular attributes::

       import torch.nn as nn
       import torch.nn.functional as F

       class Model(nn.Module):
           def __init__(self):
               super().__init__()
               self.conv1 = nn.Conv2d(1, 20, 5)
               self.conv2 = nn.Conv2d(20, 20, 5)

           def forward(self, x):
               x = F.relu(self.conv1(x))
               return F.relu(self.conv2(x))

   Submodules assigned in this way will be registered, and will have their
   parameters converted too when you call :meth:`to`, etc.

   .. note::
       As per the example above, an ``__init__()`` call to the parent class
       must be made before assignment on the child.

   :ivar training: Boolean represents whether this module is in training or
                   evaluation mode.
   :vartype training: bool

   .. py:method:: mem_of_model() -> Dict

      Size of model in MB and number of params


   .. py:method:: training_step(batch, batch_idx=None)

      Here you compute and return the training loss and some additional metrics for e.g. the progress bar or
      logger.

      :param batch: The output of your data iterable, normally a :class:`~torch.utils.data.DataLoader`.
      :param batch_idx: The index of this batch.
      :param dataloader_idx: The index of the dataloader that produced this batch.
                             (only if multiple dataloaders used)

      :returns:

                - :class:`~torch.Tensor` - The loss tensor
                - ``dict`` - A dictionary which can include any keys, but must include the key ``'loss'`` in the case of
                  automatic optimization.
                - ``None`` - In automatic optimization, this will skip to the next batch (but is not supported for
                  multi-GPU, TPU, or DeepSpeed). For manual optimization, this has no special meaning, as returning
                  the loss is not required.

      In this step you'd normally do the forward pass and calculate the loss for a batch.
      You can also do fancier things like multiple forward passes or something model specific.

      Example::

          def training_step(self, batch, batch_idx):
              x, y, z = batch
              out = self.encoder(x)
              loss = self.loss(out, x)
              return loss

      To use multiple optimizers, you can switch to 'manual optimization' and control their stepping:

      .. code-block:: python

          def __init__(self):
              super().__init__()
              self.automatic_optimization = False


          # Multiple optimizers (e.g.: GANs)
          def training_step(self, batch, batch_idx):
              opt1, opt2 = self.optimizers()

              # do training_step with encoder
              ...
              opt1.step()
              # do training_step with decoder
              ...
              opt2.step()

      .. note::

         When ``accumulate_grad_batches`` > 1, the loss returned here will be automatically
         normalized by ``accumulate_grad_batches`` internally.


   .. py:method:: loss_function(yhat_batch: torch.FloatTensor, y_batch: torch.FloatTensor)

      :param yhat_batch:
      :param y_batch:


   .. py:method:: on_train_epoch_end(*args, **kwargs)

      Called in the training loop at the very end of the epoch.

      To access all batch outputs at the end of the epoch, you can cache step outputs as an attribute of the
      :class:`~lightning.pytorch.LightningModule` and access them in this hook:

      .. code-block:: python

          class MyLightningModule(L.LightningModule):
              def __init__(self):
                  super().__init__()
                  self.training_step_outputs = []

              def training_step(self):
                  loss = ...
                  self.training_step_outputs.append(loss)
                  return loss

              def on_train_epoch_end(self):
                  # do something with all training_step outputs, for example:
                  epoch_mean = torch.stack(self.training_step_outputs).mean()
                  self.log("training_epoch_mean", epoch_mean)
                  # free up the memory
                  self.training_step_outputs.clear()



   .. py:method:: test_epoch_end(outputs: List[Any])


   .. py:method:: test_dataloader() -> None

      An iterable or collection of iterables specifying test samples.

      For more information about multiple dataloaders, see this :ref:`section <multiple-dataloaders>`.

      For data processing use the following pattern:

          - download in :meth:`prepare_data`
          - process and split in :meth:`setup`

      However, the above are only necessary for distributed processing.

      .. warning:: do not assign state in prepare_data


      - :meth:`~lightning.pytorch.trainer.trainer.Trainer.test`
      - :meth:`prepare_data`
      - :meth:`setup`

      .. note::

         Lightning tries to add the correct sampler for distributed and arbitrary hardware.
         There is no need to set it yourself.

      .. note::

         If you don't need a test dataset and a :meth:`test_step`, you don't need to implement
         this method.


   .. py:method:: val_dataloader() -> None

      An iterable or collection of iterables specifying validation samples.

      For more information about multiple dataloaders, see this :ref:`section <multiple-dataloaders>`.

      The dataloader you return will not be reloaded unless you set
      :paramref:`~lightning.pytorch.trainer.trainer.Trainer.reload_dataloaders_every_n_epochs` to
      a positive integer.

      It's recommended that all data downloads and preparation happen in :meth:`prepare_data`.

      - :meth:`~lightning.pytorch.trainer.trainer.Trainer.fit`
      - :meth:`~lightning.pytorch.trainer.trainer.Trainer.validate`
      - :meth:`prepare_data`
      - :meth:`setup`

      .. note::

         Lightning tries to add the correct sampler for distributed and arbitrary hardware
         There is no need to set it yourself.

      .. note::

         If you don't need a validation dataset and a :meth:`validation_step`, you don't need to
         implement this method.


   .. py:method:: predict_dataloader() -> None

      An iterable or collection of iterables specifying prediction samples.

      For more information about multiple dataloaders, see this :ref:`section <multiple-dataloaders>`.

      It's recommended that all data downloads and preparation happen in :meth:`prepare_data`.

      - :meth:`~lightning.pytorch.trainer.trainer.Trainer.predict`
      - :meth:`prepare_data`
      - :meth:`setup`

      .. note::

         Lightning tries to add the correct sampler for distributed and arbitrary hardware
         There is no need to set it yourself.

      :returns: A :class:`torch.utils.data.DataLoader` or a sequence of them specifying prediction samples.


   .. py:method:: train_dataloader() -> None

      An iterable or collection of iterables specifying training samples.

      For more information about multiple dataloaders, see this :ref:`section <multiple-dataloaders>`.

      The dataloader you return will not be reloaded unless you set
      :paramref:`~lightning.pytorch.trainer.trainer.Trainer.reload_dataloaders_every_n_epochs` to
      a positive integer.

      For data processing use the following pattern:

          - download in :meth:`prepare_data`
          - process and split in :meth:`setup`

      However, the above are only necessary for distributed processing.

      .. warning:: do not assign state in prepare_data

      - :meth:`~lightning.pytorch.trainer.trainer.Trainer.fit`
      - :meth:`prepare_data`
      - :meth:`setup`

      .. note::

         Lightning tries to add the correct sampler for distributed and arbitrary hardware.
         There is no need to set it yourself.


   .. py:method:: configure_optimizers(parameters=None)

      Choose what optimizers and learning-rate schedulers to use in your optimization. Normally you'd need one.
      But in the case of GANs or similar you might have multiple. Optimization with multiple optimizers only works in
      the manual optimization mode.

      :returns: Any of these 6 options.

                - **Single optimizer**.
                - **List or Tuple** of optimizers.
                - **Two lists** - The first list has multiple optimizers, and the second has multiple LR schedulers
                  (or multiple ``lr_scheduler_config``).
                - **Dictionary**, with an ``"optimizer"`` key, and (optionally) a ``"lr_scheduler"``
                  key whose value is a single LR scheduler or ``lr_scheduler_config``.
                - **None** - Fit will run without any optimizer.

      The ``lr_scheduler_config`` is a dictionary which contains the scheduler and its associated configuration.
      The default configuration is shown below.

      .. code-block:: python

          lr_scheduler_config = {
              # REQUIRED: The scheduler instance
              "scheduler": lr_scheduler,
              # The unit of the scheduler's step size, could also be 'step'.
              # 'epoch' updates the scheduler on epoch end whereas 'step'
              # updates it after a optimizer update.
              "interval": "epoch",
              # How many epochs/steps should pass between calls to
              # `scheduler.step()`. 1 corresponds to updating the learning
              # rate after every epoch/step.
              "frequency": 1,
              # Metric to to monitor for schedulers like `ReduceLROnPlateau`
              "monitor": "val_loss",
              # If set to `True`, will enforce that the value specified 'monitor'
              # is available when the scheduler is updated, thus stopping
              # training if not found. If set to `False`, it will only produce a warning
              "strict": True,
              # If using the `LearningRateMonitor` callback to monitor the
              # learning rate progress, this keyword can be used to specify
              # a custom logged name
              "name": None,
          }

      When there are schedulers in which the ``.step()`` method is conditioned on a value, such as the
      :class:`torch.optim.lr_scheduler.ReduceLROnPlateau` scheduler, Lightning requires that the
      ``lr_scheduler_config`` contains the keyword ``"monitor"`` set to the metric name that the scheduler
      should be conditioned on.

      .. testcode::

          # The ReduceLROnPlateau scheduler requires a monitor
          def configure_optimizers(self):
              optimizer = Adam(...)
              return {
                  "optimizer": optimizer,
                  "lr_scheduler": {
                      "scheduler": ReduceLROnPlateau(optimizer, ...),
                      "monitor": "metric_to_track",
                      "frequency": "indicates how often the metric is updated",
                      # If "monitor" references validation metrics, then "frequency" should be set to a
                      # multiple of "trainer.check_val_every_n_epoch".
                  },
              }


          # In the case of two optimizers, only one using the ReduceLROnPlateau scheduler
          def configure_optimizers(self):
              optimizer1 = Adam(...)
              optimizer2 = SGD(...)
              scheduler1 = ReduceLROnPlateau(optimizer1, ...)
              scheduler2 = LambdaLR(optimizer2, ...)
              return (
                  {
                      "optimizer": optimizer1,
                      "lr_scheduler": {
                          "scheduler": scheduler1,
                          "monitor": "metric_to_track",
                      },
                  },
                  {"optimizer": optimizer2, "lr_scheduler": scheduler2},
              )

      Metrics can be made available to monitor by simply logging it using
      ``self.log('metric_to_track', metric_val)`` in your :class:`~lightning.pytorch.core.LightningModule`.

      .. note::

         Some things to know:
         
         - Lightning calls ``.backward()`` and ``.step()`` automatically in case of automatic optimization.
         - If a learning rate scheduler is specified in ``configure_optimizers()`` with key
           ``"interval"`` (default "epoch") in the scheduler configuration, Lightning will call
           the scheduler's ``.step()`` method automatically in case of automatic optimization.
         - If you use 16-bit precision (``precision=16``), Lightning will automatically handle the optimizer.
         - If you use :class:`torch.optim.LBFGS`, Lightning handles the closure function automatically for you.
         - If you use multiple optimizers, you will have to switch to 'manual optimization' mode and step them
           yourself.
         - If you need to control how often the optimizer steps, override the :meth:`optimizer_step` hook.



.. py:class:: BaseKGE(args: dict)


   Bases: :py:obj:`BaseKGELightning`

   Base class for all neural network modules.

   Your models should also subclass this class.

   Modules can also contain other Modules, allowing to nest them in
   a tree structure. You can assign the submodules as regular attributes::

       import torch.nn as nn
       import torch.nn.functional as F

       class Model(nn.Module):
           def __init__(self):
               super().__init__()
               self.conv1 = nn.Conv2d(1, 20, 5)
               self.conv2 = nn.Conv2d(20, 20, 5)

           def forward(self, x):
               x = F.relu(self.conv1(x))
               return F.relu(self.conv2(x))

   Submodules assigned in this way will be registered, and will have their
   parameters converted too when you call :meth:`to`, etc.

   .. note::
       As per the example above, an ``__init__()`` call to the parent class
       must be made before assignment on the child.

   :ivar training: Boolean represents whether this module is in training or
                   evaluation mode.
   :vartype training: bool

   .. py:method:: forward_byte_pair_encoded_k_vs_all(x: torch.LongTensor)

      :param x:
      :type x: B x 2 x T


   .. py:method:: forward_byte_pair_encoded_triple(x: Tuple[torch.LongTensor, torch.LongTensor])

      Perform the forward pass for byte pair encoded triples.

      :param x: The input tuple containing byte pair encoded entities and relations.
      :type x: Tuple[torch.LongTensor, torch.LongTensor]

      :returns: The output tensor containing the scores for the byte pair encoded triples.
      :rtype: torch.Tensor


   .. py:method:: init_params_with_sanity_checking()


   .. py:method:: forward(x: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]], y_idx: torch.LongTensor = None)

      Perform the forward pass of the model.

      :param x: The input tensor or a tuple containing the input tensor and target entity indexes.
      :type x: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]]
      :param y_idx: The target entity indexes (default is None).
      :type y_idx: torch.LongTensor, optional

      :returns: The output of the forward pass.
      :rtype: Any


   .. py:method:: forward_triples(x: torch.LongTensor) -> torch.Tensor

      Perform the forward pass for triples.

      :param x: The input tensor containing the indexes of head, relation, and tail entities.
      :type x: torch.LongTensor

      :returns: The output tensor containing the scores for the input triples.
      :rtype: torch.Tensor


   .. py:method:: forward_k_vs_all(*args, **kwargs)

      Forward pass for K vs. All.

      :raises ValueError: This function is not implemented in the current model.


   .. py:method:: forward_k_vs_sample(*args, **kwargs)

      Forward pass for K vs. Sample.

      :raises ValueError: This function is not implemented in the current model.


   .. py:method:: get_triple_representation(idx_hrt)


   .. py:method:: get_head_relation_representation(indexed_triple: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor]

      Get the representation for the head and relation entities.

      :param indexed_triple: The indexes of the head and relation entities.
      :type indexed_triple: torch.LongTensor

      :returns: The representation for the head and relation entities.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_sentence_representation(x: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      Get the representation for a sentence.

      :param x: The input tensor containing the indexes of head, relation, and tail entities.
      :type x: torch.LongTensor

      :returns: The representation for the input sentence.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_bpe_head_and_relation_representation(x: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor]

      Get the representation for BPE head and relation entities.

      :param x:
      :type x: B x 2 x T

      :returns: The representation for BPE head and relation entities.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_embeddings() -> Tuple[numpy.ndarray, numpy.ndarray]

      Get the entity and relation embeddings.

      :returns: The entity and relation embeddings.
      :rtype: Tuple[np.ndarray, np.ndarray]



.. py:class:: IdentityClass(args: Optional[Dict] = None)


   Bases: :py:obj:`torch.nn.Module`

   A class that represents an identity function.

   :param args: A dictionary containing arguments (default is None).
   :type args: dict, optional

   .. py:method:: __call__(x)


   .. py:method:: forward(x: torch.Tensor) -> torch.Tensor
      :staticmethod:

      The forward pass of the identity function.

      :param x: The input tensor.
      :type x: torch.Tensor

      :returns: The output tensor, which is the same as the input.
      :rtype: torch.Tensor



.. py:class:: BaseKGE(args: dict)


   Bases: :py:obj:`BaseKGELightning`

   Base class for all neural network modules.

   Your models should also subclass this class.

   Modules can also contain other Modules, allowing to nest them in
   a tree structure. You can assign the submodules as regular attributes::

       import torch.nn as nn
       import torch.nn.functional as F

       class Model(nn.Module):
           def __init__(self):
               super().__init__()
               self.conv1 = nn.Conv2d(1, 20, 5)
               self.conv2 = nn.Conv2d(20, 20, 5)

           def forward(self, x):
               x = F.relu(self.conv1(x))
               return F.relu(self.conv2(x))

   Submodules assigned in this way will be registered, and will have their
   parameters converted too when you call :meth:`to`, etc.

   .. note::
       As per the example above, an ``__init__()`` call to the parent class
       must be made before assignment on the child.

   :ivar training: Boolean represents whether this module is in training or
                   evaluation mode.
   :vartype training: bool

   .. py:method:: forward_byte_pair_encoded_k_vs_all(x: torch.LongTensor)

      :param x:
      :type x: B x 2 x T


   .. py:method:: forward_byte_pair_encoded_triple(x: Tuple[torch.LongTensor, torch.LongTensor])

      Perform the forward pass for byte pair encoded triples.

      :param x: The input tuple containing byte pair encoded entities and relations.
      :type x: Tuple[torch.LongTensor, torch.LongTensor]

      :returns: The output tensor containing the scores for the byte pair encoded triples.
      :rtype: torch.Tensor


   .. py:method:: init_params_with_sanity_checking()


   .. py:method:: forward(x: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]], y_idx: torch.LongTensor = None)

      Perform the forward pass of the model.

      :param x: The input tensor or a tuple containing the input tensor and target entity indexes.
      :type x: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]]
      :param y_idx: The target entity indexes (default is None).
      :type y_idx: torch.LongTensor, optional

      :returns: The output of the forward pass.
      :rtype: Any


   .. py:method:: forward_triples(x: torch.LongTensor) -> torch.Tensor

      Perform the forward pass for triples.

      :param x: The input tensor containing the indexes of head, relation, and tail entities.
      :type x: torch.LongTensor

      :returns: The output tensor containing the scores for the input triples.
      :rtype: torch.Tensor


   .. py:method:: forward_k_vs_all(*args, **kwargs)

      Forward pass for K vs. All.

      :raises ValueError: This function is not implemented in the current model.


   .. py:method:: forward_k_vs_sample(*args, **kwargs)

      Forward pass for K vs. Sample.

      :raises ValueError: This function is not implemented in the current model.


   .. py:method:: get_triple_representation(idx_hrt)


   .. py:method:: get_head_relation_representation(indexed_triple: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor]

      Get the representation for the head and relation entities.

      :param indexed_triple: The indexes of the head and relation entities.
      :type indexed_triple: torch.LongTensor

      :returns: The representation for the head and relation entities.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_sentence_representation(x: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      Get the representation for a sentence.

      :param x: The input tensor containing the indexes of head, relation, and tail entities.
      :type x: torch.LongTensor

      :returns: The representation for the input sentence.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_bpe_head_and_relation_representation(x: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor]

      Get the representation for BPE head and relation entities.

      :param x:
      :type x: B x 2 x T

      :returns: The representation for BPE head and relation entities.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_embeddings() -> Tuple[numpy.ndarray, numpy.ndarray]

      Get the entity and relation embeddings.

      :returns: The entity and relation embeddings.
      :rtype: Tuple[np.ndarray, np.ndarray]



.. py:class:: DistMult(args)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   DistMult model for learning and inference in knowledge bases. It represents both entities
   and relations using embeddings and uses a simple bilinear form to compute scores for triples.

   This implementation of the DistMult model is based on the paper:
   'Embedding Entities and Relations for Learning and Inference in Knowledge Bases'
   (https://arxiv.org/abs/1412.6575).

   .. attribute:: name

      The name identifier for the DistMult model.

      :type: str

   .. method:: k_vs_all_score(emb_h: torch.FloatTensor, emb_r: torch.FloatTensor, emb_E: torch.FloatTensor) -> torch.FloatTensor

      Computes scores in a K-vs-All setting using embeddings for a batch of head entities and relations.


   .. method:: forward_k_vs_all(x: torch.LongTensor) -> torch.FloatTensor

      Computes scores for all entities given a batch of head entities and relations.


   .. method:: forward_k_vs_sample(x: torch.LongTensor, target_entity_idx: torch.LongTensor) -> torch.FloatTensor

      Computes scores for a sampled subset of entities given a batch of head entities and relations.


   .. method:: score(h: torch.FloatTensor, r: torch.FloatTensor, t: torch.FloatTensor) -> torch.FloatTensor

      Computes the score of triples using DistMult's scoring function.


   .. py:method:: k_vs_all_score(emb_h: torch.FloatTensor, emb_r: torch.FloatTensor, emb_E: torch.FloatTensor) -> torch.FloatTensor

      Computes scores in a K-vs-All setting using embeddings for a batch of head entities and relations.

      This method multiplies the head entity and relation embeddings, applies a dropout and a normalization,
      and then computes the dot product with all tail entity embeddings.

      :param emb_h: Embeddings of head entities.
      :type emb_h: torch.FloatTensor
      :param emb_r: Embeddings of relations.
      :type emb_r: torch.FloatTensor
      :param emb_E: Embeddings of all entities.
      :type emb_E: torch.FloatTensor

      :returns: Scores for all possible triples formed with the given head entities and relations against all entities.
      :rtype: torch.FloatTensor


   .. py:method:: forward_k_vs_all(x: torch.LongTensor) -> torch.FloatTensor

      Computes scores for all entities given a batch of head entities and relations.

      This method is used for K-vs-All scoring, where the model predicts the likelihood of each entity
      being the tail entity in a triple with each head entity and relation pair in the batch.

      :param x: Tensor containing indices for head entities and relations.
      :type x: torch.LongTensor

      :returns: Scores for all entities for each head entity and relation pair in the batch.
      :rtype: torch.FloatTensor


   .. py:method:: forward_k_vs_sample(x: torch.LongTensor, target_entity_idx: torch.LongTensor) -> torch.FloatTensor

      Computes scores for a sampled subset of entities given a batch of head entities and relations.

      This method is particularly useful when the full set of entities is too large to score
      with every batch and only a subset of entities is required.

      :param x: Tensor containing indices for head entities and relations.
      :type x: torch.LongTensor
      :param target_entity_idx: Indices of the target entities against which the scores are to be computed.
      :type target_entity_idx: torch.LongTensor

      :returns: Scores for each head entity and relation pair against the sampled subset of entities.
      :rtype: torch.FloatTensor


   .. py:method:: score(h: torch.FloatTensor, r: torch.FloatTensor, t: torch.FloatTensor) -> torch.FloatTensor

      Computes the score of triples using DistMult's scoring function.

      The scoring function multiplies head entity and relation embeddings, applies dropout and normalization,
      and computes the dot product with the tail entity embeddings.

      :param h: Embedding of the head entity.
      :type h: torch.FloatTensor
      :param r: Embedding of the relation.
      :type r: torch.FloatTensor
      :param t: Embedding of the tail entity.
      :type t: torch.FloatTensor

      :returns: The score of the triple.
      :rtype: torch.FloatTensor



.. py:class:: TransE(args)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   TransE model for learning embeddings in multi-relational data. It is based on the idea of translating
   embeddings for head entities by the relation vector to approach the tail entity embeddings in the embedding space.

   This implementation of TransE is based on the paper:
   'Translating Embeddings for Modeling Multi-relational Data'
   (https://proceedings.neurips.cc/paper/2013/file/1cecc7a77928ca8133fa24680a88d2f9-Paper.pdf).

   .. attribute:: name

      The name identifier for the TransE model.

      :type: str

   .. attribute:: _norm

      The norm used for computing pairwise distances in the embedding space.

      :type: int

   .. attribute:: margin

      The margin value used in the scoring function.

      :type: int

   .. method:: score(head_ent_emb: torch.Tensor, rel_ent_emb: torch.Tensor, tail_ent_emb: torch.Tensor) -> torch.Tensor

      Computes the score of triples using the TransE scoring function.


   .. method:: forward_k_vs_all(x: torch.Tensor) -> torch.FloatTensor

      Computes scores for all entities given a head entity and a relation.


   .. py:method:: score(head_ent_emb: torch.Tensor, rel_ent_emb: torch.Tensor, tail_ent_emb: torch.Tensor) -> torch.Tensor

      Computes the score of triples using the TransE scoring function.

      The scoring function computes the L2 distance between the translated head entity
      and the tail entity embeddings and subtracts this distance from the margin.

      :param head_ent_emb: Embedding of the head entity.
      :type head_ent_emb: torch.Tensor
      :param rel_ent_emb: Embedding of the relation.
      :type rel_ent_emb: torch.Tensor
      :param tail_ent_emb: Embedding of the tail entity.
      :type tail_ent_emb: torch.Tensor

      :returns: The score of the triple.
      :rtype: torch.Tensor


   .. py:method:: forward_k_vs_all(x: torch.Tensor) -> torch.FloatTensor

      Computes scores for all entities given a head entity and a relation.

      This method is used for K-vs-All scoring, where the model predicts the likelihood of each entity
      being the tail entity in a triple with each head entity and relation.

      :param x: Tensor containing indices for head entities and relations.
      :type x: torch.Tensor

      :returns: Scores for all entities for each head entity and relation pair.
      :rtype: torch.FloatTensor



.. py:class:: Shallom(args: dict)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   Shallom is a shallow neural model designed for relation prediction in knowledge graphs.
   The model combines entity embeddings and passes them through a neural network to predict
   the likelihood of different relations. It's based on the paper:
   'A Shallow Neural Model for Relation Prediction'
   (https://arxiv.org/abs/2101.09090).

   .. attribute:: name

      The name identifier for the Shallom model.

      :type: str

   .. attribute:: shallom

      A sequential neural network model used for predicting relations.

      :type: torch.nn.Sequential

   .. method:: get_embeddings() -> Tuple[np.ndarray, None]

      Retrieves the entity embeddings.


   .. method:: forward_k_vs_all(x) -> torch.FloatTensor

      Computes relation scores for all pairs of entities in the batch.


   .. method:: forward_triples(x) -> torch.FloatTensor

      Computes relation scores for a batch of triples.


   .. py:method:: get_embeddings() -> Tuple[numpy.ndarray, None]

      Retrieves the entity embeddings from the model.

      :returns: A tuple containing the entity embeddings as a NumPy array and None for the relation embeddings.
      :rtype: Tuple[np.ndarray, None]


   .. py:method:: forward_k_vs_all(x: torch.Tensor) -> torch.FloatTensor

      Computes relation scores for all pairs of entities in the batch.

      Each pair of entities is passed through the Shallom neural network to predict
      the likelihood of various relations between them.

      :param x: A tensor of entity pairs.
      :type x: torch.Tensor

      :returns: A tensor of relation scores for each pair of entities in the batch.
      :rtype: torch.FloatTensor


   .. py:method:: forward_triples(x: torch.Tensor) -> torch.FloatTensor

      Computes relation scores for a batch of triples.

      This method first computes relation scores for all possible relations for each pair of entities
      and then selects the scores corresponding to the actual relations in the triples.

      :param x: A tensor containing a batch of triples.
      :type x: torch.Tensor

      :returns: A flattened tensor of relation scores for the given batch of triples.
      :rtype: torch.FloatTensor



.. py:class:: Pyke(args: dict)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   Pyke is a physical embedding model for knowledge graphs, emphasizing the geometric relationships
   in the embedding space. The model aims to represent entities and relations in a way that captures
   the underlying structure of the knowledge graph.

   .. attribute:: name

      The name identifier for the Pyke model.

      :type: str

   .. attribute:: dist_func

      A pairwise distance function to compute distances in the embedding space.

      :type: torch.nn.PairwiseDistance

   .. attribute:: margin

      The margin value used in the scoring function.

      :type: float

   .. method:: forward_triples(x: torch.LongTensor) -> torch.FloatTensor

      Computes scores for a batch of triples based on the physical embedding approach.


   .. py:method:: forward_triples(x: torch.LongTensor) -> torch.FloatTensor

      Computes scores for a batch of triples based on the physical embedding approach.

      The method calculates the Euclidean distance between the head and relation embeddings,
      and between the relation and tail embeddings. The average of these distances is subtracted
      from the margin to compute the score for each triple.

      :param x: A tensor containing indices for head entities, relations, and tail entities.
      :type x: torch.LongTensor

      :returns: Scores for the given batch of triples. Lower scores indicate more likely triples
                according to the geometric arrangement of embeddings.
      :rtype: torch.FloatTensor



.. py:class:: BaseKGE(args: dict)


   Bases: :py:obj:`BaseKGELightning`

   Base class for all neural network modules.

   Your models should also subclass this class.

   Modules can also contain other Modules, allowing to nest them in
   a tree structure. You can assign the submodules as regular attributes::

       import torch.nn as nn
       import torch.nn.functional as F

       class Model(nn.Module):
           def __init__(self):
               super().__init__()
               self.conv1 = nn.Conv2d(1, 20, 5)
               self.conv2 = nn.Conv2d(20, 20, 5)

           def forward(self, x):
               x = F.relu(self.conv1(x))
               return F.relu(self.conv2(x))

   Submodules assigned in this way will be registered, and will have their
   parameters converted too when you call :meth:`to`, etc.

   .. note::
       As per the example above, an ``__init__()`` call to the parent class
       must be made before assignment on the child.

   :ivar training: Boolean represents whether this module is in training or
                   evaluation mode.
   :vartype training: bool

   .. py:method:: forward_byte_pair_encoded_k_vs_all(x: torch.LongTensor)

      :param x:
      :type x: B x 2 x T


   .. py:method:: forward_byte_pair_encoded_triple(x: Tuple[torch.LongTensor, torch.LongTensor])

      Perform the forward pass for byte pair encoded triples.

      :param x: The input tuple containing byte pair encoded entities and relations.
      :type x: Tuple[torch.LongTensor, torch.LongTensor]

      :returns: The output tensor containing the scores for the byte pair encoded triples.
      :rtype: torch.Tensor


   .. py:method:: init_params_with_sanity_checking()


   .. py:method:: forward(x: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]], y_idx: torch.LongTensor = None)

      Perform the forward pass of the model.

      :param x: The input tensor or a tuple containing the input tensor and target entity indexes.
      :type x: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]]
      :param y_idx: The target entity indexes (default is None).
      :type y_idx: torch.LongTensor, optional

      :returns: The output of the forward pass.
      :rtype: Any


   .. py:method:: forward_triples(x: torch.LongTensor) -> torch.Tensor

      Perform the forward pass for triples.

      :param x: The input tensor containing the indexes of head, relation, and tail entities.
      :type x: torch.LongTensor

      :returns: The output tensor containing the scores for the input triples.
      :rtype: torch.Tensor


   .. py:method:: forward_k_vs_all(*args, **kwargs)

      Forward pass for K vs. All.

      :raises ValueError: This function is not implemented in the current model.


   .. py:method:: forward_k_vs_sample(*args, **kwargs)

      Forward pass for K vs. Sample.

      :raises ValueError: This function is not implemented in the current model.


   .. py:method:: get_triple_representation(idx_hrt)


   .. py:method:: get_head_relation_representation(indexed_triple: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor]

      Get the representation for the head and relation entities.

      :param indexed_triple: The indexes of the head and relation entities.
      :type indexed_triple: torch.LongTensor

      :returns: The representation for the head and relation entities.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_sentence_representation(x: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      Get the representation for a sentence.

      :param x: The input tensor containing the indexes of head, relation, and tail entities.
      :type x: torch.LongTensor

      :returns: The representation for the input sentence.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_bpe_head_and_relation_representation(x: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor]

      Get the representation for BPE head and relation entities.

      :param x:
      :type x: B x 2 x T

      :returns: The representation for BPE head and relation entities.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_embeddings() -> Tuple[numpy.ndarray, numpy.ndarray]

      Get the entity and relation embeddings.

      :returns: The entity and relation embeddings.
      :rtype: Tuple[np.ndarray, np.ndarray]



.. py:class:: ConEx(args)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   ConEx (Convolutional ComplEx) is a Knowledge Graph Embedding model that extends ComplEx embeddings with convolutional layers.
   It integrates convolutional neural networks into the embedding process to capture complex patterns in the data.

   :param args: A dictionary of arguments containing hyperparameters and settings for the model, such as embedding dimensions,
                kernel size, number of output channels, and dropout rates.
   :type args: dict

   .. attribute:: name

      The name identifier for the ConEx model.

      :type: str

   .. attribute:: conv2d

      A 2D convolutional layer used for processing complex-valued embeddings.

      :type: torch.nn.Conv2d

   .. attribute:: fc1

      A fully connected linear layer for compressing the output of the convolutional layer.

      :type: torch.nn.Linear

   .. attribute:: norm_fc1

      Normalization layer applied after the fully connected layer.

      :type: Normalizer

   .. attribute:: bn_conv2d

      Batch normalization layer applied after the convolutional operation.

      :type: torch.nn.BatchNorm2d

   .. attribute:: feature_map_dropout

      Dropout layer applied to the output of the convolutional layer.

      :type: torch.nn.Dropout2d

   .. method:: residual_convolution(C_1: Tuple[torch.Tensor, torch.Tensor], C_2: Tuple[torch.Tensor, torch.Tensor]) -> Tuple[torch.Tensor, torch.Tensor]

      Performs a residual convolution operation on two complex-valued embeddings.

   .. method:: forward_k_vs_all(x: torch.Tensor) -> torch.FloatTensor

      Computes scores in a K-vs-All setting using convolutional operations on embeddings.

   .. method:: forward_triples(x: torch.Tensor) -> torch.FloatTensor

      Computes scores for a batch of triples using convolutional operations.

   .. method:: forward_k_vs_sample(x: torch.Tensor, target_entity_idx: torch.Tensor) -> torch.Tensor

      Computes scores against a sampled subset of entities using convolutional operations.


   .. rubric:: Notes

   ConEx combines complex-valued embeddings with convolutional neural networks to capture intricate patterns and interactions
   in the knowledge graph, potentially leading to improved performance on tasks like link prediction.

   .. py:method:: residual_convolution(C_1: Tuple[torch.Tensor, torch.Tensor], C_2: Tuple[torch.Tensor, torch.Tensor]) -> Tuple[torch.FloatTensor, torch.FloatTensor]

      Computes the residual score of two complex-valued embeddings by applying convolutional operations.
      This method is a key component of the ConEx model, combining complex embeddings with convolutional neural networks.

      :param C_1: A tuple consisting of two PyTorch tensors representing the real and imaginary components of the first complex-valued embedding.
      :type C_1: Tuple[torch.Tensor, torch.Tensor]
      :param C_2: A tuple consisting of two PyTorch tensors representing the real and imaginary components of the second complex-valued embedding.
      :type C_2: Tuple[torch.Tensor, torch.Tensor]

      :returns: A tuple of two tensors, representing the real and imaginary parts of the convolutionally transformed embeddings.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor]

      .. rubric:: Notes

      The method involves concatenating the real and imaginary components of the embeddings, applying a 2D convolution,
      followed by batch normalization, ReLU activation, dropout, and a fully connected layer. This process is intended to
      capture complex interactions between the embeddings in a convolutional manner.


   .. py:method:: forward_k_vs_all(x: torch.Tensor) -> torch.FloatTensor

      Computes scores in a K-vs-All setting using convolutional operations on complex-valued embeddings.
      This method is used for evaluating the performance of the model by computing scores for each head entity
      and relation pair against all possible tail entities.

      :param x: A tensor representing a batch of head entities and relations. Expected tensor shape: (n, 2),
                where 'n' is the batch size and '2' represents head entity and relation pairs.
      :type x: torch.Tensor

      :returns: A tensor containing the scores for each head entity and relation pair against all possible tail entities.
                Tensor shape: (n, |E|), where '|E|' is the number of entities in the knowledge graph.
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      The method retrieves embeddings for head entities and relations, splits them into real and imaginary parts,
      and applies a convolution operation. It then computes the Hermitian product of the transformed embeddings
      with all tail entity embeddings to generate scores. This approach allows for capturing complex relational patterns
      in the knowledge graph.


   .. py:method:: forward_triples(x: torch.Tensor) -> torch.FloatTensor

      Computes scores for a batch of triples using convolutional operations on complex-valued embeddings.
      This method is crucial for evaluating the performance of the model on individual triples in the
      knowledge graph.

      :param x: A tensor representing a batch of triples. Each triple consists of indices for a head entity,
                a relation, and a tail entity. Expected tensor shape: (n, 3), where 'n' is the number of triples.
      :type x: torch.Tensor

      :returns: A tensor containing the scores for each triple in the batch. Tensor shape: (n,), where 'n'
                is the number of triples.
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      The method retrieves embeddings for head entities, relations, and tail entities, and splits them
      into real and imaginary parts. It then applies a convolution operation on these embeddings and
      computes the Hermitian inner product, which involves a combination of real and imaginary parts
      of the embeddings. This process is designed to capture complex relational patterns and interactions
      within the knowledge graph, leveraging the power of convolutional neural networks.


   .. py:method:: forward_k_vs_sample(x: torch.Tensor, target_entity_idx: torch.Tensor) -> torch.Tensor

      Computes scores against a sampled subset of entities using convolutional operations
      on complex-valued embeddings. This method is particularly useful for large knowledge graphs
      where computing scores against all entities is computationally expensive.

      :param x: A tensor representing a batch of head entities and relations. Expected tensor shape:
                (batch_size, 2), where 'batch_size' is the number of head entity and relation pairs.
      :type x: torch.Tensor
      :param target_entity_idx: A tensor of target entity indices for sampling. Tensor shape:
                                (batch_size, num_selected_entities).
      :type target_entity_idx: torch.Tensor

      :returns: A tensor containing the scores for each head entity and relation pair against the sampled
                subset of tail entities. Tensor shape: (batch_size, num_selected_entities).
      :rtype: torch.Tensor

      .. rubric:: Notes

      The method first retrieves and processes the embeddings for head entities and relations. It then
      applies a convolution operation and computes the Hermitian inner product with the embeddings of
      the sampled tail entities. This process enables capturing complex relational patterns in a
      computationally efficient manner.



.. py:class:: AConEx(args)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   AConEx (Additive Convolutional ComplEx) extends the ConEx model by incorporating
   additive connections in the convolutional operations. This model integrates
   convolutional neural networks with complex-valued embeddings, emphasizing
   additive feature interactions for knowledge graph embeddings.

   :param args: A dictionary of arguments containing hyperparameters and settings for the model,
                such as embedding dimensions, kernel size, number of output channels, and dropout rates.
   :type args: dict

   .. attribute:: name

      The name identifier for the AConEx model.

      :type: str

   .. attribute:: conv2d

      A 2D convolutional layer used for processing complex-valued embeddings.

      :type: torch.nn.Conv2d

   .. attribute:: fc_num_input

      The number of input features for the fully connected layer.

      :type: int

   .. attribute:: fc1

      A fully connected linear layer for compressing the output of the
      convolutional layer.

      :type: torch.nn.Linear

   .. attribute:: norm_fc1

      Normalization layer applied after the fully connected layer.

      :type: Normalizer

   .. attribute:: bn_conv2d

      Batch normalization layer applied after the convolutional operation.

      :type: torch.nn.BatchNorm2d

   .. attribute:: feature_map_dropout

      Dropout layer applied to the output of the convolutional layer.

      :type: torch.nn.Dropout2d

   .. method:: residual_convolution(C_1: Tuple[torch.Tensor, torch.Tensor],

                       C_2: Tuple[torch.Tensor, torch.Tensor]) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]
      Performs a residual convolution operation on two complex-valued embeddings.

   .. method:: forward_k_vs_all(x: torch.Tensor) -> torch.FloatTensor

      Computes scores in a K-vs-All setting using convolutional operations on embeddings.

   .. method:: forward_triples(x: torch.Tensor) -> torch.FloatTensor

      Computes scores for a batch of triples using convolutional operations.

   .. method:: forward_k_vs_sample(x: torch.Tensor, target_entity_idx: torch.Tensor)

      Computes scores against a sampled subset of entities using convolutional operations.


   .. rubric:: Notes

   AConEx aims to enhance the modeling capabilities of knowledge graph embeddings
   by adding more complex interaction patterns through convolutional layers, potentially
   improving performance on tasks like link prediction.

   .. py:method:: residual_convolution(C_1: Tuple[torch.Tensor, torch.Tensor], C_2: Tuple[torch.Tensor, torch.Tensor]) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      Computes the residual convolution of two complex-valued embeddings. This method
      is a core part of the AConEx model, applying convolutional neural network techniques
      to complex-valued embeddings to capture intricate relationships in the data.

      :param C_1: A tuple of two PyTorch tensors representing the real and imaginary components
                  of the first complex-valued embedding.
      :type C_1: Tuple[torch.Tensor, torch.Tensor]
      :param C_2: A tuple of two PyTorch tensors representing the real and imaginary components
                  of the second complex-valued embedding.
      :type C_2: Tuple[torch.Tensor, torch.Tensor]

      :returns: A tuple of four tensors, each representing a component of the convolutionally
                transformed embeddings. These components correspond to the modified real
                and imaginary parts of the input embeddings.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      .. rubric:: Notes

      The method concatenates the real and imaginary components of the embeddings and
      applies a 2D convolution, followed by batch normalization, ReLU activation, dropout,
      and a fully connected layer. This convolutional process is designed to enhance
      the model's ability to capture complex patterns in knowledge graph embeddings.


   .. py:method:: forward_k_vs_all(x: torch.Tensor) -> torch.FloatTensor

      Computes scores in a K-vs-All setting using convolutional and additive operations on
      complex-valued embeddings. This method evaluates the performance of the model by computing
      scores for each head entity and relation pair against all possible tail entities.

      :param x: A tensor representing a batch of head entities and relations. Expected tensor shape:
                (batch_size, 2), where 'batch_size' is the number of head entity and relation pairs.
      :type x: torch.Tensor

      :returns: A tensor containing the scores for each head entity and relation pair against all possible
                tail entities. Tensor shape: (batch_size, |E|), where '|E|' is the number of entities
                in the knowledge graph.
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      The method first retrieves embeddings for head entities and relations, splits them into real
      and imaginary parts, and applies a convolutional operation. It then computes the Hermitian
      inner product with all tail entity embeddings, using an additive approach that combines the
      convolutional results with the original embeddings. This technique aims to capture complex
      relational patterns in the knowledge graph.


   .. py:method:: forward_triples(x: torch.Tensor) -> torch.FloatTensor

      Computes scores for a batch of triples using convolutional operations and additive connections
      on complex-valued embeddings. This method is key for evaluating the model's performance on
      individual triples within the knowledge graph.

      :param x: A tensor representing a batch of triples. Each triple consists of indices for a head entity,
                a relation, and a tail entity. Expected tensor shape: (n, 3), where 'n' is the number of triples.
      :type x: torch.Tensor

      :returns: A tensor containing the scores for each triple in the batch. Tensor shape: (n,), where 'n'
                is the number of triples.
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      The method retrieves embeddings for head entities, relations, and tail entities, and splits them
      into real and imaginary parts. It then applies a convolution operation on these embeddings and
      computes the Hermitian inner product, enhanced with an additive connection. This approach allows
      the model to capture complex relational patterns within the knowledge graph, potentially improving
      prediction accuracy and interpretability.


   .. py:method:: forward_k_vs_sample(x: torch.Tensor, target_entity_idx: torch.Tensor) -> torch.FloatTensor

      Computes scores for a batch of samples (entity pairs) given a batch of queries. This method is used
      to predict the scores for different tail entities for a set of query triples.

      :param x: A tensor representing a batch of query triples. Each triple consists of indices for a head entity,
                a relation, and a dummy tail entity (used for scoring). Expected tensor shape: (n, 3), where 'n' is
                the number of query triples.
      :type x: torch.Tensor
      :param target_entity_idx: A tensor containing the indices of the target tail entities for which scores are to be predicted.
                                Expected tensor shape: (n, m), where 'n' is the number of queries and 'm' is the number of target
                                entities.
      :type target_entity_idx: torch.Tensor

      :returns: A tensor containing the scores for each query-triple and target-entity pair. Tensor shape: (n, m),
                where 'n' is the number of queries and 'm' is the number of target entities.
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      This method retrieves embeddings for the head entities and relations in the query triples, splits them
      into real and imaginary parts, and applies convolutional operations with additive connections to capture
      complex patterns. It also retrieves embeddings for the target tail entities and computes Hermitian inner
      products to obtain scores, allowing the model to rank the tail entities based on their relevance to the queries.



.. py:class:: ComplEx(args: dict)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   ComplEx (Complex Embeddings for Knowledge Graphs) is a model that extends
   the base knowledge graph embedding approach by using complex-valued embeddings.
   It emphasizes the interaction of real and imaginary components of embeddings
   to capture the asymmetric relationships often found in knowledge graphs.

   :param args: A dictionary of arguments containing hyperparameters and settings for the model,
                such as embedding dimensions, learning rate, and regularization methods.
   :type args: dict

   .. attribute:: name

      The name identifier for the ComplEx model.

      :type: str

   .. method:: score(head_ent_emb: torch.FloatTensor, rel_ent_emb: torch.FloatTensor,

        tail_ent_emb: torch.FloatTensor) -> torch.FloatTensor
      Computes the score of a triple using the ComplEx scoring function.


   .. method:: k_vs_all_score(emb_h: torch.FloatTensor, emb_r: torch.FloatTensor,

                 emb_E: torch.FloatTensor) -> torch.FloatTensor
      Computes scores in a K-vs-All setting using complex-valued embeddings.


   .. method:: forward_k_vs_all(x: torch.LongTensor) -> torch.FloatTensor

      Performs a forward pass for K-vs-All scoring, returning scores for all entities.


   .. rubric:: Notes

   ComplEx is particularly suited for modeling asymmetric relations and has been
   shown to perform well on various knowledge graph benchmarks. The use of complex
   numbers allows the model to encode additional information compared to real-valued models.

   .. py:method:: score(head_ent_emb: torch.FloatTensor, rel_ent_emb: torch.FloatTensor, tail_ent_emb: torch.FloatTensor) -> torch.FloatTensor
      :staticmethod:

      Compute the scoring function for a given triple using complex-valued embeddings.

      :param head_ent_emb: The complex embedding of the head entity.
      :type head_ent_emb: torch.FloatTensor
      :param rel_ent_emb: The complex embedding of the relation.
      :type rel_ent_emb: torch.FloatTensor
      :param tail_ent_emb: The complex embedding of the tail entity.
      :type tail_ent_emb: torch.FloatTensor

      :returns: The score of the triple calculated using the Hermitian dot product of complex embeddings.
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      The scoring function exploits the complex vector space to model the interactions
      between entities and relations. It involves element-wise multiplication and
      summation of real and imaginary parts.


   .. py:method:: k_vs_all_score(emb_h: torch.FloatTensor, emb_r: torch.FloatTensor, emb_E: torch.FloatTensor) -> torch.FloatTensor
      :staticmethod:

      Compute scores for a head entity and relation against all entities in a K-vs-All scenario.

      :param emb_h: The complex embedding of the head entity.
      :type emb_h: torch.FloatTensor
      :param emb_r: The complex embedding of the relation.
      :type emb_r: torch.FloatTensor
      :param emb_E: The complex embeddings of all possible tail entities.
      :type emb_E: torch.FloatTensor

      :returns: Scores for all possible triples formed with the given head entity and relation.
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      This method is useful for tasks like link prediction where the model predicts
      the likelihood of a relation between a given entity pair.


   .. py:method:: forward_k_vs_all(x: torch.LongTensor) -> torch.FloatTensor

      Perform a forward pass for K-vs-all scoring using complex-valued embeddings.

      :param x: Tensor containing indices for head entities and relations.
      :type x: torch.LongTensor

      :returns: Scores for all triples formed with the given head entities and relations against all entities.
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      This method is typically used in training and evaluation of the model in a
      link prediction setting, where the goal is to rank all possible tail entities
      for a given head entity and relation.



.. py:function:: quaternion_mul(*, Q_1: Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor], Q_2: Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]

   Perform quaternion multiplication.

   This function multiplies two quaternions, Q_1 and Q_2, and returns the result as a quaternion.
   Quaternion multiplication is a non-commutative operation used in various applications,
   including 3D rotation and orientation tasks.

   :param Q_1: The first quaternion, represented as a tuple of four components (a_h, b_h, c_h, d_h).
   :type Q_1: Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]
   :param Q_2: The second quaternion, represented as a tuple of four components (a_r, b_r, c_r, d_r).
   :type Q_2: Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]

   :returns: The resulting quaternion from the multiplication, represented as a tuple of four components (r_val, i_val, j_val, k_val).
   :rtype: Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]

   .. rubric:: Notes

   The quaternion multiplication is defined as:
   r_val = a_h * a_r - b_h * b_r - c_h * c_r - d_h * d_r
   i_val = a_h * b_r + b_h * a_r + c_h * d_r - d_h * c_r
   j_val = a_h * c_r - b_h * d_r + c_h * a_r + d_h * b_r
   k_val = a_h * d_r + b_h * c_r - c_h * b_r + d_h * a_r


.. py:class:: BaseKGE(args: dict)


   Bases: :py:obj:`BaseKGELightning`

   Base class for all neural network modules.

   Your models should also subclass this class.

   Modules can also contain other Modules, allowing to nest them in
   a tree structure. You can assign the submodules as regular attributes::

       import torch.nn as nn
       import torch.nn.functional as F

       class Model(nn.Module):
           def __init__(self):
               super().__init__()
               self.conv1 = nn.Conv2d(1, 20, 5)
               self.conv2 = nn.Conv2d(20, 20, 5)

           def forward(self, x):
               x = F.relu(self.conv1(x))
               return F.relu(self.conv2(x))

   Submodules assigned in this way will be registered, and will have their
   parameters converted too when you call :meth:`to`, etc.

   .. note::
       As per the example above, an ``__init__()`` call to the parent class
       must be made before assignment on the child.

   :ivar training: Boolean represents whether this module is in training or
                   evaluation mode.
   :vartype training: bool

   .. py:method:: forward_byte_pair_encoded_k_vs_all(x: torch.LongTensor)

      :param x:
      :type x: B x 2 x T


   .. py:method:: forward_byte_pair_encoded_triple(x: Tuple[torch.LongTensor, torch.LongTensor])

      Perform the forward pass for byte pair encoded triples.

      :param x: The input tuple containing byte pair encoded entities and relations.
      :type x: Tuple[torch.LongTensor, torch.LongTensor]

      :returns: The output tensor containing the scores for the byte pair encoded triples.
      :rtype: torch.Tensor


   .. py:method:: init_params_with_sanity_checking()


   .. py:method:: forward(x: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]], y_idx: torch.LongTensor = None)

      Perform the forward pass of the model.

      :param x: The input tensor or a tuple containing the input tensor and target entity indexes.
      :type x: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]]
      :param y_idx: The target entity indexes (default is None).
      :type y_idx: torch.LongTensor, optional

      :returns: The output of the forward pass.
      :rtype: Any


   .. py:method:: forward_triples(x: torch.LongTensor) -> torch.Tensor

      Perform the forward pass for triples.

      :param x: The input tensor containing the indexes of head, relation, and tail entities.
      :type x: torch.LongTensor

      :returns: The output tensor containing the scores for the input triples.
      :rtype: torch.Tensor


   .. py:method:: forward_k_vs_all(*args, **kwargs)

      Forward pass for K vs. All.

      :raises ValueError: This function is not implemented in the current model.


   .. py:method:: forward_k_vs_sample(*args, **kwargs)

      Forward pass for K vs. Sample.

      :raises ValueError: This function is not implemented in the current model.


   .. py:method:: get_triple_representation(idx_hrt)


   .. py:method:: get_head_relation_representation(indexed_triple: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor]

      Get the representation for the head and relation entities.

      :param indexed_triple: The indexes of the head and relation entities.
      :type indexed_triple: torch.LongTensor

      :returns: The representation for the head and relation entities.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_sentence_representation(x: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      Get the representation for a sentence.

      :param x: The input tensor containing the indexes of head, relation, and tail entities.
      :type x: torch.LongTensor

      :returns: The representation for the input sentence.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_bpe_head_and_relation_representation(x: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor]

      Get the representation for BPE head and relation entities.

      :param x:
      :type x: B x 2 x T

      :returns: The representation for BPE head and relation entities.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_embeddings() -> Tuple[numpy.ndarray, numpy.ndarray]

      Get the entity and relation embeddings.

      :returns: The entity and relation embeddings.
      :rtype: Tuple[np.ndarray, np.ndarray]



.. py:class:: IdentityClass(args: Optional[Dict] = None)


   Bases: :py:obj:`torch.nn.Module`

   A class that represents an identity function.

   :param args: A dictionary containing arguments (default is None).
   :type args: dict, optional

   .. py:method:: __call__(x)


   .. py:method:: forward(x: torch.Tensor) -> torch.Tensor
      :staticmethod:

      The forward pass of the identity function.

      :param x: The input tensor.
      :type x: torch.Tensor

      :returns: The output tensor, which is the same as the input.
      :rtype: torch.Tensor



.. py:function:: quaternion_mul_with_unit_norm(*, Q_1: Tuple[float, float, float, float], Q_2: Tuple[float, float, float, float]) -> Tuple[float, float, float, float]

   Performs the multiplication of two quaternions with unit norm.

   :param Q_1: The first quaternion represented as a tuple of four real numbers (a_h, b_h, c_h, d_h).
   :type Q_1: Tuple[float, float, float, float]
   :param Q_2: The second quaternion represented as a tuple of four real numbers (a_r, b_r, c_r, d_r).
   :type Q_2: Tuple[float, float, float, float]

   :returns: The result of the quaternion multiplication, represented as a tuple of four real numbers (r_val, i_val, j_val, k_val).
   :rtype: Tuple[float, float, float, float]

   .. rubric:: Notes

   The function assumes that the input quaternions have unit norm.
   It first normalizes the second quaternion to eliminate the scaling effect, and then performs the Hamilton product of the two quaternions.


.. py:class:: QMult(args: dict)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   QMult extends the base knowledge graph embedding model by integrating quaternion
   algebra. This model leverages the properties of quaternions to represent and process
   the embeddings of entities and relations in a knowledge graph, aiming to capture
   complex interactions and patterns.

   :param args: A dictionary of arguments containing hyperparameters and settings for the model,
                such as embedding dimensions and learning rate.
   :type args: dict

   .. attribute:: name

      The name identifier for the QMult model.

      :type: str

   .. method:: quaternion_normalizer(x: torch.FloatTensor) -> torch.FloatTensor

      Normalizes the length of relation vectors.


   .. method:: score(head_ent_emb: torch.FloatTensor, rel_ent_emb: torch.FloatTensor, tail_ent_emb: torch.FloatTensor) -> torch.FloatTensor

      Computes the score of a triple using quaternion multiplication.


   .. method:: k_vs_all_score(bpe_head_ent_emb: torch.FloatTensor, bpe_rel_ent_emb: torch.FloatTensor, E: torch.FloatTensor) -> torch.FloatTensor

      Computes scores in a K-vs-All setting using quaternion embeddings.


   .. method:: forward_k_vs_all(x: torch.FloatTensor) -> torch.FloatTensor

      Performs a forward pass for K-vs-All scoring, returning scores for all entities.


   .. method:: forward_k_vs_sample(x: torch.FloatTensor, target_entity_idx: int) -> torch.FloatTensor

      Performs a forward pass for K-vs-Sample scoring, returning scores for the specified entities.


   .. method:: quaternion_multiplication_followed_by_inner_product(h: torch.FloatTensor, r: torch.FloatTensor, t: torch.FloatTensor) -> torch.FloatTensor

      Performs quaternion multiplication followed by inner product, returning triple scores.


   .. py:method:: quaternion_multiplication_followed_by_inner_product(h: torch.FloatTensor, r: torch.FloatTensor, t: torch.FloatTensor) -> torch.FloatTensor

      Performs quaternion multiplication followed by inner product.

      :param h: The head representations. Shape: (`*batch_dims`, dim)
      :type h: torch.FloatTensor
      :param r: The relation representations. Shape: (`*batch_dims`, dim)
      :type r: torch.FloatTensor
      :param t: The tail representations. Shape: (`*batch_dims`, dim)
      :type t: torch.FloatTensor

      :returns: Triple scores.
      :rtype: torch.FloatTensor


   .. py:method:: quaternion_normalizer(x: torch.FloatTensor) -> torch.FloatTensor
      :staticmethod:

      TODO: Add mathematical format for sphinx.
      Normalize the length of relation vectors, if the forward constraint has not been applied yet.

      The absolute value of a quaternion is calculated as follows:
      .. math::

          |a + bi + cj + dk| = \sqrt{a^2 + b^2 + c^2 + d^2}

      The L2 norm of a quaternion vector is computed as:
      .. math::
          \|x\|^2 = \sum_{i=1}^d |x_i|^2
                   = \sum_{i=1}^d (x_i.re^2 + x_i.im_1^2 + x_i.im_2^2 + x_i.im_3^2)
      :param x: The vector containing quaternion values.
      :type x: torch.FloatTensor

      :returns: The normalized vector.
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      This function normalizes the length of relation vectors represented as quaternions. It ensures that
      the absolute value of each quaternion in the vector is equal to 1, preserving the unit length.


   .. py:method:: score(head_ent_emb: torch.FloatTensor, rel_ent_emb: torch.FloatTensor, tail_ent_emb: torch.FloatTensor) -> torch.FloatTensor

      Compute scores for a batch of triples using octonion-based embeddings.

      This method computes scores for a batch of triples using octonion-based embeddings of head entities,
      relation embeddings, and tail entities. It supports both explicit and non-explicit scoring methods.

      :param head_ent_emb: Tensor containing the octonion-based embeddings of head entities.
      :type head_ent_emb: torch.FloatTensor
      :param rel_ent_emb: Tensor containing the octonion-based embeddings of relations.
      :type rel_ent_emb: torch.FloatTensor
      :param tail_ent_emb: Tensor containing the octonion-based embeddings of tail entities.
      :type tail_ent_emb: torch.FloatTensor

      :returns: Scores for the given batch of triples.
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      If no normalization is set, this method applies quaternion normalization to relation embeddings.

      If the scoring method is explicit, it computes the scores using quaternion multiplication followed by
      an inner product of the real and imaginary parts of the resulting quaternions.

      If the scoring method is non-explicit, it directly computes the inner product of the real and
      imaginary parts of the octonion-based embeddings.


   .. py:method:: k_vs_all_score(bpe_head_ent_emb: torch.FloatTensor, bpe_rel_ent_emb: torch.FloatTensor, E: torch.FloatTensor) -> torch.FloatTensor

      Computes scores in a K-vs-All setting using quaternion embeddings for a batch of head entities and relations.

      This method involves splitting the head entity and relation embeddings into quaternion components,
      optionally normalizing the relation embeddings, performing quaternion multiplication, and then
      calculating the score by performing an inner product with all tail entity embeddings.

      :param bpe_head_ent_emb: Batched embeddings of head entities, each represented as a quaternion.
      :type bpe_head_ent_emb: torch.FloatTensor
      :param bpe_rel_ent_emb: Batched embeddings of relations, each represented as a quaternion.
      :type bpe_rel_ent_emb: torch.FloatTensor
      :param E: Embeddings of all possible tail entities.
      :type E: torch.FloatTensor

      :returns: Scores for all possible triples formed with the given head entities and relations against all entities.
                The shape of the output is (size of batch, number of entities).
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      The method is particularly useful in scenarios like link prediction, where the goal is to rank all possible
      tail entities for a given head entity and relation. Quaternion algebra is used to enhance the interaction
      modeling between entities and relations.


   .. py:method:: forward_k_vs_all(x: torch.FloatTensor) -> torch.FloatTensor

      Computes scores for all entities in a K-vs-All setting given a batch of head entities and relations.

      This method retrieves embeddings for the head entities and relations from the input tensor `x`,
      applies necessary dropout and normalization, and then uses the `k_vs_all_score` method to compute
      the scores against all possible tail entities in the knowledge graph.

      :param x: A tensor containing indices for head entities and relations. The tensor is expected to have
                a specific format suitable for the model's embedding retrieval process.
      :type x: torch.FloatTensor

      :returns: A tensor of scores, where each row corresponds to the scores of all tail entities for a
                single head entity and relation pair. The shape of the tensor is (size of the batch, number of entities).
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      This method is typically used in evaluating the model's performance in link prediction tasks,
      where it's important to rank the likelihood of every possible tail entity for a given head entity
      and relation.


   .. py:method:: forward_k_vs_sample(x: torch.FloatTensor, target_entity_idx: int) -> torch.FloatTensor

      Computes scores for a batch of triples against a sampled subset of entities in a K-vs-Sample setting.

      Given a batch of head entities and relations (h,r), this method computes the scores for all possible triples
      formed with these head entities and relations against a subset of entities, i.e.,
      [score(h,r,x)|x \in Entities] => [0.0,0.1,...,0.8], shape=> (1, |Entities|). TODO: Add mathematical format for sphinx.
      The subset of entities is specified by the `target_entity_idx`, which is an integer index representing a specific entity.
      Given a batch of head entities and relations => shape (size of batch,| Entities|).

      :param x: A tensor containing indices for head entities and relations. The tensor is expected to have
                a specific format suitable for the model's embedding retrieval process.
      :type x: torch.FloatTensor
      :param target_entity_idx: Index of the target entity against which the scores are to be computed.
      :type target_entity_idx: int

      :returns: A tensor of scores where each element corresponds to the score of the target entity
                for a single head entity and relation pair. The shape of the tensor is (size of the batch, 1).
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      This method is particularly useful in scenarios like link prediction, where it's necessary to
      evaluate the likelihood of a specific relationship between a given head entity and a particular
      target entity.



.. py:class:: ConvQ(args)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   Convolutional Quaternion Knowledge Graph Embeddings (ConvQ) is a model that extends
   the base knowledge graph embedding approach by using quaternion algebra and convolutional
   neural networks. This model aims to capture complex interactions in knowledge graphs
   by applying convolutions to quaternion-based entity and relation embeddings.

   :param args: A dictionary of arguments containing hyperparameters and settings for the model,
                such as embedding dimensions, number of output channels, kernel size, and dropout rates.
   :type args: dict

   .. attribute:: name

      The name identifier for the ConvQ model.

      :type: str

   .. attribute:: entity_embeddings

      Embedding layer for entities in the knowledge graph.

      :type: torch.nn.Embedding

   .. attribute:: relation_embeddings

      Embedding layer for relations in the knowledge graph.

      :type: torch.nn.Embedding

   .. attribute:: conv2d

      A 2D convolutional layer used for processing quaternion embeddings.

      :type: torch.nn.Conv2d

   .. attribute:: fc_num_input

      The number of input features for the fully connected layer.

      :type: int

   .. attribute:: fc1

      A fully connected linear layer for compressing the output of the convolutional layer.

      :type: torch.nn.Linear

   .. attribute:: bn_conv1

      First batch normalization layer applied after the convolutional operation.

      :type: torch.nn.BatchNorm2d

   .. attribute:: bn_conv2

      Second normalization layer applied after the fully connected layer.

      :type: Normalizer

   .. attribute:: feature_map_dropout

      Dropout layer applied to the output of the convolutional layer.

      :type: torch.nn.Dropout2d

   .. method:: residual_convolution(Q_1, Q_2)

      Performs a residual convolution operation on two sets of quaternion embeddings.


   .. method:: forward_triples(indexed_triple: torch.FloatTensor) -> torch.FloatTensor

      Computes scores for a batch of triples using convolutional operations on quaternion embeddings.


   .. method:: forward_k_vs_all(x: torch.FloatTensor) -> torch.FloatTensor

      Computes scores for all entities in a K-vs-All setting given a batch of head entities and relations.


   .. rubric:: Notes

   ConvQ leverages the properties of quaternions, a number system that extends complex numbers,
   to represent and process the embeddings of entities and relations. The convolutional layers
   aim to capture spatial relationships and complex patterns in the embeddings.

   .. py:method:: residual_convolution(Q_1: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor], Q_2: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      Performs a residual convolution operation on two sets of quaternion embeddings.

      The method combines two quaternion embeddings and applies a convolutional operation
      followed by batch normalization, dropout, and a fully connected layer.

      :param Q_1: The first set of quaternion embeddings.
      :type Q_1: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]
      :param Q_2: The second set of quaternion embeddings.
      :type Q_2: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      :returns: The resulting quaternion embeddings after the convolutional operation.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]


   .. py:method:: forward_triples(indexed_triple: torch.FloatTensor) -> torch.FloatTensor

      Computes scores for a batch of triples using convolutional operations on quaternion embeddings.

      The method processes head, relation, and tail embeddings using quaternion algebra and
      convolutional layers and computes the scores of the triples.

      :param indexed_triple: Tensor containing indices for head entities, relations, and tail entities.
      :type indexed_triple: torch.FloatTensor

      :returns: Scores for the given batch of triples.
      :rtype: torch.FloatTensor


   .. py:method:: forward_k_vs_all(x: torch.FloatTensor) -> torch.FloatTensor

      Computes scores for all entities in a K-vs-All setting given a batch of head entities and relations.

      This method retrieves embeddings for the head entities and relations from the input tensor `x`,
      applies necessary dropout and normalization, and then computes scores against all entities in
      the knowledge graph.

      :param x: A tensor containing indices for head entities and relations.
      :type x: torch.FloatTensor

      :returns: Scores for all entities for the given batch of head entities and relations.
      :rtype: torch.FloatTensor



.. py:class:: AConvQ(args)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   Additive Convolutional Quaternion Knowledge Graph Embeddings (AConvQ) model integrates
   quaternion algebra with convolutional neural networks for knowledge graph embeddings.
   This model is designed to capture complex interactions in knowledge graphs by applying
   additive convolutions to quaternion-based entity and relation embeddings.

   .. attribute:: name

      The name identifier for the AConvQ model.

      :type: str

   .. attribute:: entity_embeddings

      Embedding layer for entities in the knowledge graph.

      :type: torch.nn.Embedding

   .. attribute:: relation_embeddings

      Embedding layer for relations in the knowledge graph.

      :type: torch.nn.Embedding

   .. attribute:: conv2d

      A 2D convolutional layer used for processing quaternion embeddings.

      :type: torch.nn.Conv2d

   .. attribute:: fc_num_input

      The number of input features for the fully connected layer.

      :type: int

   .. attribute:: fc1

      A fully connected linear layer for compressing the output of the convolutional layer.

      :type: torch.nn.Linear

   .. attribute:: bn_conv1

      Batch normalization layer applied after the convolutional operation.

      :type: torch.nn.BatchNorm2d

   .. attribute:: bn_conv2

      Normalization layer applied after the fully connected layer.

      :type: Normalizer

   .. attribute:: feature_map_dropout

      Dropout layer applied to the output of the convolutional layer.

      :type: torch.nn.Dropout2d

   .. method:: residual_convolution(Q_1, Q_2)

      Performs an additive residual convolution operation on two sets of quaternion embeddings.


   .. method:: forward_triples(indexed_triple: torch.FloatTensor) -> torch.FloatTensor

      Computes scores for a batch of triples using additive convolutional operations on quaternion embeddings.


   .. method:: forward_k_vs_all(x: torch.FloatTensor) -> torch.FloatTensor

      Computes scores for all entities in a K-vs-All setting given a batch of head entities and relations.


   .. py:method:: residual_convolution(Q_1: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor], Q_2: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      Performs a residual convolution operation on two sets of quaternion embeddings.

      The method combines two quaternion embeddings and applies a convolutional operation
      followed by batch normalization, dropout, and a fully connected layer.

      :param Q_1: The first set of quaternion embeddings.
      :type Q_1: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]
      :param Q_2: The second set of quaternion embeddings.
      :type Q_2: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      :returns: The resulting quaternion embeddings after the convolutional operation.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]


   .. py:method:: forward_triples(indexed_triple: torch.FloatTensor) -> torch.FloatTensor

      Computes scores for a batch of triples using convolutional operations on quaternion embeddings.

      The method processes head, relation, and tail embeddings using quaternion algebra and
      convolutional layers and computes the scores of the triples.

      :param indexed_triple: Tensor containing indices for head entities, relations, and tail entities.
      :type indexed_triple: torch.FloatTensor

      :returns: Scores for the given batch of triples.
      :rtype: torch.FloatTensor


   .. py:method:: forward_k_vs_all(x: torch.FloatTensor) -> torch.FloatTensor

      Computes scores for all entities in a K-vs-All setting given a batch of head entities and relations.

      This method retrieves embeddings for the head entities and relations from the input tensor `x`,
      applies necessary dropout and normalization, and then computes scores against all entities in
      the knowledge graph.

      :param x: A tensor containing indices for head entities and relations.
      :type x: torch.FloatTensor

      :returns: Scores for all entities for the given batch of head entities and relations.
      :rtype: torch.FloatTensor



.. py:class:: BaseKGE(args: dict)


   Bases: :py:obj:`BaseKGELightning`

   Base class for all neural network modules.

   Your models should also subclass this class.

   Modules can also contain other Modules, allowing to nest them in
   a tree structure. You can assign the submodules as regular attributes::

       import torch.nn as nn
       import torch.nn.functional as F

       class Model(nn.Module):
           def __init__(self):
               super().__init__()
               self.conv1 = nn.Conv2d(1, 20, 5)
               self.conv2 = nn.Conv2d(20, 20, 5)

           def forward(self, x):
               x = F.relu(self.conv1(x))
               return F.relu(self.conv2(x))

   Submodules assigned in this way will be registered, and will have their
   parameters converted too when you call :meth:`to`, etc.

   .. note::
       As per the example above, an ``__init__()`` call to the parent class
       must be made before assignment on the child.

   :ivar training: Boolean represents whether this module is in training or
                   evaluation mode.
   :vartype training: bool

   .. py:method:: forward_byte_pair_encoded_k_vs_all(x: torch.LongTensor)

      :param x:
      :type x: B x 2 x T


   .. py:method:: forward_byte_pair_encoded_triple(x: Tuple[torch.LongTensor, torch.LongTensor])

      Perform the forward pass for byte pair encoded triples.

      :param x: The input tuple containing byte pair encoded entities and relations.
      :type x: Tuple[torch.LongTensor, torch.LongTensor]

      :returns: The output tensor containing the scores for the byte pair encoded triples.
      :rtype: torch.Tensor


   .. py:method:: init_params_with_sanity_checking()


   .. py:method:: forward(x: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]], y_idx: torch.LongTensor = None)

      Perform the forward pass of the model.

      :param x: The input tensor or a tuple containing the input tensor and target entity indexes.
      :type x: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]]
      :param y_idx: The target entity indexes (default is None).
      :type y_idx: torch.LongTensor, optional

      :returns: The output of the forward pass.
      :rtype: Any


   .. py:method:: forward_triples(x: torch.LongTensor) -> torch.Tensor

      Perform the forward pass for triples.

      :param x: The input tensor containing the indexes of head, relation, and tail entities.
      :type x: torch.LongTensor

      :returns: The output tensor containing the scores for the input triples.
      :rtype: torch.Tensor


   .. py:method:: forward_k_vs_all(*args, **kwargs)

      Forward pass for K vs. All.

      :raises ValueError: This function is not implemented in the current model.


   .. py:method:: forward_k_vs_sample(*args, **kwargs)

      Forward pass for K vs. Sample.

      :raises ValueError: This function is not implemented in the current model.


   .. py:method:: get_triple_representation(idx_hrt)


   .. py:method:: get_head_relation_representation(indexed_triple: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor]

      Get the representation for the head and relation entities.

      :param indexed_triple: The indexes of the head and relation entities.
      :type indexed_triple: torch.LongTensor

      :returns: The representation for the head and relation entities.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_sentence_representation(x: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      Get the representation for a sentence.

      :param x: The input tensor containing the indexes of head, relation, and tail entities.
      :type x: torch.LongTensor

      :returns: The representation for the input sentence.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_bpe_head_and_relation_representation(x: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor]

      Get the representation for BPE head and relation entities.

      :param x:
      :type x: B x 2 x T

      :returns: The representation for BPE head and relation entities.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_embeddings() -> Tuple[numpy.ndarray, numpy.ndarray]

      Get the entity and relation embeddings.

      :returns: The entity and relation embeddings.
      :rtype: Tuple[np.ndarray, np.ndarray]



.. py:class:: IdentityClass(args: Optional[Dict] = None)


   Bases: :py:obj:`torch.nn.Module`

   A class that represents an identity function.

   :param args: A dictionary containing arguments (default is None).
   :type args: dict, optional

   .. py:method:: __call__(x)


   .. py:method:: forward(x: torch.Tensor) -> torch.Tensor
      :staticmethod:

      The forward pass of the identity function.

      :param x: The input tensor.
      :type x: torch.Tensor

      :returns: The output tensor, which is the same as the input.
      :rtype: torch.Tensor



.. py:function:: octonion_mul(*, O_1: Tuple[float, float, float, float, float, float, float, float], O_2: Tuple[float, float, float, float, float, float, float, float]) -> Tuple[float, float, float, float, float, float, float, float]

   Performs the multiplication of two octonions.

   Octonions are an extension of quaternions and are represented here as 8-tuples of floats.
   This function computes the product of two octonions using their components.

   :param O_1: The first octonion, represented as an 8-tuple of float components.
   :type O_1: Tuple[float, float, float, float, float, float, float, float]
   :param O_2: The second octonion, represented as an 8-tuple of float components.
   :type O_2: Tuple[float, float, float, float, float, float, float, float]

   :returns: The product of the two octonions, represented as an 8-tuple of float components.
   :rtype: Tuple[float, float, float, float, float, float, float, float]


.. py:function:: octonion_mul_norm(*, O_1: Tuple[float, float, float, float, float, float, float, float], O_2: Tuple[float, float, float, float, float, float, float, float]) -> Tuple[float, float, float, float, float, float, float, float]

   Performs the normalized multiplication of two octonions.

   This function first normalizes the second octonion to unit length to eliminate
   the scaling effect and then computes the product of two octonions using their components.

   :param O_1: The first octonion, represented as an 8-tuple of float components.
   :type O_1: Tuple[float, float, float, float, float, float, float, float]
   :param O_2: The second octonion, represented as an 8-tuple of float components.
   :type O_2: Tuple[float, float, float, float, float, float, float, float]

   :returns: The product of the two octonions, represented as an 8-tuple of float components.
   :rtype: Tuple[float, float, float, float, float, float, float, float]

   .. rubric:: Notes

   Normalization may cause NaNs due to floating-point precision issues, especially
   if the second octonion's magnitude is very small.


.. py:class:: OMult(args: dict)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   OMult extends the base knowledge graph embedding model by integrating octonion
   algebra. This model leverages the properties of octonions to represent and process
   the embeddings of entities and relations in a knowledge graph, aiming to capture
   complex interactions and patterns.

   :param args: A dictionary of arguments containing hyperparameters and settings for the model,
                such as embedding dimensions and learning rate.
   :type args: dict

   .. attribute:: name

      The name identifier for the OMult model.

      :type: str

   .. method:: octonion_normalizer(emb_rel_e0: torch.Tensor, emb_rel_e1: torch.Tensor, ..., emb_rel_e7: torch.Tensor) -> Tuple[torch.Tensor, ...]

      Normalizes octonion components to unit length.


   .. method:: score(head_ent_emb: torch.FloatTensor, rel_ent_emb: torch.FloatTensor, tail_ent_emb: torch.FloatTensor) -> torch.FloatTensor

      Computes the score of a triple using octonion multiplication.


   .. method:: k_vs_all_score(bpe_head_ent_emb, bpe_rel_ent_emb, E) -> torch.FloatTensor

      Computes scores in a K-vs-All setting using octonion embeddings.


   .. method:: forward_k_vs_all(x) -> torch.FloatTensor

      Performs a forward pass for K-vs-All scoring, returning scores for all entities.


   .. py:method:: octonion_normalizer(emb_rel_e0: torch.Tensor, emb_rel_e1: torch.Tensor, emb_rel_e2: torch.Tensor, emb_rel_e3: torch.Tensor, emb_rel_e4: torch.Tensor, emb_rel_e5: torch.Tensor, emb_rel_e6: torch.Tensor, emb_rel_e7: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]
      :staticmethod:

      Normalizes the components of an octonion.

      Each component of the octonion is divided by the square root of the sum of
      the squares of all components, normalizing it to unit length.

      :param emb_rel_e0: The eight components of an octonion.
      :type emb_rel_e0: torch.Tensor
      :param emb_rel_e1: The eight components of an octonion.
      :type emb_rel_e1: torch.Tensor
      :param ...: The eight components of an octonion.
      :type ...: torch.Tensor
      :param emb_rel_e7: The eight components of an octonion.
      :type emb_rel_e7: torch.Tensor

      :returns: The normalized components of the octonion.
      :rtype: Tuple[torch.Tensor, ...]


   .. py:method:: score(head_ent_emb: torch.FloatTensor, rel_ent_emb: torch.FloatTensor, tail_ent_emb: torch.FloatTensor) -> torch.FloatTensor

      Computes the score of a triple using octonion multiplication.

      The method involves splitting the embeddings into real and imaginary parts,
      normalizing the relation embeddings, performing octonion multiplication,
      and then calculating the score based on the inner product.

      :param head_ent_emb: Embedding of the head entity.
      :type head_ent_emb: torch.FloatTensor
      :param rel_ent_emb: Embedding of the relation.
      :type rel_ent_emb: torch.FloatTensor
      :param tail_ent_emb: Embedding of the tail entity.
      :type tail_ent_emb: torch.FloatTensor

      :returns: The score of the triple.
      :rtype: torch.FloatTensor


   .. py:method:: k_vs_all_score(bpe_head_ent_emb: torch.FloatTensor, bpe_rel_ent_emb: torch.FloatTensor, E: torch.FloatTensor) -> torch.FloatTensor

      Computes scores in a K-vs-All setting using octonion embeddings for a batch of head entities and relations.

      This method splits the head entity and relation embeddings into their octonion components, normalizes
      the relation embeddings if necessary, and then applies octonion multiplication. It computes the score
      by performing an inner product with all tail entity embeddings.

      :param bpe_head_ent_emb: Batched embeddings of head entities, each represented as an octonion.
      :type bpe_head_ent_emb: torch.FloatTensor
      :param bpe_rel_ent_emb: Batched embeddings of relations, each represented as an octonion.
      :type bpe_rel_ent_emb: torch.FloatTensor
      :param E: Embeddings of all possible tail entities.
      :type E: torch.FloatTensor

      :returns: Scores for all possible triples formed with the given head entities and relations against all entities.
                The shape of the output is (size of batch, number of entities).
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      The method is particularly useful in scenarios like link prediction, where the goal is to rank all possible
      tail entities for a given head entity and relation.


   .. py:method:: forward_k_vs_all(x)

      Performs a forward pass for K-vs-All scoring.

      TODO: Add mathematical format for sphinx.

      Given a head entity and a relation (h,r), this method computes scores for all
      possible triples, i.e., [score(h,r,x)|x \in Entities] => [0.0,0.1,...,0.8], shape=> (1, |Entities|), returning a score for each entity in the knowledge graph.

      :param x: Tensor containing indices for head entities and relations.
      :type x: Tensor

      :returns: Scores for all triples formed with the given head entities and relations against all entities.
      :rtype: torch.FloatTensor



.. py:class:: ConvO(args: dict)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   ConvO extends the base knowledge graph embedding model by integrating convolutional
   operations with octonion algebra. This model applies convolutional neural networks
   to octonion-based embeddings, capturing complex interactions in knowledge graphs.

   :param args: A dictionary of arguments containing hyperparameters and settings for the model,
                such as embedding dimensions, number of output channels, kernel size, and dropout rates.
   :type args: dict

   .. attribute:: name

      The name identifier for the ConvO model.

      :type: str

   .. attribute:: conv2d

      A 2D convolutional layer used for processing octonion-based embeddings.

      :type: torch.nn.Conv2d

   .. attribute:: fc_num_input

      The number of input features for the fully connected layer.

      :type: int

   .. attribute:: fc1

      A fully connected linear layer for compressing the output of the convolutional layer.

      :type: torch.nn.Linear

   .. attribute:: bn_conv2d

      Batch normalization layer applied after the convolutional operation.

      :type: torch.nn.BatchNorm2d

   .. attribute:: norm_fc1

      Normalization layer applied after the fully connected layer.

      :type: Normalizer

   .. attribute:: feature_map_dropout

      Dropout layer applied to the output of the convolutional layer.

      :type: torch.nn.Dropout2d

   .. method:: octonion_normalizer(emb_rel_e0, emb_rel_e1, ..., emb_rel_e7)

      Normalizes octonion components to unit length.


   .. method:: residual_convolution(O_1, O_2)

      Performs a residual convolution operation on two octonion embeddings.


   .. method:: forward_triples(x: torch.Tensor) -> torch.Tensor

      Computes scores for a batch of triples using convolutional operations.


   .. method:: forward_k_vs_all(x: torch.Tensor)

      Computes scores against a sampled subset of entities using convolutional operations.


   .. rubric:: Notes

   ConvO aims to enhance the modeling capabilities of knowledge graph embeddings by
   adding more complex interaction patterns through convolutional layers, potentially
   improving performance on tasks like link prediction.

   .. py:method:: octonion_normalizer(emb_rel_e0: torch.Tensor, emb_rel_e1: torch.Tensor, emb_rel_e2: torch.Tensor, emb_rel_e3: torch.Tensor, emb_rel_e4: torch.Tensor, emb_rel_e5: torch.Tensor, emb_rel_e6: torch.Tensor, emb_rel_e7: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]
      :staticmethod:

      Normalizes the components of an octonion to unit length.

      Each component of the octonion is divided by the square root of the sum of
      the squares of all components.

      :param emb_rel_e0: The eight components of an octonion.
      :type emb_rel_e0: torch.Tensor
      :param emb_rel_e1: The eight components of an octonion.
      :type emb_rel_e1: torch.Tensor
      :param ...: The eight components of an octonion.
      :type ...: torch.Tensor
      :param emb_rel_e7: The eight components of an octonion.
      :type emb_rel_e7: torch.Tensor

      :returns: The normalized components of the octonion.
      :rtype: Tuple[torch.Tensor, ...]


   .. py:method:: residual_convolution(O_1: Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor], O_2: Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]

      Performs a residual convolution operation on two sets of octonion embeddings.

      The method combines two octonion embeddings and applies a convolutional operation
      followed by batch normalization, dropout, and a fully connected layer.

      :param O_1: The first set of octonion embeddings.
      :type O_1: Tuple[torch.Tensor, ...]
      :param O_2: The second set of octonion embeddings.
      :type O_2: Tuple[torch.Tensor, ...]

      :returns: The resulting octonion embeddings after the convolutional operation.
      :rtype: Tuple[torch.Tensor, ...]


   .. py:method:: forward_triples(x: torch.Tensor) -> torch.Tensor

      Computes scores for a batch of triples using convolutional operations.

      The method processes head, relation, and tail embeddings using convolutional
      layers and computes the scores of the triples.

      :param x: Tensor containing indices for head entities, relations, and tail entities.
      :type x: torch.Tensor

      :returns: Scores for the given batch of triples.
      :rtype: torch.Tensor


   .. py:method:: forward_k_vs_all(x: torch.Tensor) -> torch.Tensor

      Given a batch of head entities and relations (h,r), this method computes scores for all entities.
      [score(h,r,x)|x \in Entities] => [0.0,0.1,...,0.8], shape=> (1, |Entities|)
      Given a batch of head entities and relations => shape (size of batch,| Entities|)

      :param x: A tensor representing a batch of input triples in the form of (head entities, relations).
      :type x: torch.Tensor

      :returns: Scores for the input triples against all possible tail entities.
      :rtype: torch.Tensor

      .. rubric:: Notes

      - The input `x` is a tensor of shape (batch_size, 2), where each row represents a pair of head entities and relations.
      - The method follows the following steps:
          (1) Retrieve embeddings & Apply Dropout & Normalization.
          (2) Split the embeddings into real and imaginary parts.
          (3) Apply convolution operation on the real and imaginary parts.
          (4) Perform quaternion multiplication.
          (5) Compute scores for all entities.

      The method returns a tensor of shape (batch_size, num_entities) where each row contains scores for each entity in the knowledge graph.



.. py:class:: AConvO(args: dict)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   Additive Convolutional Octonion(AConvO) extends the base knowledge graph embedding model by integrating additive convolutional
   operations with octonion algebra. This model applies convolutional neural networks to octonion-based
   embeddings, capturing complex interactions in knowledge graphs.

   :param args: A dictionary of arguments containing hyperparameters and settings for the model,
                such as embedding dimensions, number of output channels, kernel size, and dropout rates.
   :type args: dict

   .. attribute:: name

      The name identifier for the AConvO model.

      :type: str

   .. attribute:: conv2d

      A 2D convolutional layer used for processing octonion-based embeddings.

      :type: torch.nn.Conv2d

   .. attribute:: fc_num_input

      The number of input features for the fully connected layer.

      :type: int

   .. attribute:: fc1

      A fully connected linear layer for compressing the output of the convolutional layer.

      :type: torch.nn.Linear

   .. attribute:: bn_conv2d

      Batch normalization layer applied after the convolutional operation.

      :type: torch.nn.BatchNorm2d

   .. attribute:: norm_fc1

      Normalization layer applied after the fully connected layer.

      :type: Normalizer

   .. attribute:: feature_map_dropout

      Dropout layer applied to the output of the convolutional layer.

      :type: torch.nn.Dropout2d

   .. method:: octonion_normalizer(emb_rel_e0: torch.Tensor, emb_rel_e1: torch.Tensor, ..., emb_rel_e7: torch.Tensor) -> Tuple[torch.Tensor, ...]

      Normalizes octonion components to unit length.


   .. method:: residual_convolution(self, O_1: Tuple[torch.Tensor, ...], O_2: Tuple[torch.Tensor, ...]) -> Tuple[torch.Tensor, ...]

      Performs a residual convolution operation on two octonion embeddings.


   .. method:: forward_triples(x: torch.Tensor) -> torch.Tensor

      Computes scores for a batch of triples using convolutional operations.


   .. method:: forward_k_vs_all(x: torch.Tensor)

      Computes scores against a sampled subset of entities using convolutional operations.


   .. rubric:: Notes

   AConvO aims to enhance the modeling capabilities of knowledge graph embeddings by
   adding more complex interaction patterns through convolutional layers, potentially
   improving performance on tasks like link prediction.

   .. py:method:: octonion_normalizer(emb_rel_e0: torch.Tensor, emb_rel_e1: torch.Tensor, emb_rel_e2: torch.Tensor, emb_rel_e3: torch.Tensor, emb_rel_e4: torch.Tensor, emb_rel_e5: torch.Tensor, emb_rel_e6: torch.Tensor, emb_rel_e7: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]
      :staticmethod:

      Normalizes the components of an octonion to unit length.

      Each component of the octonion is divided by the square root of the sum of
      the squares of all components.

      :param emb_rel_e0: The eight components of an octonion.
      :type emb_rel_e0: torch.Tensor
      :param emb_rel_e1: The eight components of an octonion.
      :type emb_rel_e1: torch.Tensor
      :param ...: The eight components of an octonion.
      :type ...: torch.Tensor
      :param emb_rel_e7: The eight components of an octonion.
      :type emb_rel_e7: torch.Tensor

      :returns: The normalized components of the octonion.
      :rtype: Tuple[torch.Tensor, ...]


   .. py:method:: residual_convolution(O_1: Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor], O_2: Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]

      Performs a residual convolution operation on two sets of octonion embeddings.

      The method combines two octonion embeddings and applies a convolutional operation
      followed by batch normalization, dropout, and a fully connected layer.

      :param O_1: The first set of octonion embeddings.
      :type O_1: Tuple[torch.Tensor, ...]
      :param O_2: The second set of octonion embeddings.
      :type O_2: Tuple[torch.Tensor, ...]

      :returns: The resulting octonion embeddings after the convolutional operation.
      :rtype: Tuple[torch.Tensor, ...]


   .. py:method:: forward_triples(x: torch.Tensor) -> torch.Tensor

      Computes scores for a batch of triples using convolutional operations.

      The method processes head, relation, and tail embeddings using convolutional
      layers and computes the scores of the triples.

      :param x: Tensor containing indices for head entities, relations, and tail entities.
      :type x: torch.Tensor

      :returns: Scores for the given batch of triples.
      :rtype: torch.Tensor


   .. py:method:: forward_k_vs_all(x: torch.Tensor) -> torch.Tensor

      Compute scores for a head entity and a relation (h,r) against all entities in the knowledge graph.

      Given a head entity and a relation (h, r), this method computes scores for (h, r, x) for all entities x in the knowledge graph.

      :param x: A tensor containing indices for head entities and relations.
      :type x: torch.Tensor

      :returns: A tensor of scores representing the compatibility of (h, r, x) for all entities x in the knowledge graph.
      :rtype: torch.Tensor

      .. rubric:: Notes

      This method supports batch processing, allowing the input tensor `x` to contain multiple head entities and relations.

      The scores indicate how well each entity x in the knowledge graph fits the (h, r) pattern, with higher scores indicating better compatibility.



.. py:class:: Keci(args: dict)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   The Keci class is a knowledge graph embedding model that incorporates Clifford algebra for embeddings.
   It supports different dimensions of Clifford algebra by setting the parameters p and q. The class
   utilizes Clifford multiplication for embedding interactions and computes scores for knowledge graph triples.

   :param args: A dictionary of arguments containing hyperparameters and settings for the model.
   :type args: dict

   .. attribute:: name

      The name identifier for the Keci class.

      :type: str

   .. attribute:: p

      The parameter 'p' in Clifford algebra, representing the number of positive square terms.

      :type: int

   .. attribute:: q

      The parameter 'q' in Clifford algebra, representing the number of negative square terms.

      :type: int

   .. attribute:: r

      A derived attribute for dimension scaling based on 'p' and 'q'.

      :type: int

   .. attribute:: p_coefficients

      Embedding for scaling coefficients of 'p' terms, if 'p' > 0.

      :type: torch.nn.Embedding (optional)

   .. attribute:: q_coefficients

      Embedding for scaling coefficients of 'q' terms, if 'q' > 0.

      :type: torch.nn.Embedding (optional)

   .. method:: compute_sigma_pp(hp: torch.Tensor, rp: torch.Tensor) -> torch.Tensor

      Computes the sigma_pp component in Clifford multiplication.

   .. method:: compute_sigma_qq(hq: torch.Tensor, rq: torch.Tensor) -> torch.Tensor

      Computes the sigma_qq component in Clifford multiplication.

   .. method:: compute_sigma_pq(hp: torch.Tensor, hq: torch.Tensor, rp: torch.Tensor, rq: torch.Tensor) -> torch.Tensor

      Computes the sigma_pq component in Clifford multiplication.

   .. method:: apply_coefficients(h0: torch.Tensor, hp: torch.Tensor, hq: torch.Tensor, r0: torch.Tensor, rp: torch.Tensor, rq: torch.Tensor) -> tuple

      Applies scaling coefficients to the base vectors in Clifford algebra.

   .. method:: clifford_multiplication(h0: torch.Tensor, hp: torch.Tensor, hq: torch.Tensor, r0: torch.Tensor, rp: torch.Tensor, rq: torch.Tensor) -> tuple

      Performs Clifford multiplication of head and relation embeddings.

   .. method:: construct_cl_multivector(x: torch.FloatTensor, r: int, p: int, q: int) -> tuple

      Constructs a multivector in Clifford algebra Cl_{p,q}(\mathbb{R}^d).

   .. method:: forward_k_vs_with_explicit(x: torch.Tensor) -> torch.FloatTensor

      Computes scores for a batch of triples against all entities using explicit Clifford multiplication.

   .. method:: k_vs_all_score(bpe_head_ent_emb: torch.Tensor, bpe_rel_ent_emb: torch.Tensor, E: torch.Tensor) -> torch.FloatTensor

      Computes scores for all triples using Clifford multiplication in a K-vs-All setup.

   .. method:: forward_k_vs_all(x: torch.Tensor) -> torch.FloatTensor

      Wrapper function for K-vs-All scoring.

   .. method:: forward_k_vs_sample(x: torch.LongTensor, target_entity_idx: torch.LongTensor) -> torch.FloatTensor

      Computes scores for a sampled subset of entities.

   .. method:: score(h: torch.Tensor, r: torch.Tensor, t: torch.Tensor) -> torch.FloatTensor

      Computes the score for a given triple using Clifford multiplication.

   .. method:: forward_triples(x: torch.Tensor) -> torch.FloatTensor

      Computes scores for a batch of triples.


   .. rubric:: Notes

   The class is designed to work with embeddings in the context of knowledge graph completion tasks,
   leveraging the properties of Clifford algebra for embedding interactions.

   .. py:method:: compute_sigma_pp(hp: torch.Tensor, rp: torch.Tensor) -> torch.Tensor

      Computes the sigma_pp component in Clifford multiplication, representing the interactions
      between the positive square terms in the Clifford algebra.

      sigma_{pp} = \sum_{i=1}^{p-1} \sum_{k=i+1}^p (h_i r_k - h_k r_i) e_i e_k, TODO: Add mathematical format for sphinx.

      sigma_{pp} captures the interactions between along p bases
      For instance, let p e_1, e_2, e_3, we compute interactions between e_1 e_2, e_1 e_3 , and e_2 e_3
      This can be implemented with a nested two for loops

                      results = []
                      for i in range(p - 1):
                          for k in range(i + 1, p):
                              results.append(hp[:, :, i] * rp[:, :, k] - hp[:, :, k] * rp[:, :, i])
                      sigma_pp = torch.stack(results, dim=2)
                      assert sigma_pp.shape == (b, r, int((p * (p - 1)) / 2))

      Yet, this computation would be quite inefficient. Instead, we compute interactions along all p,
      e.g., e1e1, e1e2, e1e3,
            e2e1, e2e2, e2e3,
            e3e1, e3e2, e3e3
      Then select the triangular matrix without diagonals: e1e2, e1e3, e2e3.

      :param hp: The 'p' part of the head entity embedding in Clifford algebra.
      :type hp: torch.Tensor
      :param rp: The 'p' part of the relation embedding in Clifford algebra.
      :type rp: torch.Tensor

      :returns: **sigma_pp** -- The sigma_pp component of the Clifford multiplication.
      :rtype: torch.Tensor


   .. py:method:: compute_sigma_qq(hq: torch.Tensor, rq: torch.Tensor) -> torch.Tensor

      Computes the sigma_qq component in Clifford multiplication, representing the interactions
      between the negative square terms in the Clifford algebra.

      TODO: Add mathematical format for sphinx.

      sigma_{qq} = \sum_{j=1}^{p+q-1} \sum_{k=j+1}^{p+q} (h_j r_k - h_k r_j) e_j e_k
      sigma_{q} captures the interactions between along q bases
      For instance, let q e_1, e_2, e_3, we compute interactions between e_1 e_2, e_1 e_3 , and e_2 e_3
      This can be implemented with a nested two for loops

                      results = []
                      for j in range(q - 1):
                          for k in range(j + 1, q):
                              results.append(hq[:, :, j] * rq[:, :, k] - hq[:, :, k] * rq[:, :, j])
                      sigma_qq = torch.stack(results, dim=2)
                      assert sigma_qq.shape == (b, r, int((q * (q - 1)) / 2))

      Yet, this computation would be quite inefficient. Instead, we compute interactions along all p,
      e.g., e1e1, e1e2, e1e3,
            e2e1, e2e2, e2e3,
            e3e1, e3e2, e3e3
      Then select the triangular matrix without diagonals: e1e2, e1e3, e2e3.

      :param hq: The 'q' part of the head entity embedding in Clifford algebra.
      :type hq: torch.Tensor
      :param rq: The 'q' part of the relation embedding in Clifford algebra.
      :type rq: torch.Tensor

      :returns: **sigma_qq** -- The sigma_qq component of the Clifford multiplication.
      :rtype: torch.Tensor


   .. py:method:: compute_sigma_pq(*, hp: torch.Tensor, hq: torch.Tensor, rp: torch.Tensor, rq: torch.Tensor) -> torch.Tensor

      Computes the sigma_pq component in Clifford multiplication, representing the interactions
      between the positive and negative square terms in the Clifford algebra.

      TODO: Add mathematical format for sphinx.

      \sum_{i=1}^{p} \sum_{j=p+1}^{p+q} (h_i r_j - h_j r_i) e_i e_j

      # results = []
      # sigma_pq = torch.zeros(b, r, p, q)
      # for i in range(p):
      #     for j in range(q):
      #         sigma_pq[:, :, i, j] = hp[:, :, i] * rq[:, :, j] - hq[:, :, j] * rp[:, :, i]
      # print(sigma_pq.shape)

      :param hp: The 'p' part of the head entity embedding in Clifford algebra.
      :type hp: torch.Tensor
      :param hq: The 'q' part of the head entity embedding in Clifford algebra.
      :type hq: torch.Tensor
      :param rp: The 'p' part of the relation embedding in Clifford algebra.
      :type rp: torch.Tensor
      :param rq: The 'q' part of the relation embedding in Clifford algebra.
      :type rq: torch.Tensor

      :returns: **sigma_pq** -- The sigma_pq component of the Clifford multiplication.
      :rtype: torch.Tensor


   .. py:method:: apply_coefficients(h0: torch.Tensor, hp: torch.Tensor, hq: torch.Tensor, r0: torch.Tensor, rp: torch.Tensor, rq: torch.Tensor) -> tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      Applies scaling coefficients to the base vectors in the Clifford algebra.
      This method is used for adjusting the contributions of different components in the algebra.

      :param h0: The scalar part of the head entity embedding.
      :type h0: torch.Tensor
      :param hp: The 'p' part of the head entity embedding.
      :type hp: torch.Tensor
      :param hq: The 'q' part of the head entity embedding.
      :type hq: torch.Tensor
      :param r0: The scalar part of the relation embedding.
      :type r0: torch.Tensor
      :param rp: The 'p' part of the relation embedding.
      :type rp: torch.Tensor
      :param rq: The 'q' part of the relation embedding.
      :type rq: torch.Tensor

      :returns: Tuple containing the scaled components of the head and relation embeddings.
      :rtype: tuple


   .. py:method:: clifford_multiplication(h0: torch.Tensor, hp: torch.Tensor, hq: torch.Tensor, r0: torch.Tensor, rp: torch.Tensor, rq: torch.Tensor) -> tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

              Performs Clifford multiplication of head and relation embeddings. This method computes the
              various components of the Clifford product, combining the scalar, 'p', and 'q' parts of the embeddings.

              TODO: Add mathematical format for sphinx.

              h = h_0 + \sum_{i=1}^p h_i e_i + \sum_{j=p+1}^{p+q} h_j e_j
              r = r_0 + \sum_{i=1}^p r_i e_i + \sum_{j=p+1}^{p+q} r_j e_j

              ei ^2 = +1     for i =< i =< p
              ej ^2 = -1     for p < j =< p+q
              ei ej = -eje1  for i
      eq j

              h r =   sigma_0 + sigma_p + sigma_q + sigma_{pp} + sigma_{q}+ sigma_{pq}
              where
                      (1) sigma_0 = h_0 r_0 + \sum_{i=1}^p (h_0 r_i) e_i - \sum_{j=p+1}^{p+q} (h_j r_j) e_j

                      (2) sigma_p = \sum_{i=1}^p (h_0 r_i + h_i r_0) e_i

                      (3) sigma_q = \sum_{j=p+1}^{p+q} (h_0 r_j + h_j r_0) e_j

                      (4) sigma_{pp} = \sum_{i=1}^{p-1} \sum_{k=i+1}^p (h_i r_k - h_k r_i) e_i e_k

                      (5) sigma_{qq} = \sum_{j=1}^{p+q-1} \sum_{k=j+1}^{p+q} (h_j r_k - h_k r_j) e_j e_k

                      (6) sigma_{pq} = \sum_{i=1}^{p} \sum_{j=p+1}^{p+q} (h_i r_j - h_j r_i) e_i e_j

              Parameters
              ----------
              h0 : torch.Tensor
                  The scalar part of the head entity embedding.
              hp : torch.Tensor
                  The 'p' part of the head entity embedding.
              hq : torch.Tensor
                  The 'q' part of the head entity embedding.
              r0 : torch.Tensor
                  The scalar part of the relation embedding.
              rp : torch.Tensor
                  The 'p' part of the relation embedding.
              rq : torch.Tensor
                  The 'q' part of the relation embedding.

              Returns
              -------
              tuple
                  Tuple containing the components of the Clifford product.




   .. py:method:: construct_cl_multivector(x: torch.FloatTensor, r: int, p: int, q: int) -> tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      Construct a batch of multivectors Cl_{p,q}(\mathbb{R}^d)

      Parameter
      ---------
      x : torch.FloatTensor
          The embedding vector with shape (n, d).
      r : int
          The dimension of the scalar part.
      p : int
          The number of positive square terms.
      q : int
          The number of negative square terms.

      :returns: * **a0** (*torch.FloatTensor*) -- Tensor with (n,r) shape
                * **ap** (*torch.FloatTensor*) -- Tensor with (n,r,p) shape
                * **aq** (*torch.FloatTensor*) -- Tensor with (n,r,q) shape


   .. py:method:: forward_k_vs_with_explicit(x: torch.Tensor) -> torch.FloatTensor

      Computes scores for a batch of triples against all entities using explicit Clifford multiplication.
      This method is used for K-vs-All training and evaluation.

      :param x: Tensor representing a batch of head entities and relations.
      :type x: torch.Tensor

      :returns: A tensor containing scores for each triple against all entities.
      :rtype: torch.FloatTensor


   .. py:method:: k_vs_all_score(bpe_head_ent_emb: torch.Tensor, bpe_rel_ent_emb: torch.Tensor, E: torch.Tensor) -> torch.FloatTensor

      Computes scores for all triples using Clifford multiplication in a K-vs-All setup. This method involves constructing
      multivectors for head entities and relations in Clifford algebra, applying coefficients, and computing interaction
      scores based on different components of the Clifford algebra.

      :param bpe_head_ent_emb: Batch of head entity embeddings in BPE (Byte Pair Encoding) format. Tensor shape: (batch_size, embedding_dim).
      :type bpe_head_ent_emb: torch.Tensor
      :param bpe_rel_ent_emb: Batch of relation embeddings in BPE format. Tensor shape: (batch_size, embedding_dim).
      :type bpe_rel_ent_emb: torch.Tensor
      :param E: Tensor containing all entity embeddings. Tensor shape: (num_entities, embedding_dim).
      :type E: torch.Tensor

      :returns: Tensor containing the scores for each triple in the K-vs-All setting. Tensor shape: (batch_size, num_entities).
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      The method computes scores based on the basis of 1 (scalar part), the bases of 'p' (positive square terms),
      and the bases of 'q' (negative square terms). Additional computations involve sigma_pp, sigma_qq, and sigma_pq
      components in Clifford multiplication, corresponding to different interaction terms.


   .. py:method:: forward_k_vs_all(x: torch.Tensor) -> torch.FloatTensor

      TODO: Add mathematical format for sphinx.
      Performs the forward pass for K-vs-All training and evaluation in knowledge graph embeddings.
      This method involves retrieving real-valued embedding vectors for head entities and relations \mathbb{R}^d,
      constructing Clifford algebra multivectors for these embeddings according to Cl_{p,q}(\mathbb{R}^d), performing Clifford multiplication,
      and computing the inner product with all entity embeddings.

      :param x: A tensor representing a batch of head entities and relations for the K-vs-All evaluation.
                Expected tensor shape: (n, 2), where 'n' is the batch size and '2' represents head entity
                and relation pairs.
      :type x: torch.Tensor

      :returns: A tensor containing the scores for each head entity and relation pair against all possible
                tail entities in the knowledge graph. Tensor shape: (n, |E|), where '|E|' is the number
                of entities in the knowledge graph.
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      This method is similar to the 'forward_k_vs_with_explicit' function in functionality. It is
      typically used in scenarios where every possible combination of a head entity and a relation
      is scored against all tail entities, commonly used in knowledge graph completion tasks.


   .. py:method:: forward_k_vs_sample(x: torch.LongTensor, target_entity_idx: torch.LongTensor) -> torch.FloatTensor

      TODO: Add mathematical format for sphinx.

      Performs the forward pass for K-vs-Sample training in knowledge graph embeddings. This method involves
      retrieving real-valued embedding vectors for head entities and relations \mathbb{R}^d, constructing Clifford algebra
      multivectors for these embeddings according to Cl_{p,q}(\mathbb{R}^d), performing Clifford multiplication,
      and computing the inner product with a sampled subset of entity embeddings.

      :param x: A tensor representing a batch of head entities and relations for the K-vs-Sample evaluation.
                Expected tensor shape: (n, 2), where 'n' is the batch size and '2' represents head entity
                and relation pairs.
      :type x: torch.LongTensor
      :param target_entity_idx: A tensor of target entity indices for sampling in the K-vs-Sample evaluation.
                                Tensor shape: (n, sample_size), where 'sample_size' is the number of entities sampled.
      :type target_entity_idx: torch.LongTensor

      :returns: A tensor containing the scores for each head entity and relation pair against the sampled
                subset of tail entities. Tensor shape: (n, sample_size).
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      This method is used in scenarios where every possible combination of a head entity and a relation
      is scored against a sampled subset of tail entities, commonly used in knowledge graph completion tasks
      with a large number of entities.


   .. py:method:: score(h: torch.Tensor, r: torch.Tensor, t: torch.Tensor) -> torch.FloatTensor

      Computes the score for a given triple using Clifford multiplication in the context of knowledge graph embeddings.
      This method involves constructing Clifford algebra multivectors for head entities, relations, and tail entities,
      applying coefficients, and computing interaction scores based on different components of the Clifford algebra.

      :param h: Tensor representing the embeddings of head entities. Expected shape: (n, d), where 'n' is the number of triples
                and 'd' is the embedding dimension.
      :type h: torch.Tensor
      :param r: Tensor representing the embeddings of relations. Expected shape: (n, d).
      :type r: torch.Tensor
      :param t: Tensor representing the embeddings of tail entities. Expected shape: (n, d).
      :type t: torch.Tensor

      :returns: Tensor containing the scores for each triple. Tensor shape: (n,).
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      The method computes scores based on the scalar part, the bases of 'p' (positive square terms),
      and the bases of 'q' (negative square terms) in Clifford algebra. It includes additional computations
      involving sigma_pp, sigma_qq, and sigma_pq components, which correspond to different interaction terms
      in the Clifford product.


   .. py:method:: forward_triples(x: torch.Tensor) -> torch.FloatTensor

      Computes scores for a batch of triples using Clifford multiplication.
      This method is involved in the forward pass of the model during training or evaluation.
      It retrieves embeddings for head entities, relations, and tail entities, constructs Clifford algebra multivectors,
      applies coefficients, and computes interaction scores based on different components of Clifford algebra.

      :param x: A tensor representing a batch of triples. Each triple consists of indices for a head entity, a relation, and a tail entity.
                Expected tensor shape: (n, 3), where 'n' is the number of triples.
      :type x: torch.Tensor

      :returns: A tensor containing the scores for each triple in the batch. Tensor shape: (n,), where 'n' is the number of triples.
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      The method computes scores based on the scalar part, the bases of 'p' (positive square terms), and the bases of 'q' (negative square terms) in Clifford algebra.
      It includes additional computations involving sigma_pp, sigma_qq, and sigma_pq components, corresponding to different interaction terms in the Clifford product.



.. py:class:: KeciBase(args)


   Bases: :py:obj:`Keci`

   Without learning dimension scaling


.. py:class:: CMult(args)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   The CMult class represents a specific kind of mathematical object used in knowledge graph embeddings,
   involving Clifford algebra multiplication. It defines several algebraic structures based on the signature (p, q),
   such as Real Numbers, Complex Numbers, Quaternions, and others. The class provides functionality for
   performing Clifford multiplication, a generalization of the geometric product for vectors in a Clifford algebra.

   TODO: Add mathematical format for sphinx.

   Cl_(0,0) => Real Numbers


   Cl_(0,1) =>
               A multivector \mathbf{a} = a_0 + a_1 e_1
               A multivector \mathbf{b} = b_0 + b_1 e_1

               multiplication is isomorphic to the product of two complex numbers

               \mathbf{a}      imes \mathbf{b} = a_0 b_0 + a_0b_1 e1 + a_1 b_1 e_1 e_1
                                            = (a_0 b_0 - a_1 b_1) + (a_0 b_1 + a_1 b_0) e_1
   Cl_(2,0) =>
               A multivector \mathbf{a} = a_0 + a_1 e_1 + a_2 e_2 + a_{12} e_1 e_2
               A multivector \mathbf{b} = b_0 + b_1 e_1 + b_2 e_2 + b_{12} e_1 e_2

               \mathbf{a}      imes \mathbf{b} = a_0b_0 + a_0b_1 e_1 + a_0b_2e_2 + a_0 b_12 e_1 e_2
                                           + a_1 b_0 e_1 + a_1b_1 e_1_e1 ..

   Cl_(0,2) => Quaternions

   .. attribute:: name

      The name identifier for the CMult class.

      :type: str

   .. attribute:: entity_embeddings

      Embedding layer for entities in the knowledge graph.

      :type: torch.nn.Embedding

   .. attribute:: relation_embeddings

      Embedding layer for relations in the knowledge graph.

      :type: torch.nn.Embedding

   .. attribute:: p

      Non-negative integer representing the number of positive square terms in the Clifford algebra.

      :type: int

   .. attribute:: q

      Non-negative integer representing the number of negative square terms in the Clifford algebra.

      :type: int

   .. method:: clifford_mul(x: torch.FloatTensor, y: torch.FloatTensor, p: int, q: int) -> tuple

      Performs Clifford multiplication based on the given signature (p, q).

   .. method:: score(head_ent_emb, rel_ent_emb, tail_ent_emb) -> torch.FloatTensor

      Computes a scoring function for a head entity, relation, and tail entity embeddings.

   .. method:: forward_triples(x: torch.LongTensor) -> torch.FloatTensor

      Computes scores for a batch of triples.

   .. method:: forward_k_vs_all(x: torch.Tensor) -> torch.FloatTensor

      Computes scores for a batch of triples against all entities in the knowledge graph.


   .. py:method:: clifford_mul(x: torch.FloatTensor, y: torch.FloatTensor, p: int, q: int) -> tuple

              Performs Clifford multiplication in the Clifford algebra Cl_{p,q}. This method generalizes the geometric product
              of vectors in a Clifford algebra, handling different algebraic structures like real numbers, complex numbers,
              quaternions, etc., based on the signature (p, q).

              Clifford multiplication Cl_{p,q} (\mathbb{R})

              ei ^2 = +1     for i =< i =< p
              ej ^2 = -1     for p < j =< p+q
              ei ej = -eje1  for i
      eq j

              Parameters
              ----------
              x : torch.FloatTensor
                  The first multivector operand with shape (n, d).
              y : torch.FloatTensor
                  The second multivector operand with shape (n, d).
              p : int
                  A non-negative integer representing the number of positive square terms in the Clifford algebra.
              q : int
                  A non-negative integer representing the number of negative square terms in the Clifford algebra.

              Returns
              -------
              tuple
                  The result of Clifford multiplication, a tuple of tensors representing the components of the resulting multivector.



   .. py:method:: score(head_ent_emb: torch.FloatTensor, rel_ent_emb: torch.FloatTensor, tail_ent_emb: torch.FloatTensor) -> torch.FloatTensor

      Computes a scoring function for a given triple of head entity, relation, and tail entity embeddings.
      The method involves Clifford multiplication of the head entity and relation embeddings, followed by
      a calculation of the score with the tail entity embedding.

      :param head_ent_emb: Embedding of the head entity.
      :type head_ent_emb: torch.FloatTensor
      :param rel_ent_emb: Embedding of the relation.
      :type rel_ent_emb: torch.FloatTensor
      :param tail_ent_emb: Embedding of the tail entity.
      :type tail_ent_emb: torch.FloatTensor

      :returns: A tensor representing the score of the given triple.
      :rtype: torch.FloatTensor


   .. py:method:: forward_triples(x: torch.LongTensor) -> torch.FloatTensor

      Computes scores for a batch of triples. This method is typically used in training or evaluation
      of knowledge graph embedding models. It applies Clifford multiplication to the embeddings of head
      entities and relations and then calculates the score with respect to the tail entity embeddings.

      :param x: A tensor with shape (n, 3) representing a batch of triples, where each triple consists of indices
                for a head entity, a relation, and a tail entity.
      :type x: torch.LongTensor

      :returns: A tensor with shape (n,) containing the scores for each triple in the batch.
      :rtype: torch.FloatTensor


   .. py:method:: forward_k_vs_all(x: torch.Tensor) -> torch.FloatTensor

      Computes scores for a batch of triples against all entities in the knowledge graph, often used in KvsAll evaluation.
      This method retrieves embeddings for heads and relations, performs Clifford multiplication, and then computes the
      inner product with all entity embeddings to get scores for every possible triple involving the given heads and relations.

      :param x: A tensor with shape (n, 3) representing a batch of triples, where each triple consists of indices
                for a head entity and a relation. The tail entity is to be compared against all possible entities.
      :type x: torch.Tensor

      :returns: A tensor with shape (n,) containing scores for each triple against all possible tail entities.
      :rtype: torch.FloatTensor



.. py:class:: DeCaL(args)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   Base class for all neural network modules.

   Your models should also subclass this class.

   Modules can also contain other Modules, allowing to nest them in
   a tree structure. You can assign the submodules as regular attributes::

       import torch.nn as nn
       import torch.nn.functional as F

       class Model(nn.Module):
           def __init__(self):
               super().__init__()
               self.conv1 = nn.Conv2d(1, 20, 5)
               self.conv2 = nn.Conv2d(20, 20, 5)

           def forward(self, x):
               x = F.relu(self.conv1(x))
               return F.relu(self.conv2(x))

   Submodules assigned in this way will be registered, and will have their
   parameters converted too when you call :meth:`to`, etc.

   .. note::
       As per the example above, an ``__init__()`` call to the parent class
       must be made before assignment on the child.

   :ivar training: Boolean represents whether this module is in training or
                   evaluation mode.
   :vartype training: bool

   .. py:method:: forward_triples(x: torch.Tensor) -> torch.FloatTensor

      Parameter
      ---------
      x: torch.LongTensor with (n, ) shape

      :rtype: torch.FloatTensor with (n) shape


   .. py:method:: cl_pqr(a: torch.tensor) -> torch.tensor

      Input: tensor(batch_size, emb_dim) ---> output: tensor with 1+p+q+r components with size (batch_size, emb_dim/(1+p+q+r)) each.

      1) takes a tensor of size (batch_size, emb_dim), split it into 1 + p + q +r components, hence 1+p+q+r must be a divisor
      of the emb_dim.
      2) Return a list of the 1+p+q+r components vectors, each are tensors of size (batch_size, emb_dim/(1+p+q+r))


   .. py:method:: compute_sigmas_single(list_h_emb, list_r_emb, list_t_emb)

      here we compute all the sums with no others vectors interaction taken with the scalar product with t, that is,

      .. math::

           s0 = h_0r_0t_0
           s1 = \sum_{i=1}^{p}h_ir_it_0
           s2 = \sum_{j=p+1}^{p+q}h_jr_jt_0
           s3 = \sum_{i=1}^{q}(h_0r_it_i + h_ir_0t_i)
           s4 = \sum_{i=p+1}^{p+q}(h_0r_it_i + h_ir_0t_i)
           s5 = \sum_{i=p+q+1}^{p+q+r}(h_0r_it_i + h_ir_0t_i)

      and return:

      .. math::

          sigma_0t = \sigma_0 \cdot t_0 = s0 + s1 -s2
          s3, s4 and s5




   .. py:method:: compute_sigmas_multivect(list_h_emb, list_r_emb)

      Here we compute and return all the sums with vectors interaction for the same and different bases.

      For same bases vectors interaction we have

      .. math::

           \sigma_pp = \sum_{i=1}^{p-1}\sum_{i'=i+1}^{p}(h_ir_{i'}-h_{i'}r_i) (models the interactions between e_i and e_i' for 1 <= i, i' <= p)
           \sigma_qq = \sum_{j=p+1}^{p+q-1}\sum_{j'=j+1}^{p+q}(h_jr_{j'}-h_{j'} (models the interactions between e_j and e_j' for p+1 <= j, j' <= p+q)
           \sigma_rr = \sum_{k=p+q+1}^{p+q+r-1}\sum_{k'=k+1}^{p}(h_kr_{k'}-h_{k'}r_k) (models the interactions between e_k and e_k' for p+q+1 <= k, k' <= p+q+r)

      For different base vector interactions, we have

       .. math::

           \sigma_pq = \sum_{i=1}^{p}\sum_{j=p+1}^{p+q}(h_ir_j - h_jr_i) (interactionsn between e_i and e_j for 1<=i <=p and p+1<= j <= p+q)
           \sigma_pr = \sum_{i=1}^{p}\sum_{k=p+q+1}^{p+q+r}(h_ir_k - h_kr_i) (interactionsn between e_i and e_k for 1<=i <=p and p+q+1<= k <= p+q+r)
           \sigma_qr = \sum_{j=p+1}^{p+q}\sum_{j=p+q+1}^{p+q+r}(h_jr_k - h_kr_j) (interactionsn between e_j and e_k for p+1 <= j <=p+q and p+q+1<= j <= p+q+r)



   .. py:method:: forward_k_vs_all(x: torch.Tensor) -> torch.FloatTensor

      Kvsall training

      (1) Retrieve real-valued embedding vectors for heads and relations
      (2) Construct head entity and relation embeddings according to Cl_{p,q, r}(\mathbb{R}^d) .
      (3) Perform Cl multiplication
      (4) Inner product of (3) and all entity embeddings

      forward_k_vs_with_explicit and this funcitons are identical
      Parameter
      ---------
      x: torch.LongTensor with (n, ) shape
      :rtype: torch.FloatTensor with (n, |E|) shape


   .. py:method:: apply_coefficients(h0, hp, hq, hk, r0, rp, rq, rk)

      Multiplying a base vector with its scalar coefficient


   .. py:method:: construct_cl_multivector(x: torch.FloatTensor, re: int, p: int, q: int, r: int) -> tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      Construct a batch of multivectors Cl_{p,q,r}(\mathbb{R}^d)

      Parameter
      ---------
      x: torch.FloatTensor with (n,d) shape

      :returns: * **a0** (*torch.FloatTensor*)
                * **ap** (*torch.FloatTensor*)
                * **aq** (*torch.FloatTensor*)
                * **ar** (*torch.FloatTensor*)


   .. py:method:: compute_sigma_pp(hp, rp)

      Compute
      .. math::

          \sigma_{p,p}^* = \sum_{i=1}^{p-1}\sum_{i'=i+1}^{p}(x_iy_{i'}-x_{i'}y_i)

      \sigma_{pp} captures the interactions between along p bases
      For instance, let p e_1, e_2, e_3, we compute interactions between e_1 e_2, e_1 e_3 , and e_2 e_3
      This can be implemented with a nested two for loops

                      results = []
                      for i in range(p - 1):
                          for k in range(i + 1, p):
                              results.append(hp[:, :, i] * rp[:, :, k] - hp[:, :, k] * rp[:, :, i])
                      sigma_pp = torch.stack(results, dim=2)
                      assert sigma_pp.shape == (b, r, int((p * (p - 1)) / 2))

      Yet, this computation would be quite inefficient. Instead, we compute interactions along all p,
      e.g., e1e1, e1e2, e1e3,
            e2e1, e2e2, e2e3,
            e3e1, e3e2, e3e3
      Then select the triangular matrix without diagonals: e1e2, e1e3, e2e3.


   .. py:method:: compute_sigma_qq(hq, rq)

      Compute

      .. math::

          \sigma_{q,q}^* = \sum_{j=p+1}^{p+q-1}\sum_{j'=j+1}^{p+q}(x_jy_{j'}-x_{j'}y_j) Eq. 16

      sigma_{q} captures the interactions between along q bases
      For instance, let q e_1, e_2, e_3, we compute interactions between e_1 e_2, e_1 e_3 , and e_2 e_3
      This can be implemented with a nested two for loops

                      results = []
                      for j in range(q - 1):
                          for k in range(j + 1, q):
                              results.append(hq[:, :, j] * rq[:, :, k] - hq[:, :, k] * rq[:, :, j])
                      sigma_qq = torch.stack(results, dim=2)
                      assert sigma_qq.shape == (b, r, int((q * (q - 1)) / 2))

      Yet, this computation would be quite inefficient. Instead, we compute interactions along all p,
      e.g., e1e1, e1e2, e1e3,
            e2e1, e2e2, e2e3,
            e3e1, e3e2, e3e3
      Then select the triangular matrix without diagonals: e1e2, e1e3, e2e3.


   .. py:method:: compute_sigma_rr(hk, rk)

      .. math::

          \sigma_{r,r}^* = \sum_{k=p+q+1}^{p+q+r-1}\sum_{k'=k+1}^{p}(x_ky_{k'}-x_{k'}y_k)



   .. py:method:: compute_sigma_pq(*, hp, hq, rp, rq)

      Compute

      .. math::

          \sum_{i=1}^{p} \sum_{j=p+1}^{p+q} (h_i r_j - h_j r_i) e_i e_j

      results = []
      sigma_pq = torch.zeros(b, r, p, q)
      for i in range(p):
          for j in range(q):
              sigma_pq[:, :, i, j] = hp[:, :, i] * rq[:, :, j] - hq[:, :, j] * rp[:, :, i]
      print(sigma_pq.shape)



   .. py:method:: compute_sigma_pr(*, hp, hk, rp, rk)

      Compute

      .. math::

          \sum_{i=1}^{p} \sum_{j=p+1}^{p+q} (h_i r_j - h_j r_i) e_i e_j

      results = []
      sigma_pq = torch.zeros(b, r, p, q)
      for i in range(p):
          for j in range(q):
              sigma_pq[:, :, i, j] = hp[:, :, i] * rq[:, :, j] - hq[:, :, j] * rp[:, :, i]
      print(sigma_pq.shape)



   .. py:method:: compute_sigma_qr(*, hq, hk, rq, rk)

      .. math::

          \sum_{i=1}^{p} \sum_{j=p+1}^{p+q} (h_i r_j - h_j r_i) e_i e_j

      results = []
      sigma_pq = torch.zeros(b, r, p, q)
      for i in range(p):
          for j in range(q):
              sigma_pq[:, :, i, j] = hp[:, :, i] * rq[:, :, j] - hq[:, :, j] * rp[:, :, i]
      print(sigma_pq.shape)




.. py:class:: BaseKGE(args: dict)


   Bases: :py:obj:`BaseKGELightning`

   Base class for all neural network modules.

   Your models should also subclass this class.

   Modules can also contain other Modules, allowing to nest them in
   a tree structure. You can assign the submodules as regular attributes::

       import torch.nn as nn
       import torch.nn.functional as F

       class Model(nn.Module):
           def __init__(self):
               super().__init__()
               self.conv1 = nn.Conv2d(1, 20, 5)
               self.conv2 = nn.Conv2d(20, 20, 5)

           def forward(self, x):
               x = F.relu(self.conv1(x))
               return F.relu(self.conv2(x))

   Submodules assigned in this way will be registered, and will have their
   parameters converted too when you call :meth:`to`, etc.

   .. note::
       As per the example above, an ``__init__()`` call to the parent class
       must be made before assignment on the child.

   :ivar training: Boolean represents whether this module is in training or
                   evaluation mode.
   :vartype training: bool

   .. py:method:: forward_byte_pair_encoded_k_vs_all(x: torch.LongTensor)

      :param x:
      :type x: B x 2 x T


   .. py:method:: forward_byte_pair_encoded_triple(x: Tuple[torch.LongTensor, torch.LongTensor])

      Perform the forward pass for byte pair encoded triples.

      :param x: The input tuple containing byte pair encoded entities and relations.
      :type x: Tuple[torch.LongTensor, torch.LongTensor]

      :returns: The output tensor containing the scores for the byte pair encoded triples.
      :rtype: torch.Tensor


   .. py:method:: init_params_with_sanity_checking()


   .. py:method:: forward(x: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]], y_idx: torch.LongTensor = None)

      Perform the forward pass of the model.

      :param x: The input tensor or a tuple containing the input tensor and target entity indexes.
      :type x: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]]
      :param y_idx: The target entity indexes (default is None).
      :type y_idx: torch.LongTensor, optional

      :returns: The output of the forward pass.
      :rtype: Any


   .. py:method:: forward_triples(x: torch.LongTensor) -> torch.Tensor

      Perform the forward pass for triples.

      :param x: The input tensor containing the indexes of head, relation, and tail entities.
      :type x: torch.LongTensor

      :returns: The output tensor containing the scores for the input triples.
      :rtype: torch.Tensor


   .. py:method:: forward_k_vs_all(*args, **kwargs)

      Forward pass for K vs. All.

      :raises ValueError: This function is not implemented in the current model.


   .. py:method:: forward_k_vs_sample(*args, **kwargs)

      Forward pass for K vs. Sample.

      :raises ValueError: This function is not implemented in the current model.


   .. py:method:: get_triple_representation(idx_hrt)


   .. py:method:: get_head_relation_representation(indexed_triple: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor]

      Get the representation for the head and relation entities.

      :param indexed_triple: The indexes of the head and relation entities.
      :type indexed_triple: torch.LongTensor

      :returns: The representation for the head and relation entities.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_sentence_representation(x: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      Get the representation for a sentence.

      :param x: The input tensor containing the indexes of head, relation, and tail entities.
      :type x: torch.LongTensor

      :returns: The representation for the input sentence.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_bpe_head_and_relation_representation(x: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor]

      Get the representation for BPE head and relation entities.

      :param x:
      :type x: B x 2 x T

      :returns: The representation for BPE head and relation entities.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_embeddings() -> Tuple[numpy.ndarray, numpy.ndarray]

      Get the entity and relation embeddings.

      :returns: The entity and relation embeddings.
      :rtype: Tuple[np.ndarray, np.ndarray]



.. py:class:: PykeenKGE(args: dict)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   A class for using knowledge graph embedding models implemented in Pykeen.

   :param args: A dictionary of arguments containing hyperparameters and settings for the model,
                such as embedding dimensions, random seed, and model-specific kwargs.
   :type args: dict

   .. attribute:: name

      The name identifier for the PykeenKGE model.

      :type: str

   .. attribute:: model

      The Pykeen model instance.

      :type: pykeen.models.base.Model

   .. attribute:: loss_history

      A list to store the training loss history.

      :type: list

   .. attribute:: args

      The arguments used to initialize the model.

      :type: dict

   .. attribute:: entity_embeddings

      Entity embeddings learned by the model.

      :type: torch.nn.Embedding

   .. attribute:: relation_embeddings

      Relation embeddings learned by the model.

      :type: torch.nn.Embedding

   .. attribute:: interaction

      Interaction module used by the Pykeen model.

      :type: pykeen.nn.modules.Interaction

   .. method:: forward_k_vs_all(x: torch.LongTensor) -> torch.FloatTensor

      Compute scores for all entities given a batch of head entities and relations.

   .. method:: forward_triples(x: torch.LongTensor) -> torch.FloatTensor

      Compute scores for a batch of triples.

   .. method:: forward_k_vs_sample(x: torch.LongTensor, target_entity_idx: int)

      Compute scores against a sampled subset of entities.


   .. rubric:: Notes

   This class provides an interface for using knowledge graph embedding models implemented
   in Pykeen. It initializes Pykeen models based on the provided arguments and allows for
   scoring triples and conducting knowledge graph embedding experiments.

   .. py:method:: forward_k_vs_all(x: torch.LongTensor)

      TODO: Format in Numpy-style documentation

      # => Explicit version by this we can apply bn and dropout

      # (1) Retrieve embeddings of heads and relations +  apply Dropout & Normalization if given.
      h, r = self.get_head_relation_representation(x)
      # (2) Reshape (1).
      if self.last_dim > 0:
          h = h.reshape(len(x), self.embedding_dim, self.last_dim)
          r = r.reshape(len(x), self.embedding_dim, self.last_dim)
      # (3) Reshape all entities.
      if self.last_dim > 0:
          t = self.entity_embeddings.weight.reshape(self.num_entities, self.embedding_dim, self.last_dim)
      else:
          t = self.entity_embeddings.weight
      # (4) Call the score_t from interactions to generate triple scores.
      return self.interaction.score_t(h=h, r=r, all_entities=t, slice_size=1)


   .. py:method:: forward_triples(x: torch.LongTensor) -> torch.FloatTensor

      TODO: Format in Numpy-style documentation

      # => Explicit version by this we can apply bn and dropout

      # (1) Retrieve embeddings of heads, relations and tails and apply Dropout & Normalization if given.
      h, r, t = self.get_triple_representation(x)
      # (2) Reshape (1).
      if self.last_dim > 0:
          h = h.reshape(len(x), self.embedding_dim, self.last_dim)
          r = r.reshape(len(x), self.embedding_dim, self.last_dim)
          t = t.reshape(len(x), self.embedding_dim, self.last_dim)
      # (3) Compute the triple score
      return self.interaction.score(h=h, r=r, t=t, slice_size=None, slice_dim=0)


   .. py:method:: forward_k_vs_sample(x: torch.LongTensor, target_entity_idx: int)
      :abstractmethod:

      Forward pass for K vs. Sample.

      :raises ValueError: This function is not implemented in the current model.



.. py:class:: BaseKGE(args: dict)


   Bases: :py:obj:`BaseKGELightning`

   Base class for all neural network modules.

   Your models should also subclass this class.

   Modules can also contain other Modules, allowing to nest them in
   a tree structure. You can assign the submodules as regular attributes::

       import torch.nn as nn
       import torch.nn.functional as F

       class Model(nn.Module):
           def __init__(self):
               super().__init__()
               self.conv1 = nn.Conv2d(1, 20, 5)
               self.conv2 = nn.Conv2d(20, 20, 5)

           def forward(self, x):
               x = F.relu(self.conv1(x))
               return F.relu(self.conv2(x))

   Submodules assigned in this way will be registered, and will have their
   parameters converted too when you call :meth:`to`, etc.

   .. note::
       As per the example above, an ``__init__()`` call to the parent class
       must be made before assignment on the child.

   :ivar training: Boolean represents whether this module is in training or
                   evaluation mode.
   :vartype training: bool

   .. py:method:: forward_byte_pair_encoded_k_vs_all(x: torch.LongTensor)

      :param x:
      :type x: B x 2 x T


   .. py:method:: forward_byte_pair_encoded_triple(x: Tuple[torch.LongTensor, torch.LongTensor])

      Perform the forward pass for byte pair encoded triples.

      :param x: The input tuple containing byte pair encoded entities and relations.
      :type x: Tuple[torch.LongTensor, torch.LongTensor]

      :returns: The output tensor containing the scores for the byte pair encoded triples.
      :rtype: torch.Tensor


   .. py:method:: init_params_with_sanity_checking()


   .. py:method:: forward(x: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]], y_idx: torch.LongTensor = None)

      Perform the forward pass of the model.

      :param x: The input tensor or a tuple containing the input tensor and target entity indexes.
      :type x: Union[torch.LongTensor, Tuple[torch.LongTensor, torch.LongTensor]]
      :param y_idx: The target entity indexes (default is None).
      :type y_idx: torch.LongTensor, optional

      :returns: The output of the forward pass.
      :rtype: Any


   .. py:method:: forward_triples(x: torch.LongTensor) -> torch.Tensor

      Perform the forward pass for triples.

      :param x: The input tensor containing the indexes of head, relation, and tail entities.
      :type x: torch.LongTensor

      :returns: The output tensor containing the scores for the input triples.
      :rtype: torch.Tensor


   .. py:method:: forward_k_vs_all(*args, **kwargs)

      Forward pass for K vs. All.

      :raises ValueError: This function is not implemented in the current model.


   .. py:method:: forward_k_vs_sample(*args, **kwargs)

      Forward pass for K vs. Sample.

      :raises ValueError: This function is not implemented in the current model.


   .. py:method:: get_triple_representation(idx_hrt)


   .. py:method:: get_head_relation_representation(indexed_triple: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor]

      Get the representation for the head and relation entities.

      :param indexed_triple: The indexes of the head and relation entities.
      :type indexed_triple: torch.LongTensor

      :returns: The representation for the head and relation entities.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_sentence_representation(x: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]

      Get the representation for a sentence.

      :param x: The input tensor containing the indexes of head, relation, and tail entities.
      :type x: torch.LongTensor

      :returns: The representation for the input sentence.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_bpe_head_and_relation_representation(x: torch.LongTensor) -> Tuple[torch.FloatTensor, torch.FloatTensor]

      Get the representation for BPE head and relation entities.

      :param x:
      :type x: B x 2 x T

      :returns: The representation for BPE head and relation entities.
      :rtype: Tuple[torch.FloatTensor, torch.FloatTensor]


   .. py:method:: get_embeddings() -> Tuple[numpy.ndarray, numpy.ndarray]

      Get the entity and relation embeddings.

      :returns: The entity and relation embeddings.
      :rtype: Tuple[np.ndarray, np.ndarray]



.. py:class:: FMult(args: dict)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   FMult is a model for learning neural networks on knowledge graphs. It extends
   the base knowledge graph embedding model by integrating neural network computations
   with entity and relation embeddings. The model is designed to work with complex
   embeddings and utilizes a neural network-based approach for embedding interactions.

   :param args: A dictionary of arguments containing hyperparameters and settings for the model,
                such as embedding dimensions and other model-specific parameters.
   :type args: dict

   .. attribute:: name

      The name identifier for the FMult model.

      :type: str

   .. attribute:: entity_embeddings

      Embedding layer for entities in the knowledge graph.

      :type: torch.nn.Embedding

   .. attribute:: relation_embeddings

      Embedding layer for relations in the knowledge graph.

      :type: torch.nn.Embedding

   .. attribute:: k

      Dimension size for reshaping weights in neural network layers.

      :type: int

   .. attribute:: num_sample

      The number of samples to consider in the model computations.

      :type: int

   .. attribute:: gamma

      Randomly initialized weights for the neural network layers.

      :type: torch.Tensor

   .. attribute:: roots

      Precomputed roots for Legendre polynomials.

      :type: torch.Tensor

   .. attribute:: weights

      Precomputed weights for Legendre polynomials.

      :type: torch.Tensor

   .. method:: compute_func(weights: torch.FloatTensor, x: torch.Tensor) -> torch.FloatTensor

      Computes the output of a two-layer neural network for given weights and input.


   .. method:: chain_func(weights: torch.FloatTensor, x: torch.Tensor) -> torch.Tensor

      Chains two linear neural network layers for a given input.


   .. method:: forward_triples(idx_triple: torch.Tensor) -> torch.Tensor

      Performs a forward pass for a batch of triples and computes the embedding interactions.


   .. py:method:: compute_func(weights: torch.FloatTensor, x: torch.Tensor) -> torch.FloatTensor

      Compute the output of a two-layer neural network.

      :param weights: The weights of the neural network, split into two sets for two layers.
      :type weights: torch.FloatTensor
      :param x: The input tensor for the neural network.
      :type x: torch.Tensor

      :returns: The output tensor after passing through the two-layer neural network.
      :rtype: torch.FloatTensor


   .. py:method:: chain_func(weights: torch.FloatTensor, x: torch.Tensor) -> torch.Tensor

      Chain two linear layers of a neural network for given weights and input.

      :param weights: The weights of the neural network, split into two sets for two layers.
      :type weights: torch.FloatTensor
      :param x: The input tensor for the neural network.
      :type x: torch.Tensor

      :returns: The output tensor after chaining the two linear layers.
      :rtype: torch.Tensor


   .. py:method:: forward_triples(idx_triple: torch.Tensor) -> torch.Tensor

      Forward pass for a batch of triples to compute embedding interactions.

      :param idx_triple: Tensor containing indices of triples.
      :type idx_triple: torch.Tensor

      :returns: The computed scores for the batch of triples.
      :rtype: torch.Tensor



.. py:class:: GFMult(args: dict)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   GFMult (Graph Function Multiplication) extends the base knowledge graph embedding
   model by integrating neural network computations with entity and relation embeddings.
   This model is designed to leverage the strengths of neural networks in capturing
   complex interactions within knowledge graphs.

   :param args: A dictionary of arguments containing hyperparameters and settings for the model,
                such as embedding dimensions, learning rate, and other model-specific parameters.
   :type args: dict

   .. attribute:: name

      The name identifier for the GFMult model.

      :type: str

   .. attribute:: entity_embeddings

      Embedding layer for entities in the knowledge graph.

      :type: torch.nn.Embedding

   .. attribute:: relation_embeddings

      Embedding layer for relations in the knowledge graph.

      :type: torch.nn.Embedding

   .. attribute:: k

      The dimension size for reshaping weights in neural network layers.

      :type: int

   .. attribute:: num_sample

      The number of samples to use in the model computations.

      :type: int

   .. attribute:: roots

      Precomputed roots for Legendre polynomials, repeated for each dimension.

      :type: torch.Tensor

   .. attribute:: weights

      Precomputed weights for Legendre polynomials.

      :type: torch.Tensor

   .. method:: compute_func(weights: torch.FloatTensor, x: torch.Tensor) -> torch.FloatTensor

      Computes the output of a two-layer neural network for given weights and input.


   .. method:: chain_func(weights: torch.FloatTensor, x: torch.Tensor) -> torch.Tensor

      Chains two linear neural network layers for a given input.


   .. method:: forward_triples(idx_triple: torch.Tensor) -> torch.Tensor

      Performs a forward pass for a batch of triples and computes the embedding interactions.


   .. py:method:: compute_func(weights: torch.FloatTensor, x: torch.Tensor) -> torch.FloatTensor

      Compute the output of a two-layer neural network.

      :param weights: The weights of the neural network, split into two sets for two layers.
      :type weights: torch.FloatTensor
      :param x: The input tensor for the neural network.
      :type x: torch.Tensor

      :returns: The output tensor after passing through the two-layer neural network.
      :rtype: torch.FloatTensor


   .. py:method:: chain_func(weights: torch.FloatTensor, x: torch.Tensor) -> torch.Tensor

      Chain two linear layers of a neural network for given weights and input.

      :param weights: The weights of the neural network, split into two sets for two layers.
      :type weights: torch.FloatTensor
      :param x: The input tensor for the neural network.
      :type x: torch.Tensor

      :returns: The output tensor after chaining the two linear layers.
      :rtype: torch.Tensor


   .. py:method:: forward_triples(idx_triple: torch.Tensor) -> torch.Tensor

      Forward pass for a batch of triples to compute embedding interactions.

      :param idx_triple: Tensor containing indices of triples.
      :type idx_triple: torch.Tensor

      :returns: The computed scores for the batch of triples.
      :rtype: torch.Tensor



.. py:class:: FMult2(args: dict)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   FMult2 is a model for learning neural networks on knowledge graphs, offering
   enhanced capabilities for capturing complex interactions in the graph. It extends
   the base knowledge graph embedding model by integrating multi-layer neural network
   computations with entity and relation embeddings.

   :param args: A dictionary of arguments containing hyperparameters and settings for the model,
                such as embedding dimensions, learning rate, number of layers, and other model-specific parameters.
   :type args: dict

   .. attribute:: name

      The name identifier for the FMult2 model.

      :type: str

   .. attribute:: n_layers

      Number of layers in the neural network.

      :type: int

   .. attribute:: k

      Dimension size for reshaping weights in neural network layers.

      :type: int

   .. attribute:: n

      The number of discrete points for computations.

      :type: int

   .. attribute:: a

      Lower bound of the range for discrete points.

      :type: float

   .. attribute:: b

      Upper bound of the range for discrete points.

      :type: float

   .. attribute:: score_func

      The scoring function used in the model.

      :type: str

   .. attribute:: discrete_points

      Tensor of discrete points used in the computations.

      :type: torch.Tensor

   .. attribute:: entity_embeddings

      Embedding layer for entities in the knowledge graph.

      :type: torch.nn.Embedding

   .. attribute:: relation_embeddings

      Embedding layer for relations in the knowledge graph.

      :type: torch.nn.Embedding

   .. method:: build_func(Vec: torch.Tensor) -> Tuple[List[torch.Tensor], torch.Tensor]

      Constructs a multi-layer neural network from a vector representation.


   .. method:: build_chain_funcs(list_Vec: List[torch.Tensor]) -> Tuple[List[torch.Tensor], torch.Tensor]

      Builds chained functions from a list of vector representations.


   .. method:: compute_func(W: List[torch.Tensor], b: torch.Tensor, x: torch.Tensor) -> torch.FloatTensor

      Computes the output of a multi-layer neural network.


   .. method:: function(list_W: List[List[torch.Tensor]], list_b: List[torch.Tensor]) -> Callable[[torch.Tensor], torch.Tensor]

      Defines a function for neural network computation based on weights and biases.


   .. method:: trapezoid(list_W: List[List[torch.Tensor]], list_b: List[torch.Tensor]) -> torch.Tensor

      Applies the trapezoidal rule for integration on the function output.


   .. method:: forward_triples(idx_triple: torch.Tensor) -> torch.Tensor

      Performs a forward pass for a batch of triples and computes the embedding interactions.


   .. py:method:: build_func(Vec: torch.Tensor) -> Tuple[List[torch.Tensor], torch.Tensor]

      Constructs a multi-layer neural network from a vector representation.

      :param Vec: The vector representation from which the neural network is constructed.
      :type Vec: torch.Tensor

      :returns: A tuple containing the list of weight matrices for each layer and the bias vector.
      :rtype: Tuple[List[torch.Tensor], torch.Tensor]


   .. py:method:: build_chain_funcs(list_Vec: List[torch.Tensor]) -> Tuple[List[torch.Tensor], torch.Tensor]

      Builds chained functions from a list of vector representations. This method
      constructs a sequence of neural network layers and their corresponding biases
      based on the provided vector representations.

      Each vector representation in the list is first transformed into a set of weights
      and biases for a neural network layer using the `build_func` method. The method
      then computes a chained multiplication of these weights, adjusted by biases,
      to form a composite neural network function.

      :param list_Vec: A list of vector representations, each corresponding to a set of parameters
                       for constructing a neural network layer.
      :type list_Vec: List[torch.Tensor]

      :returns: A tuple where the first element is a list of weight tensors for each layer of
                the composite neural network, and the second element is the bias tensor for
                the last layer in the list.
      :rtype: Tuple[List[torch.Tensor], torch.Tensor]

      .. rubric:: Notes

      This method is specifically designed to work with the neural network architecture
      defined in the FMult2 model. It assumes that each vector in `list_Vec` can be
      decomposed into weights and biases suitable for a layer in a neural network.


   .. py:method:: compute_func(W: List[torch.Tensor], b: torch.Tensor, x: torch.Tensor) -> torch.FloatTensor

      Computes the output of a multi-layer neural network defined by the given weights and bias.

      This method sequentially applies a series of matrix multiplications and non-linear
      transformations to an input tensor `x`, using the provided weights `W`. The method
      alternates between applying a non-linear function (tanh) and a linear transformation
      to the intermediate outputs. The final output is adjusted with a bias term `b`.

      :param W: A list of weight tensors for each layer in the neural network. Each tensor
                in the list represents the weights of a layer.
      :type W: List[torch.Tensor]
      :param b: The bias tensor to be added to the output of the final layer.
      :type b: torch.Tensor
      :param x: The input tensor to be processed by the neural network.
      :type x: torch.Tensor

      :returns: The output tensor after processing by the multi-layer neural network.
      :rtype: torch.FloatTensor

      .. rubric:: Notes

      The method assumes an odd-indexed layer applies a non-linearity (tanh), while
      even-indexed layers apply linear transformations. This design choice is based on
      empirical observations for better performance in the context of the FMult2 model.


   .. py:method:: function(list_W: List[List[torch.Tensor]], list_b: List[torch.Tensor]) -> Callable[[torch.Tensor], torch.Tensor]

      Defines a function that computes the output of a composite neural network.
      This higher-order function returns a callable that applies a sequence of
      transformations defined by the provided weights and biases.

      The returned function (`f`) takes an input tensor `x` and applies a series of
      neural network computations on it. If only one set of weights and biases is provided,
      it directly computes the output using `compute_func`. Otherwise, it sequentially
      multiplies the outputs of multiple calls to `compute_func`, each using a different
      set of weights and biases from `list_W` and `list_b`.

      :param list_W: A list where each element is a list of weight tensors for a neural network.
      :type list_W: List[List[torch.Tensor]]
      :param list_b: A list of bias tensors corresponding to each set of weights in `list_W`.
      :type list_b: List[torch.Tensor]

      :returns: A function that takes an input tensor and returns the output of the composite
                neural network.
      :rtype: Callable[[torch.Tensor], torch.Tensor]

      .. rubric:: Notes

      This method is part of the FMult2 model's approach to construct complex scoring
      functions for knowledge graph embeddings. The flexibility in combining multiple
      neural network layers enables capturing intricate patterns in the data.


   .. py:method:: trapezoid(list_W: List[List[torch.Tensor]], list_b: List[torch.Tensor]) -> torch.Tensor

      Computes the integral of the output of a composite neural network function over a
      range of discrete points using the trapezoidal rule.

      This method first constructs a composite neural network function using the `function`
      method with the provided weights `list_W` and biases `list_b`. It then evaluates this
      function at a series of discrete points (`self.discrete_points`) and applies the
      trapezoidal rule to approximate the integral of the function over these points. The
      sum of the integral approximations across all dimensions is returned.

      :param list_W: A list where each element is a list of weight tensors for a neural network.
      :type list_W: List[List[torch.Tensor]]
      :param list_b: A list of bias tensors corresponding to each set of weights in `list_W`.
      :type list_b: List[torch.Tensor]

      :returns: The sum of the integral of the composite function's output over the range
                of discrete points, computed using the trapezoidal rule.
      :rtype: torch.Tensor

      .. rubric:: Notes

      The trapezoidal rule is a numerical method to approximate definite integrals.
      In the context of the FMult2 model, this method is used to integrate the output
      of the neural network over a range of inputs, which is crucial for certain types
      of calculations in knowledge graph embeddings.


   .. py:method:: forward_triples(idx_triple: torch.Tensor) -> torch.Tensor

      Forward pass for a batch of triples to compute embedding interactions.

      :param idx_triple: Tensor containing indices of triples.
      :type idx_triple: torch.Tensor

      :returns: The computed scores for the batch of triples.
      :rtype: torch.Tensor



.. py:class:: LFMult1(args)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   Embedding with trigonometric functions. We represent all entities and relations in the complex number space as:
   f(x) = \sum_{k=0}^{k=d-1}wk e^{kix}. and use the three differents scoring function as in the paper to evaluate the score

   .. py:method:: forward_triples(idx_triple)

      Perform the forward pass for triples.

      :param x: The input tensor containing the indexes of head, relation, and tail entities.
      :type x: torch.LongTensor

      :returns: The output tensor containing the scores for the input triples.
      :rtype: torch.Tensor


   .. py:method:: tri_score(h, r, t)


   .. py:method:: vtp_score(h, r, t)



.. py:class:: LFMult(args)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   Embedding with polynomial functions. We represent all entities and relations in the polynomial space as:
   f(x) = \sum_{i=0}^{d-1} a_k x^{i%d} and use the three differents scoring function as in the paper to evaluate the score.
   We also consider combining with Neural Networks.

   .. py:method:: forward_triples(idx_triple)

      Perform the forward pass for triples.

      :param x: The input tensor containing the indexes of head, relation, and tail entities.
      :type x: torch.LongTensor

      :returns: The output tensor containing the scores for the input triples.
      :rtype: torch.Tensor


   .. py:method:: construct_multi_coeff(x)


   .. py:method:: poly_NN(x, coefh, coefr, coeft)

      Constructing a 2 layers NN to represent the embeddings.
      h = \sigma(wh^T x + bh ),  r = \sigma(wr^T x + br ),  t = \sigma(wt^T x + bt )


   .. py:method:: linear(x, w, b)


   .. py:method:: scalar_batch_NN(a, b, c)

      element wise multiplication between a,b and c:
      Inputs : a, b, c ====> torch.tensor of size batch_size x m x d
      Output : a tensor of size batch_size x d


   .. py:method:: tri_score(coeff_h, coeff_r, coeff_t)

      this part implement the trilinear scoring techniques:

      score(h,r,t) = \int_{0}{1} h(x)r(x)t(x) dx = \sum_{i,j,k = 0}^{d-1} \dfrac{a_i*b_j*c_k}{1+(i+j+k)%d}

      1. generate the range for i,j and k from [0 d-1]

      2. perform
      \dfrac{a_i*b_j*c_k}{1+(i+j+k)%d} in parallel for every batch

      3. take the sum over each batch



   .. py:method:: vtp_score(h, r, t)

      this part implement the vector triple product scoring techniques:

      score(h,r,t) = \int_{0}{1} h(x)r(x)t(x) dx = \sum_{i,j,k = 0}^{d-1} \dfrac{a_i*c_j*b_k - b_i*c_j*a_k}{(1+(i+j)%d)(1+k)}

      1. generate the range for i,j and k from [0 d-1]

      2. Compute the first and second terms of the sum

      3.  Multiply with then denominator and take the sum

      4. take the sum over each batch



   .. py:method:: comp_func(h, r, t)

      this part implement the function composition scoring techniques: i.e. score = <hor, t>


   .. py:method:: polynomial(coeff, x, degree)

      This function takes a matrix tensor of coefficients (coeff), a tensor vector of points x  and range of integer [0,1,...d]
      and return a vector tensor (coeff[0][0] + coeff[0][1]x +...+ coeff[0][d]x^d,
                          coeff[1][0] + coeff[1][1]x +...+ coeff[1][d]x^d)
                                  ....


   .. py:method:: pop(coeff, x, degree)

      This function allow us to evaluate the composition of two polynomes without for loops :)
      it takes a matrix tensor of coefficients (coeff), a matrix tensor of points x  and range of integer [0,1,...d]
          and return a tensor (coeff[0][0] + coeff[0][1]x +...+ coeff[0][d]x^d,
                              coeff[1][0] + coeff[1][1]x +...+ coeff[1][d]x^d)
                                      ....



.. py:class:: DualE(args)


   Bases: :py:obj:`dicee.models.base_model.BaseKGE`

   Dual Quaternion Knowledge Graph Embeddings (https://ojs.aaai.org/index.php/AAAI/article/download/16850/16657)

   .. py:method:: kvsall_score(e_1_h, e_2_h, e_3_h, e_4_h, e_5_h, e_6_h, e_7_h, e_8_h, e_1_t, e_2_t, e_3_t, e_4_t, e_5_t, e_6_t, e_7_t, e_8_t, r_1, r_2, r_3, r_4, r_5, r_6, r_7, r_8) -> torch.tensor

      KvsAll scoring function

      Input
      ---------
      x: torch.LongTensor with (n, ) shape

      Output
      -------
      torch.FloatTensor with (n) shape


   .. py:method:: forward_triples(idx_triple: torch.tensor) -> torch.tensor

      Negative Sampling forward pass:

      Input
      ---------
      x: torch.LongTensor with (n, ) shape

      Output
      -------
      torch.FloatTensor with (n) shape


   .. py:method:: forward_k_vs_all(x)

      KvsAll forward pass

      Input
      ---------
      x: torch.LongTensor with (n, ) shape

      Output
      -------
      torch.FloatTensor with (n) shape



   .. py:method:: T(x: torch.tensor) -> torch.tensor

      Transpose function

      Input: Tensor with shape (nxm)
      Output: Tensor with shape (mxn)



