{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training a KGE model with DDP on KINSHIP with torchDDP with 128 CPUs and NVIDIA GeForce RTX 3090\n",
    "```torchrun --standalone --nproc_per_node=gpu main.py --model 'ComplEx' --embedding_dim 32 --num_epochs 500 --path_dataset_folder 'KGs/KINSHIP' --trainer torchDDP --eval_mode 'test'```\n",
    "\n",
    "### Here are the last few lines of the log file:\n",
    "Global1 | Local1 | Epoch:500 | Batch:2 | Loss:0.036598145961761475 |ForwardBackwardUpdate:0.00sec | BatchConst.:0.01sec\n",
    "Global0 | Local0 | Epoch:500 | Batch:2 | Loss:0.03864430636167526 |ForwardBackwardUpdate:0.00sec | BatchConst.:0.01sec\n",
    "Done ! It took 12.274 seconds.\n",
    "Done ! It took 12.276 seconds.\n",
    "\n",
    "*** Save Trained Model ***\n",
    "Took 0.0007 seconds | Current Memory Usage  3189.0 in MB\n",
    "Total computation time: 12.364 seconds\n",
    "*** Save Trained Model ***\n",
    "Took 0.0008 seconds | Current Memory Usage  2645.0 in MB\n",
    "Total computation time: 12.364 seconds\n",
    "Evaluate ComplEx on Test set: Evaluate ComplEx on Test set: Evaluate ComplEx on Test set\n",
    "{'H@1': 0.6191806331471136, 'H@3': 0.8514897579143389, 'H@10': 0.9706703910614525, 'MRR': 0.7481822177321609}\n",
    "Evaluate ComplEx on Test set\n",
    "{'H@1': 0.6191806331471136, 'H@3': 0.8514897579143389, 'H@10': 0.9706703910614525, 'MRR': 0.7481822177321609}\n",
    "\n",
    "### We see two eval result as we have to GPUs.\n",
    "\n",
    "### Training a KGE model with CPU\n",
    "```torchrun --standalone --nproc_per_node=gpu main.py --model 'ComplEx' --embedding_dim 32 --num_epochs 500 --path_dataset_folder 'KGs/KINSHIP' --trainer torchCPU --eval_mode 'test'```\n",
    "\n",
    "Epoch:500 | Batch:1 | Loss:0.05302952229976654 |ForwardBackwardUpdate:0.00secs | Mem. Usage  497.07MB\n",
    "Epoch:500 | Batch:2 | Loss:0.0575931221 |ForwardBackwardUpdate:0.00sec | BatchConst.:0.01sec | Mem. Usage  497.07MB  avail. 1.5 %\n",
    "Epoch:500 | Batch:3 | Loss:0.0585726425 |ForwardBackwardUpdate:0.00sec | BatchConst.:0.01sec | Mem. Usage  497.07MB  avail. 1.5 %\n",
    "Epoch:500 | Batch:4 | Loss:0.0551908500 |ForwardBackwardUpdate:0.00sec | BatchConst.:0.00sec | Mem. Usage  497.07MB  avail. 1.5 %\n",
    "Done ! It took 23.230 seconds.\n",
    "*** Save Trained Model ***\n",
    "Took 0.0006 seconds | Current Memory Usage  497.25 in MB\n",
    "Total computation time: 23.308 seconds\n",
    "Evaluate ComplEx on Test set: Evaluate ComplEx on Test set\n",
    "{'H@1': 0.6014897579143389, 'H@3': 0.8212290502793296, 'H@10': 0.9599627560521415, 'MRR': 0.7271467645821516}\n",
    "\n",
    "# Multi-node GPU training\n",
    "Execute the following command on the node 1\n",
    "```torchrun --nnodes 2 --nproc_per_node=gpu  --node_rank 0 --rdzv_id 456 --rdzv_backend c10d --rdzv_endpoint=nebula main.py --model 'ComplEx' --embedding_dim 32 --num_epochs 100 --path_dataset_folder 'KGs/WN18RR' --trainer torchDDP```\n",
    "Execute the following command on the node 2\n",
    "```torchrun --nnodes 2 --nproc_per_node=gpu  --node_rank 1 --rdzv_id 456 --rdzv_backend c10d --rdzv_endpoint=nebula main.py --model 'ComplEx' --embedding_dim 32 --num_epochs 100 --path_dataset_folder 'KGs/WN18RR' --trainer torchDDP```\n",
    "\n",
    "### Node 1\n",
    "Global:3 | Local:1 | Epoch:100 | Loss:0.00011253 | Runtime:0.042mins\n",
    "Global:2 | Local:0 | Epoch:100 | Batch:26 | Loss:0.00011469019227661192 |ForwardBackwardUpdate:0.01sec | BatchConst.:0.09sec\n",
    "Global:2 | Local:0 | Epoch:100 | Loss:0.00011178 | Runtime:0.042mins\n",
    "Done ! It took 4.440 minutes.\n",
    "Done ! It took 4.441 minutes.\n",
    "\n",
    "### Node 2\n",
    "```\n",
    "Global:1 | Local:1 | Epoch:100 | Batch:25 | Loss:0.00011904298298759386 |ForwardBackwardUpdate:0.01sec | BatchConst.:0.09sec\n",
    "Global:0 | Local:0 | Epoch:100 | Batch:25 | Loss:0.00011089341569459066 |ForwardBackwardUpdate:0.01sec | BatchConst.:0.09sec\n",
    "Global:1 | Local:1 | Epoch:100 | Batch:26 | Loss:0.00011964481382165104 |ForwardBackwardUpdate:0.01sec | BatchConst.:0.08sec\n",
    "Epoch:100 | Loss:0.00011271 | Runtime:0.042mins\n",
    "Global:0 | Local:0 | Epoch:100 | Batch:26 | Loss:9.990083344746381e-05 |ForwardBackwardUpdate:0.01sec | BatchConst.:0.05sec\n",
    "Epoch:100 | Loss:0.00010982 | Runtime:0.042mins\n",
    "Done ! It took 4.421 minutes.\n",
    "Done ! It took 4.419 minutes.\n",
    "```\n",
    "\n",
    "# TODO:Pytorch-Lightning Trainer\n",
    "\n",
    "By setting --trainer PL, pytorch-lightning can be used to train a knowledge graph embedding model\n",
    "\n",
    "### Training with two GPUs\n",
    "python main.py --model 'DistMult' --trainer PL --num_epochs 10 --gpus 2\n",
    "\n",
    "### Using two GPUs with DDP\n",
    "python main.py --model 'DistMult' --trainer PL --num_epochs 10 --accelerator gpu\n",
    "\n",
    "\n",
    "### Using two GPUs with DDP with Low-Precision\n",
    "python main.py --model 'DistMult' --trainer PL --num_epochs 50 --accelerator gpu --precision 16\n",
    "\n",
    "python main.py --model 'DistMult' --trainer PL --num_epochs 50 --accelerator gpu --precision bf16\n",
    "\n",
    "\n",
    "### Using two GPUs with Model Parallel ([Deep-Speed 3](https://lightning.ai/docs/pytorch/stable/advanced/model_parallel.html#deepspeed-zero-stage-3-offload)) and Low-Precision\n",
    "\n",
    "python main.py --path_dataset_folder 'KGs/YAGO3-10' --trainer PL --accelerator gpu --strategy deepspeed_stage_3 --precision 16\n",
    "\n",
    "\n",
    "### Using two GPUs with Mult-node\n",
    "torchrun --nnodes 2 --nproc_per_node=gpu --node_rank 0 --rdzv_id 456 --rdzv_backend c10d --rdzv_endpoint=nebula main.py --path_dataset_folder 'KGs/YAGO3-10' --trainer torchDDP\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}