from .util import read_from_disk, read_from_triple_store
import glob
import pandas as pd
import numpy as np


class ReadFromDisk:
    """
    Read the data from disk into memory.

    This class is responsible for loading a knowledge graph from various sources such as
    disk files, triple stores, or SPARQL endpoints, and then making it available in memory
    for further processing.

    Attributes
    ----------
    kg : object
        An instance representing the knowledge graph.

    Methods
    -------
    start() -> None
        Read a knowledge graph from disk into memory.
    add_noisy_triples_into_training() -> None
        Add noisy triples into the training set of the knowledge graph.
    """

    def __init__(self, kg):
        self.kg = kg

    def start(self) -> None:
        """
        Read a knowledge graph from disk into memory.

        This method reads the knowledge graph data from the specified source (disk, triple store,
        or SPARQL endpoint) and loads it into memory. The data is made available in the
        train_set, test_set, and valid_set attributes of the knowledge graph instance.

        Parameters
        ----------
        None

        Returns
        -------
        None

        Raises
        ------
        RuntimeError
            If the data source is invalid or not specified correctly.
        """
        if self.kg.path_single_kg is not None:
            self.kg.raw_train_set = read_from_disk(
                self.kg.path_single_kg,
                self.kg.read_only_few,
                self.kg.sample_triples_ratio,
                backend=self.kg.backend,
            )
            if self.kg.add_noise_rate:
                self.add_noisy_triples_into_training()

            self.kg.raw_valid_set = None
            self.kg.raw_test_set = None
        elif self.kg.sparql_endpoint is not None:
            self.kg.raw_train_set = read_from_triple_store(
                endpoint=self.kg.sparql_endpoint
            )
            self.kg.raw_valid_set = None
            self.kg.raw_test_set = None
        elif self.kg.dataset_dir:
            for i in glob.glob(self.kg.dataset_dir + "/*"):
                if "train" in i:
                    self.kg.raw_train_set = read_from_disk(
                        i,
                        self.kg.read_only_few,
                        self.kg.sample_triples_ratio,
                        backend=self.kg.backend,
                    )
                    if self.kg.add_noise_rate:
                        self.add_noisy_triples_into_training()
                elif "test" in i and self.kg.eval_model is not None:
                    self.kg.raw_test_set = read_from_disk(i, backend=self.kg.backend)
                elif "valid" in i and self.kg.eval_model is not None:
                    self.kg.raw_valid_set = read_from_disk(i, backend=self.kg.backend)
                else:
                    print(f"Not processed data: {i}")
        else:
            raise RuntimeError(
                f"Invalid data:{self.kg.data_dir}\t{self.kg.sparql_endpoint}\t{self.kg.path_single_kg}"
            )

    def add_noisy_triples_into_training(self) -> None:
        """
        Add noisy triples into the training set of the knowledge graph.

        This method injects a specified proportion of noisy triples into the training set.
        Noisy triples are randomly generated by shuffling the entities and relations in the
        knowledge graph. The purpose of adding noisy triples is often to test the robustness
        of the model or to augment the training data.

        Parameters
        ----------
        None

        Returns
        -------
        None

        Notes
        -----
        The number of noisy triples added is determined by the 'add_noise_rate' attribute
        of the knowledge graph. The method ensures that the total number of triples (original
        plus noisy) in the training set matches the expected count after adding the noisy triples.
        """
        num_noisy_triples = int(len(self.kg.train_set) * self.kg.add_noise_rate)
        s = len(self.kg.train_set)
        list_of_entities = pd.unique(
            self.kg.train_set[["subject", "object"]].values.ravel("K")
        )
        self.kg.train_set = pd.concat(
            [
                self.kg.train_set,
                # Noisy triples
                pd.DataFrame(
                    {
                        "subject": np.random.choice(
                            list_of_entities, num_noisy_triples
                        ),
                        "relation": np.random.choice(
                            pd.unique(
                                self.kg.train_set[["relation"]].values.ravel("K")
                            ),
                            num_noisy_triples,
                        ),
                        "object": np.random.choice(list_of_entities, num_noisy_triples),
                    }
                ),
            ],
            ignore_index=True,
        )

        assert s + num_noisy_triples == len(self.kg.train_set)
