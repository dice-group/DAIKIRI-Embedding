<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>dicee.callbacks &mdash; DICE Embeddings 0.1.3.2 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=8775fe07" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=eafc0fe6" />
      <link rel="stylesheet" type="text/css" href="../../../_static/theme.css?v=ea877efc" />
      <link rel="stylesheet" type="text/css" href="../../../_static/theme_tweak.css?v=f0ad19f3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=8775fe07" />

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=c6726a90"></script>
        <script src="../../../_static/doctools.js?v=888ff710"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="dicee.config" href="../config/index.html" />
    <link rel="prev" title="dicee.analyse_experiments" href="../analyse_experiments/index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            DICE Embeddings
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html">Dicee Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#installation">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#download-knowledge-graphs">Download Knowledge Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#knowledge-graph-embedding-models">Knowledge Graph Embedding Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#how-to-train">How to Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#creating-an-embedding-vector-database">Creating an Embedding Vector Database</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#answering-complex-queries">Answering Complex Queries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#predicting-missing-links">Predicting Missing Links</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#downloading-pretrained-models">Downloading Pretrained Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#how-to-deploy">How to Deploy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#docker">Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#how-to-cite">How to cite</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee</span></code></a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#subpackages">Subpackages</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#submodules">Submodules</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../abstracts/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.abstracts</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../analyse_experiments/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.analyse_experiments</span></code></a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.callbacks</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#module-contents">Module Contents</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#classes">Classes</a></li>
<li class="toctree-l5"><a class="reference internal" href="#functions">Functions</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#dicee.callbacks.AccumulateEpochLossCallback"><code class="docutils literal notranslate"><span class="pre">AccumulateEpochLossCallback</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.callbacks.PrintCallback"><code class="docutils literal notranslate"><span class="pre">PrintCallback</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.callbacks.KGESaveCallback"><code class="docutils literal notranslate"><span class="pre">KGESaveCallback</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.callbacks.PseudoLabellingCallback"><code class="docutils literal notranslate"><span class="pre">PseudoLabellingCallback</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.callbacks.estimate_q"><code class="docutils literal notranslate"><span class="pre">estimate_q()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.callbacks.compute_convergence"><code class="docutils literal notranslate"><span class="pre">compute_convergence()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.callbacks.PPE"><code class="docutils literal notranslate"><span class="pre">PPE</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.callbacks.ASWA"><code class="docutils literal notranslate"><span class="pre">ASWA</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.callbacks.FPPE"><code class="docutils literal notranslate"><span class="pre">FPPE</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.callbacks.Eval"><code class="docutils literal notranslate"><span class="pre">Eval</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.callbacks.KronE"><code class="docutils literal notranslate"><span class="pre">KronE</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.callbacks.Perturb"><code class="docutils literal notranslate"><span class="pre">Perturb</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../config/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.config</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../dataset_classes/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.dataset_classes</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../eval_static_funcs/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.eval_static_funcs</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../evaluator/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.evaluator</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../executer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.executer</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../knowledge_graph/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.knowledge_graph</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../knowledge_graph_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.knowledge_graph_embeddings</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../query_generator/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.query_generator</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../sanity_checkers/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.sanity_checkers</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../static_funcs/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.static_funcs</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../static_funcs_training/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.static_funcs_training</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../static_preprocess_funcs/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.static_preprocess_funcs</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#package-contents">Package Contents</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">DICE Embeddings</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee</span></code></a></li>
      <li class="breadcrumb-item active"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.callbacks</span></code></li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/autoapi/dicee/callbacks/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-dicee.callbacks">
<span id="dicee-callbacks"></span><h1><a class="reference internal" href="#module-dicee.callbacks" title="dicee.callbacks"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.callbacks</span></code></a><a class="headerlink" href="#module-dicee.callbacks" title="Link to this heading"></a></h1>
<section id="module-contents">
<h2>Module Contents<a class="headerlink" href="#module-contents" title="Link to this heading"></a></h2>
<section id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Link to this heading"></a></h3>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.callbacks.AccumulateEpochLossCallback" title="dicee.callbacks.AccumulateEpochLossCallback"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AccumulateEpochLossCallback</span></code></a></p></td>
<td><p>A callback to accumulate and save epoch losses to a CSV file at the end of training.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.callbacks.PrintCallback" title="dicee.callbacks.PrintCallback"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PrintCallback</span></code></a></p></td>
<td><p>A callback that prints the start time of training and its total runtime upon completion.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.callbacks.KGESaveCallback" title="dicee.callbacks.KGESaveCallback"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KGESaveCallback</span></code></a></p></td>
<td><p>A callback to save the model periodically during training.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.callbacks.PseudoLabellingCallback" title="dicee.callbacks.PseudoLabellingCallback"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PseudoLabellingCallback</span></code></a></p></td>
<td><p>A callback for implementing pseudo-labelling during training.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.callbacks.PPE" title="dicee.callbacks.PPE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PPE</span></code></a></p></td>
<td><p>Polyak Parameter Ensemble (PPE) callback for maintaining a running average of model parameters.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.callbacks.ASWA" title="dicee.callbacks.ASWA"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ASWA</span></code></a></p></td>
<td><p>Implements the Adaptive Stochastic Weight Averaging (ASWA) technique.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.callbacks.FPPE" title="dicee.callbacks.FPPE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FPPE</span></code></a></p></td>
<td><p>import matplotlib.pyplot as plt</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.callbacks.Eval" title="dicee.callbacks.Eval"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Eval</span></code></a></p></td>
<td><p>Callback for evaluating the model at certain epochs during training and logging the results.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.callbacks.KronE" title="dicee.callbacks.KronE"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KronE</span></code></a></p></td>
<td><p>Callback for augmenting triple representations with Kronecker product embeddings during training.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.callbacks.Perturb" title="dicee.callbacks.Perturb"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Perturb</span></code></a></p></td>
<td><p>Implements a three-level perturbation technique for knowledge graph embedding models during training.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="functions">
<h3>Functions<a class="headerlink" href="#functions" title="Link to this heading"></a></h3>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.callbacks.estimate_q" title="dicee.callbacks.estimate_q"><code class="xref py py-obj docutils literal notranslate"><span class="pre">estimate_q</span></code></a>(→ float)</p></td>
<td><p>Estimate the rate of convergence, q, from a sequence of errors.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.callbacks.compute_convergence" title="dicee.callbacks.compute_convergence"><code class="xref py py-obj docutils literal notranslate"><span class="pre">compute_convergence</span></code></a>(→ float)</p></td>
<td><p>Compute the convergence rate of the last <cite>i</cite> elements in a sequence.</p></td>
</tr>
</tbody>
</table>
<dl class="py class">
<dt class="sig sig-object py" id="dicee.callbacks.AccumulateEpochLossCallback">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.callbacks.</span></span><span class="sig-name descname"><span class="pre">AccumulateEpochLossCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.callbacks.AccumulateEpochLossCallback" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="../abstracts/index.html#dicee.abstracts.AbstractCallback" title="dicee.abstracts.AbstractCallback"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.abstracts.AbstractCallback</span></code></a></p>
<p>A callback to accumulate and save epoch losses to a CSV file at the end of training.</p>
<p>This callback listens to the end of the training process and saves the accumulated
epoch losses stored in the model’s loss history to a CSV file. The file is saved
in the specified directory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>path</strong> (<em>str</em>) – The directory path where the epoch loss CSV file will be saved.</p>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.callbacks.AccumulateEpochLossCallback.path">
<span class="sig-name descname"><span class="pre">path</span></span><a class="headerlink" href="#dicee.callbacks.AccumulateEpochLossCallback.path" title="Link to this definition"></a></dt>
<dd><p>Stores the provided directory path for later use in saving the epoch losses.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.AccumulateEpochLossCallback.on_fit_end">
<span class="sig-name descname"><span class="pre">on_fit_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">lightning.Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dicee.callbacks.AccumulateEpochLossCallback.on_fit_end" title="Link to this definition"></a></dt>
<dd><p>Invoked at the end of the training process to save the epoch losses.</p>
<p>This method is called automatically by the training loop at the end of training.
It retrieves the loss history from the model and saves it as a CSV file in the
specified directory.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<em>Trainer</em>) – The trainer instance conducting the training process. Not used in this method,
but required for compatibility with the callback interface.</p></li>
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The model being trained. This model should have a <cite>loss_history</cite> attribute
containing the losses of each epoch.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.callbacks.PrintCallback">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.callbacks.</span></span><span class="sig-name descname"><span class="pre">PrintCallback</span></span><a class="headerlink" href="#dicee.callbacks.PrintCallback" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="../abstracts/index.html#dicee.abstracts.AbstractCallback" title="dicee.abstracts.AbstractCallback"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.abstracts.AbstractCallback</span></code></a></p>
<p>A callback that prints the start time of training and its total runtime upon completion.</p>
<p>This callback demonstrates a simple usage of the PyTorch Lightning callback system,
printing a message when the training starts and another when it ends, showing how
long the training took.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.PrintCallback.on_fit_start">
<span class="sig-name descname"><span class="pre">on_fit_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">lightning.Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pl_module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">lightning.LightningModule</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.callbacks.PrintCallback.on_fit_start" title="Link to this definition"></a></dt>
<dd><p>Invoked at the start of the fit process.</p>
<p>Prints a message indicating that the training is starting, along with the current date and time.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<em>Trainer</em>) – The trainer instance conducting the training process.</p></li>
<li><p><strong>pl_module</strong> (<em>LightningModule</em>) – The LightningModule instance being trained.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.PrintCallback.on_fit_end">
<span class="sig-name descname"><span class="pre">on_fit_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">lightning.Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pl_module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">lightning.LightningModule</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.callbacks.PrintCallback.on_fit_end" title="Link to this definition"></a></dt>
<dd><p>Invoked at the end of the fit process.</p>
<p>Calculates and prints the total training time in an appropriate time unit (seconds, minutes, or hours).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<em>Trainer</em>) – The trainer instance conducting the training process.</p></li>
<li><p><strong>pl_module</strong> (<em>LightningModule</em>) – The LightningModule instance that was trained.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.PrintCallback.on_train_batch_end">
<span class="sig-name descname"><span class="pre">on_train_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.callbacks.PrintCallback.on_train_batch_end" title="Link to this definition"></a></dt>
<dd><p>Dummy method for handling the end of a training batch. Implemented as a placeholder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – Variable length argument list.</p></li>
<li><p><strong>**kwargs</strong> – Arbitrary keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.PrintCallback.on_train_epoch_end">
<span class="sig-name descname"><span class="pre">on_train_epoch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.callbacks.PrintCallback.on_train_epoch_end" title="Link to this definition"></a></dt>
<dd><p>Dummy method for handling the end of a training epoch. Implemented as a placeholder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – Variable length argument list.</p></li>
<li><p><strong>**kwargs</strong> – Arbitrary keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.callbacks.KGESaveCallback">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.callbacks.</span></span><span class="sig-name descname"><span class="pre">KGESaveCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">every_x_epoch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_epochs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.callbacks.KGESaveCallback" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="../abstracts/index.html#dicee.abstracts.AbstractCallback" title="dicee.abstracts.AbstractCallback"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.abstracts.AbstractCallback</span></code></a></p>
<p>A callback to save the model periodically during training.</p>
<p>This callback is intended to periodically save the current state of the model during training,
allowing for checkpointing and potential recovery of intermediate states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>every_x_epoch</strong> (<em>int</em>) – Interval between epochs to save the model. The model will be saved every ‘every_x_epoch’ epochs.</p></li>
<li><p><strong>max_epochs</strong> (<em>int</em>) – The maximum number of epochs for the training. Used to calculate the default saving interval if ‘every_x_epoch’ is not provided.</p></li>
<li><p><strong>path</strong> (<em>str</em>) – The directory path where the model checkpoints will be saved.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.callbacks.KGESaveCallback.epoch_counter">
<span class="sig-name descname"><span class="pre">epoch_counter</span></span><a class="headerlink" href="#dicee.callbacks.KGESaveCallback.epoch_counter" title="Link to this definition"></a></dt>
<dd><p>A counter to keep track of the current epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.KGESaveCallback.on_epoch_end">
<span class="sig-name descname"><span class="pre">on_epoch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">\*\*kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.callbacks.KGESaveCallback.on_epoch_end" title="Link to this definition"></a></dt>
<dd><p>Saves the model at specified intervals.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.KGESaveCallback.on_train_batch_end">
<span class="sig-name descname"><span class="pre">on_train_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.callbacks.KGESaveCallback.on_train_batch_end" title="Link to this definition"></a></dt>
<dd><p>Call at the end of each mini-batch during the training.</p>
<section id="parameter">
<h4>Parameter<a class="headerlink" href="#parameter" title="Link to this heading"></a></h4>
<p>trainer:</p>
<p>model:</p>
<dl class="field-list simple">
<dt class="field-odd">rtype<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.KGESaveCallback.on_fit_start">
<span class="sig-name descname"><span class="pre">on_fit_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pl_module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.callbacks.KGESaveCallback.on_fit_start" title="Link to this definition"></a></dt>
<dd><p>Called at the very beginning of fit.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<em>pl.Trainer</em>) – The trainer instance.</p></li>
<li><p><strong>pl_module</strong> (<em>pl.LightningModule</em>) – The model that is being trained.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.KGESaveCallback.on_train_epoch_end">
<span class="sig-name descname"><span class="pre">on_train_epoch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.callbacks.KGESaveCallback.on_train_epoch_end" title="Link to this definition"></a></dt>
<dd><p>Called at the end of the training epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<em>pl.Trainer</em>) – The trainer instance.</p></li>
<li><p><strong>pl_module</strong> (<em>pl.LightningModule</em>) – The model that is being trained.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.KGESaveCallback.on_fit_end">
<span class="sig-name descname"><span class="pre">on_fit_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.callbacks.KGESaveCallback.on_fit_end" title="Link to this definition"></a></dt>
<dd><p>Called at the end of fit.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<em>pl.Trainer</em>) – The trainer instance.</p></li>
<li><p><strong>pl_module</strong> (<em>pl.LightningModule</em>) – The model that has been trained.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id0">
<span class="sig-name descname"><span class="pre">on_epoch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">lightning.LightningModule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">lightning.Trainer</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#id0" title="Link to this definition"></a></dt>
<dd><p>Invoked at the end of each epoch to potentially save the model.</p>
<p>Checks if the current epoch matches the saving criteria. If so, the model’s state is saved as a checkpoint.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>LightningModule</em>) – The model being trained.</p></li>
<li><p><strong>trainer</strong> (<em>Trainer</em>) – The trainer instance conducting the training process.</p></li>
<li><p><strong>**kwargs</strong> – Arbitrary keyword arguments.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.callbacks.PseudoLabellingCallback">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.callbacks.</span></span><span class="sig-name descname"><span class="pre">PseudoLabellingCallback</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_module</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">lightning.LightningDataModule</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kg</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.callbacks.PseudoLabellingCallback" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="../abstracts/index.html#dicee.abstracts.AbstractCallback" title="dicee.abstracts.AbstractCallback"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.abstracts.AbstractCallback</span></code></a></p>
<p>A callback for implementing pseudo-labelling during training.</p>
<p>Pseudo-labelling is a semi-supervised learning technique that uses the model’s predictions
on unlabeled data as labels for retraining the model. This callback generates pseudo-labels
for a batch of randomly created or selected unlabeled data and adds them to the training set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_module</strong> (<em>LightningDataModule</em>) – The data module that provides data loaders for the training process.</p></li>
<li><p><strong>kg</strong> (<em>KnowledgeGraph</em>) – The knowledge graph object that contains information about the entities, relations, and the unlabeled set.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – The size of the batch to generate or select for pseudo-labelling.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.callbacks.PseudoLabellingCallback.num_of_epochs">
<span class="sig-name descname"><span class="pre">num_of_epochs</span></span><a class="headerlink" href="#dicee.callbacks.PseudoLabellingCallback.num_of_epochs" title="Link to this definition"></a></dt>
<dd><p>Tracks the number of epochs that have been processed.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.callbacks.PseudoLabellingCallback.unlabelled_size">
<span class="sig-name descname"><span class="pre">unlabelled_size</span></span><a class="headerlink" href="#dicee.callbacks.PseudoLabellingCallback.unlabelled_size" title="Link to this definition"></a></dt>
<dd><p>The size of the unlabeled dataset in the knowledge graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.PseudoLabellingCallback.create_random_data">
<span class="sig-name descname"><span class="pre">create_random_data</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#dicee.callbacks.PseudoLabellingCallback.create_random_data" title="Link to this definition"></a></dt>
<dd><p>Generates a batch of random triples (head entity, relation, tail entity).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A batch of randomly generated triples.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.PseudoLabellingCallback.on_epoch_end">
<span class="sig-name descname"><span class="pre">on_epoch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">lightning.Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">lightning.LightningModule</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dicee.callbacks.PseudoLabellingCallback.on_epoch_end" title="Link to this definition"></a></dt>
<dd><p>Invoked at the end of each epoch to perform pseudo-labelling.</p>
<p>Generates or selects a batch of unlabeled data, uses the model to predict pseudo-labels,
and adds the selected triples with high-confidence pseudo-labels to the training set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<em>Trainer</em>) – The trainer instance conducting the training process.</p></li>
<li><p><strong>model</strong> (<em>LightningModule</em>) – The model being trained.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.callbacks.estimate_q">
<span class="sig-prename descclassname"><span class="pre">dicee.callbacks.</span></span><span class="sig-name descname"><span class="pre">estimate_q</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">eps</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#dicee.callbacks.estimate_q" title="Link to this definition"></a></dt>
<dd><p>Estimate the rate of convergence, q, from a sequence of errors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>eps</strong> (<em>array-like</em>) – A sequence of errors (epsilons) from which the rate of convergence is to be estimated.
It’s expected that <cite>eps</cite> represents a decreasing sequence of errors as the approximation
improves, typically from an iterative numerical method.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The estimated rate of convergence, q.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>The function estimates the rate of convergence by fitting a line to the logarithm of the
absolute difference of the logarithm of the errors. The slope of this line corresponds to
the logarithm of the rate of convergence, q. This method assumes exponential convergence,
where the error decreases as a power of the number of iterations.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">eps</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="o">**</span><span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">q</span> <span class="o">=</span> <span class="n">estimate_q</span><span class="p">(</span><span class="n">eps</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
<span class="go">2.0</span>
</pre></div>
</div>
<p>This indicates a quadratic convergence rate, as expected for the given sequence of errors
that halve at each step.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.callbacks.compute_convergence">
<span class="sig-prename descclassname"><span class="pre">dicee.callbacks.</span></span><span class="sig-name descname"><span class="pre">compute_convergence</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seq</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#dicee.callbacks.compute_convergence" title="Link to this definition"></a></dt>
<dd><p>Compute the convergence rate of the last <cite>i</cite> elements in a sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seq</strong> (<em>array-like</em>) – The sequence of numeric values for which the convergence rate is to be computed.</p></li>
<li><p><strong>i</strong> (<em>int</em>) – The number of elements from the end of <cite>seq</cite> to use for computing the convergence rate.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The estimated rate of convergence over the last <cite>i</cite> elements of <cite>seq</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
<dt class="field-even">Raises<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>AssertionError</strong> – If <cite>i</cite> is not less than or equal to the length of <cite>seq</cite> or if <cite>i</cite> is not greater than 0.</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>This function wraps the <cite>estimate_q</cite> function to specifically evaluate the convergence rate
of a subsection of a given sequence. It modifies the sequence to fit the model of <cite>estimate_q</cite>
by dividing each element by its index (adjusted for Python’s 0-indexing), which normalizes
the sequence in preparation for estimating the convergence rate.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">seq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="o">/</span><span class="mi">2</span><span class="o">**</span><span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">compute_convergence</span><span class="p">(</span><span class="n">seq</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="go">2.0</span>
</pre></div>
</div>
<p>Here, <cite>compute_convergence</cite> estimates the rate of convergence using the last 5 elements
of a sequence exhibiting quadratic convergence. The function should return a value close
to 2.0, indicating quadratic convergence.</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.callbacks.PPE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.callbacks.</span></span><span class="sig-name descname"><span class="pre">PPE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_epochs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch_to_start</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_percent_to_consider</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.callbacks.PPE" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">AbstractPPECallback</span></code></p>
<p>Polyak Parameter Ensemble (PPE) callback for maintaining a running average of model parameters.</p>
<p>This callback implements the Polyak Parameter Ensemble technique, which maintains
a running average of the model parameters across epochs to potentially improve
generalization performance of the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_epochs</strong> (<em>int</em>) – Total number of epochs in the training process.</p></li>
<li><p><strong>path</strong> (<em>str</em>) – Path where the ensemble model and intermediate states are stored.</p></li>
<li><p><strong>epoch_to_start</strong> (<em>int</em><em>, </em><em>optional</em>) – Epoch number from which to start applying PPE. If not specified, PPE will start from the beginning.</p></li>
<li><p><strong>last_percent_to_consider</strong> (<em>float</em><em>, </em><em>optional</em>) – Last X percent of the epochs to consider for PPE. This parameter is used if <cite>epoch_to_start</cite> is not provided.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.callbacks.PPE.epoch_count">
<span class="sig-name descname"><span class="pre">epoch_count</span></span><a class="headerlink" href="#dicee.callbacks.PPE.epoch_count" title="Link to this definition"></a></dt>
<dd><p>Counter to track the current epoch number.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.callbacks.PPE.sample_counter">
<span class="sig-name descname"><span class="pre">sample_counter</span></span><a class="headerlink" href="#dicee.callbacks.PPE.sample_counter" title="Link to this definition"></a></dt>
<dd><p>Counter to track the number of samples (epochs) considered in the ensemble.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.PPE.initialize_ensemble">
<span class="sig-name descname"><span class="pre">initialize_ensemble</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#dicee.callbacks.PPE.initialize_ensemble" title="Link to this definition"></a></dt>
<dd><p>Initializes the ensemble by saving the current model’s state dict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> (<em>torch.nn.Module</em>) – The model from which to initialize the ensemble.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The state dict of the model used to initialize the ensemble.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.PPE.should_averaging_start">
<span class="sig-name descname"><span class="pre">should_averaging_start</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#dicee.callbacks.PPE.should_averaging_start" title="Link to this definition"></a></dt>
<dd><p>Checks whether parameter averaging should start based on the current epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>True if averaging should start, False otherwise.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.PPE.get_ensemble_model">
<span class="sig-name descname"><span class="pre">get_ensemble_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="headerlink" href="#dicee.callbacks.PPE.get_ensemble_model" title="Link to this definition"></a></dt>
<dd><p>Retrieves the ensemble model’s state dict.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> (<em>torch.nn.Module</em>) – The current model being trained.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The state dict of the ensemble model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.PPE.update_ensemble">
<span class="sig-name descname"><span class="pre">update_ensemble</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ensemble_state_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.Module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.callbacks.PPE.update_ensemble" title="Link to this definition"></a></dt>
<dd><p>Updates the ensemble model’s state dict with the current model’s parameters.
This method performs an in-place update of the ensemble model’s state dict
using the Polyak averaging formula.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ensemble_state_dict</strong> (<em>dict</em>) – The state dict of the ensemble model to be updated.</p></li>
<li><p><strong>current_model</strong> (<em>torch.nn.Module</em>) – The current model from which parameters are extracted to update the ensemble.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.PPE.on_train_epoch_end">
<span class="sig-name descname"><span class="pre">on_train_epoch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">lightning.Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dicee.callbacks.PPE.on_train_epoch_end" title="Link to this definition"></a></dt>
<dd><p>Called at the end of each training epoch to possibly update the ensemble model.
This method checks if the conditions for starting parameter averaging are met
and, if so, updates the ensemble model with the current model’s parameters.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<em>Trainer</em>) – The PyTorch Lightning trainer instance.</p></li>
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The model being trained.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.callbacks.ASWA">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.callbacks.</span></span><span class="sig-name descname"><span class="pre">ASWA</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_epochs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.callbacks.ASWA" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">AbstractPPECallback</span></code></p>
<p>Implements the Adaptive Stochastic Weight Averaging (ASWA) technique.
This technique keeps track of validation performance and updates the ensemble model accordingly.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_epochs</strong> (<em>int</em>) – The total number of epochs to train the model.</p></li>
<li><p><strong>path</strong> (<em>str</em>) – Path where the model and intermediate results will be saved.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.callbacks.ASWA.initial_eval_setting">
<span class="sig-name descname"><span class="pre">initial_eval_setting</span></span><a class="headerlink" href="#dicee.callbacks.ASWA.initial_eval_setting" title="Link to this definition"></a></dt>
<dd><p>Initial evaluation setting, used to restore the original evaluation mode of the model after ASWA is applied.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None or str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.callbacks.ASWA.alphas">
<span class="sig-name descname"><span class="pre">alphas</span></span><a class="headerlink" href="#dicee.callbacks.ASWA.alphas" title="Link to this definition"></a></dt>
<dd><p>Weights for each model state in the ensemble.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.callbacks.ASWA.val_aswa">
<span class="sig-name descname"><span class="pre">val_aswa</span></span><a class="headerlink" href="#dicee.callbacks.ASWA.val_aswa" title="Link to this definition"></a></dt>
<dd><p>Validation performance (MRR) of the current ASWA model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.ASWA.on_fit_end">
<span class="sig-name descname"><span class="pre">on_fit_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None:</span></span></span><a class="headerlink" href="#dicee.callbacks.ASWA.on_fit_end" title="Link to this definition"></a></dt>
<dd><p>Applies the ASWA technique at the end of training.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.ASWA.compute_mrr">
<span class="sig-name descname"><span class="pre">compute_mrr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float:</span></span></span><a class="headerlink" href="#dicee.callbacks.ASWA.compute_mrr" title="Link to this definition"></a></dt>
<dd><p>Computes the Mean Reciprocal Rank (MRR) on the validation dataset.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.ASWA.get_aswa_state_dict">
<span class="sig-name descname"><span class="pre">get_aswa_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">OrderedDict:</span></span></span><a class="headerlink" href="#dicee.callbacks.ASWA.get_aswa_state_dict" title="Link to this definition"></a></dt>
<dd><p>Retrieves the state dictionary for the ASWA model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.ASWA.decide">
<span class="sig-name descname"><span class="pre">decide</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">running_model_state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ensemble_state_dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_running_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mrr_updated_ensemble_model</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None:</span></span></span><a class="headerlink" href="#dicee.callbacks.ASWA.decide" title="Link to this definition"></a></dt>
<dd><p>Decides whether to update ASWA based on validation performance.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.ASWA.on_train_epoch_end">
<span class="sig-name descname"><span class="pre">on_train_epoch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None:</span></span></span><a class="headerlink" href="#dicee.callbacks.ASWA.on_train_epoch_end" title="Link to this definition"></a></dt>
<dd><p>Performs the ASWA update process at the end of each training epoch.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id1">
<span class="sig-name descname"><span class="pre">on_fit_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">lightning.Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#id1" title="Link to this definition"></a></dt>
<dd><p>Called at the end of the fit process to apply the ASWA technique.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<em>Trainer</em>) – The PyTorch Lightning trainer instance.</p></li>
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The model being trained.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id2">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">compute_mrr</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">lightning.Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">float</span></span></span><a class="headerlink" href="#id2" title="Link to this definition"></a></dt>
<dd><p>Computes the Mean Reciprocal Rank (MRR) for the model on the validation dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<em>Trainer</em>) – The PyTorch Lightning trainer instance.</p></li>
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The model for which MRR will be computed.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The MRR score of the model on the validation dataset.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id3">
<span class="sig-name descname"><span class="pre">get_aswa_state_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">OrderedDict</span></span></span><a class="headerlink" href="#id3" title="Link to this definition"></a></dt>
<dd><p>Retrieves the state dictionary for the ASWA model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>model</strong> (<em>torch.nn.Module</em>) – The current model from which the ASWA state will be derived.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The state dictionary of the ASWA model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>OrderedDict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id4">
<span class="sig-name descname"><span class="pre">decide</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">running_model_state_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">OrderedDict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ensemble_state_dict</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">OrderedDict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_running_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mrr_updated_ensemble_model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="headerlink" href="#id4" title="Link to this definition"></a></dt>
<dd><p>Decides whether to update the ASWA model based on the validation performance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>running_model_state_dict</strong> (<em>OrderedDict</em>) – The state dictionary of the current running model.</p></li>
<li><p><strong>ensemble_state_dict</strong> (<em>OrderedDict</em>) – The state dictionary of the current ASWA model.</p></li>
<li><p><strong>val_running_model</strong> (<em>float</em>) – The validation performance (MRR) of the running model.</p></li>
<li><p><strong>mrr_updated_ensemble_model</strong> (<em>float</em>) – The validation performance (MRR) of the updated ASWA model.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The boolean flag to determine the updation of the ASWA model.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id5">
<span class="sig-name descname"><span class="pre">on_train_epoch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">lightning.Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.Module</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#id5" title="Link to this definition"></a></dt>
<dd><p>Called at the end of each training epoch to possibly update the ASWA model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<em>Trainer</em>) – The PyTorch Lightning trainer instance.</p></li>
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The model being trained.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.callbacks.FPPE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.callbacks.</span></span><span class="sig-name descname"><span class="pre">FPPE</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">last_percent_to_consider</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.callbacks.FPPE" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">AbstractPPECallback</span></code></p>
<p>import matplotlib.pyplot as plt
import numpy as np
def exponential_function(x: np.ndarray, lam: float, ascending_order=True) -&gt; torch.FloatTensor:</p>
<blockquote>
<div><p># A sequence in exponentially decreasing order
result = np.exp(-lam * x) / np.sum(np.exp(-lam * x))
assert 0.999 &lt; sum(result) &lt; 1.0001
result = np.flip(result) if ascending_order else result
return torch.tensor(result.tolist())</p>
</div></blockquote>
<p>N = 100
equal_weights = np.ones(N) / N
plt.plot(equal_weights, ‘r’, label=”Equal”)
plt.plot(exponential_function(np.arange(N), lam=0.1,), ‘c-’, label=”Exp. forgetful with 0.1”)
plt.plot(exponential_function(np.arange(N), lam=0.05), ‘g-’, label=”Exp. forgetful with 0.05”)
plt.plot(exponential_function(np.arange(N), lam=0.025), ‘b-’, label=”Exp. forgetful with 0.025”)
plt.plot(exponential_function(np.arange(N), lam=0.01), ‘k-’, label=”Exp. forgetful with 0.01”)
plt.title(‘Ensemble coefficients’)
plt.xlabel(‘Epochs’)
plt.ylabel(‘Coefficients’)
plt.legend()
plt.savefig(‘ensemble_coefficients.pdf’)
plt.show()</p>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.callbacks.Eval">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.callbacks.</span></span><span class="sig-name descname"><span class="pre">Eval</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.callbacks.Eval" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="../abstracts/index.html#dicee.abstracts.AbstractCallback" title="dicee.abstracts.AbstractCallback"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.abstracts.AbstractCallback</span></code></a></p>
<p>Callback for evaluating the model at certain epochs during training and logging the results.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em>) – Path where evaluation reports will be saved.</p></li>
<li><p><strong>epoch_ratio</strong> (<em>int</em><em>, </em><em>optional</em>) – Interval of epochs after which the evaluation will be performed. Default is 1, meaning evaluation after every epoch.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.callbacks.Eval.reports">
<span class="sig-name descname"><span class="pre">reports</span></span><a class="headerlink" href="#dicee.callbacks.Eval.reports" title="Link to this definition"></a></dt>
<dd><p>List of evaluation reports generated after each evaluation.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.callbacks.Eval.epoch_counter">
<span class="sig-name descname"><span class="pre">epoch_counter</span></span><a class="headerlink" href="#dicee.callbacks.Eval.epoch_counter" title="Link to this definition"></a></dt>
<dd><p>Counter for keeping track of the number of epochs passed.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.Eval.on_fit_end">
<span class="sig-name descname"><span class="pre">on_fit_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None:</span></span></span><a class="headerlink" href="#dicee.callbacks.Eval.on_fit_end" title="Link to this definition"></a></dt>
<dd><p>Saves the evaluation reports to a file and optionally generates plots for training and validation MRR.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.Eval.on_train_epoch_end">
<span class="sig-name descname"><span class="pre">on_train_epoch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None:</span></span></span><a class="headerlink" href="#dicee.callbacks.Eval.on_train_epoch_end" title="Link to this definition"></a></dt>
<dd><p>Evaluates the model if the current epoch matches the specified epoch ratio and appends the report to <cite>reports</cite>.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.Eval.on_fit_start">
<span class="sig-name descname"><span class="pre">on_fit_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.callbacks.Eval.on_fit_start" title="Link to this definition"></a></dt>
<dd><p>Called at the very beginning of fit.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<em>pl.Trainer</em>) – The trainer instance.</p></li>
<li><p><strong>pl_module</strong> (<em>pl.LightningModule</em>) – The model that is being trained.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id6">
<span class="sig-name descname"><span class="pre">on_fit_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">lightning.Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#id6" title="Link to this definition"></a></dt>
<dd><p>Called at the end of the fit process. Saves the collected evaluation reports to a file.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<em>Trainer</em>) – The PyTorch Lightning trainer instance.</p></li>
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The model being trained.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id7">
<span class="sig-name descname"><span class="pre">on_train_epoch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">lightning.Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#id7" title="Link to this definition"></a></dt>
<dd><p>Called at the end of each training epoch. Performs evaluation if the current epoch matches the epoch_ratio.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<em>Trainer</em>) – The PyTorch Lightning trainer instance.</p></li>
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The model being trained.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.Eval.on_train_batch_end">
<span class="sig-name descname"><span class="pre">on_train_batch_end</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dicee.callbacks.Eval.on_train_batch_end" title="Link to this definition"></a></dt>
<dd><p>Called at the end of each training batch. This method is not implemented in this callback.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – Variable length argument list.</p></li>
<li><p><strong>**kwargs</strong> – Arbitrary keyword arguments.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.callbacks.KronE">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.callbacks.</span></span><span class="sig-name descname"><span class="pre">KronE</span></span><a class="headerlink" href="#dicee.callbacks.KronE" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="../abstracts/index.html#dicee.abstracts.AbstractCallback" title="dicee.abstracts.AbstractCallback"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.abstracts.AbstractCallback</span></code></a></p>
<p>Callback for augmenting triple representations with Kronecker product embeddings during training.</p>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.KronE.batch_kronecker_product">
<span class="sig-name descname"><span class="pre">batch_kronecker_product</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor:</span></span></span><a class="headerlink" href="#dicee.callbacks.KronE.batch_kronecker_product" title="Link to this definition"></a></dt>
<dd><p>Computes the Kronecker product of two tensors with batch dimensions.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.KronE.get_kronecker_triple_representation">
<span class="sig-name descname"><span class="pre">get_kronecker_triple_representation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indexed_triple</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple[torch.Tensor,</span> <span class="pre">torch.Tensor,</span> <span class="pre">torch.Tensor]:</span></span></span><a class="headerlink" href="#dicee.callbacks.KronE.get_kronecker_triple_representation" title="Link to this definition"></a></dt>
<dd><p>Augments triple representations with Kronecker product embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.KronE.on_fit_start">
<span class="sig-name descname"><span class="pre">on_fit_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None:</span></span></span><a class="headerlink" href="#dicee.callbacks.KronE.on_fit_start" title="Link to this definition"></a></dt>
<dd><p>Overrides the model’s method to get triple representations with a method that includes Kronecker product embeddings.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id8">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">batch_kronecker_product</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">a</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="headerlink" href="#id8" title="Link to this definition"></a></dt>
<dd><p>Computes the Kronecker product of two tensors <cite>a</cite> and <cite>b</cite> with batch dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a</strong> (<em>torch.Tensor</em>) – The first tensor with batch dimensions.</p></li>
<li><p><strong>b</strong> (<em>torch.Tensor</em>) – The second tensor with batch dimensions.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The Kronecker product of <cite>a</cite> and <cite>b</cite>.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id9">
<span class="sig-name descname"><span class="pre">get_kronecker_triple_representation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">indexed_triple</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#id9" title="Link to this definition"></a></dt>
<dd><p>Augments triple representations with Kronecker product embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>indexed_triple</strong> (<em>torch.LongTensor</em>) – Indexed triple representations.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Augmented head entity, relation, and tail entity embeddings.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id10">
<span class="sig-name descname"><span class="pre">on_fit_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">lightning.Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#id10" title="Link to this definition"></a></dt>
<dd><p>Overrides the model’s method to get triple representations with a method that includes Kronecker product embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<em>Trainer</em>) – The PyTorch Lightning trainer instance.</p></li>
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The model being trained.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.callbacks.Perturb">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.callbacks.</span></span><span class="sig-name descname"><span class="pre">Perturb</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">level</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'input'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scaler</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frequency</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#dicee.callbacks.Perturb" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="../abstracts/index.html#dicee.abstracts.AbstractCallback" title="dicee.abstracts.AbstractCallback"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dicee.abstracts.AbstractCallback</span></code></a></p>
<p>Implements a three-level perturbation technique for knowledge graph embedding models during training.
The perturbations can be applied at the input, parameter, or output levels.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.callbacks.Perturb.level">
<span class="sig-name descname"><span class="pre">level</span></span><a class="headerlink" href="#dicee.callbacks.Perturb.level" title="Link to this definition"></a></dt>
<dd><p>The perturbation level. Must be one of {“input”, “param”, “out”}.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.callbacks.Perturb.ratio">
<span class="sig-name descname"><span class="pre">ratio</span></span><a class="headerlink" href="#dicee.callbacks.Perturb.ratio" title="Link to this definition"></a></dt>
<dd><p>The ratio of the mini-batch data points to be perturbed, between [0, 1].</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.callbacks.Perturb.method">
<span class="sig-name descname"><span class="pre">method</span></span><a class="headerlink" href="#dicee.callbacks.Perturb.method" title="Link to this definition"></a></dt>
<dd><p>The method used for perturbation.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.callbacks.Perturb.scaler">
<span class="sig-name descname"><span class="pre">scaler</span></span><a class="headerlink" href="#dicee.callbacks.Perturb.scaler" title="Link to this definition"></a></dt>
<dd><p>The scaler factor used for perturbation.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.callbacks.Perturb.frequency">
<span class="sig-name descname"><span class="pre">frequency</span></span><a class="headerlink" href="#dicee.callbacks.Perturb.frequency" title="Link to this definition"></a></dt>
<dd><p>The frequency of perturbation, e.g., per epoch or per mini-batch.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">on_train_batch_start(trainer,</span> <span class="pre">model,</span> <span class="pre">batch,</span> <span class="pre">batch_idx):</span></span></dt>
<dd><p>Applies perturbation to the batch data points before the training batch starts.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.callbacks.Perturb.on_train_batch_start">
<span class="sig-name descname"><span class="pre">on_train_batch_start</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">lightning.Trainer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#dicee.callbacks.Perturb.on_train_batch_start" title="Link to this definition"></a></dt>
<dd><p>Applies perturbation to the batch data points before the training batch starts.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>trainer</strong> (<em>Trainer</em>) – The PyTorch Lightning trainer instance.</p></li>
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The model being trained.</p></li>
<li><p><strong>batch</strong> (<em>torch.Tensor</em>) – The current mini-batch of data.</p></li>
<li><p><strong>batch_idx</strong> (<em>int</em>) – The index of the current batch.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../analyse_experiments/index.html" class="btn btn-neutral float-left" title="dicee.analyse_experiments" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../config/index.html" class="btn btn-neutral float-right" title="dicee.config" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Caglar Demir.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>