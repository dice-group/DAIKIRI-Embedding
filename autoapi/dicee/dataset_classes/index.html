<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>dicee.dataset_classes &mdash; DICE Embeddings 0.1.3.2 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=8775fe07" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=eafc0fe6" />
      <link rel="stylesheet" type="text/css" href="../../../_static/theme.css?v=ea877efc" />
      <link rel="stylesheet" type="text/css" href="../../../_static/theme_tweak.css?v=f0ad19f3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=8775fe07" />

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=c6726a90"></script>
        <script src="../../../_static/doctools.js?v=888ff710"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="dicee.eval_static_funcs" href="../eval_static_funcs/index.html" />
    <link rel="prev" title="dicee.config" href="../config/index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            DICE Embeddings
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html">Dicee Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#installation">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#download-knowledge-graphs">Download Knowledge Graphs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#knowledge-graph-embedding-models">Knowledge Graph Embedding Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#how-to-train">How to Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#creating-an-embedding-vector-database">Creating an Embedding Vector Database</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#answering-complex-queries">Answering Complex Queries</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#predicting-missing-links">Predicting Missing Links</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#downloading-pretrained-models">Downloading Pretrained Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#how-to-deploy">How to Deploy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#docker">Docker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/main.html#how-to-cite">How to cite</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee</span></code></a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#subpackages">Subpackages</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#submodules">Submodules</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../abstracts/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.abstracts</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../analyse_experiments/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.analyse_experiments</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../callbacks/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.callbacks</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../config/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.config</span></code></a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.dataset_classes</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#module-contents">Module Contents</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#classes">Classes</a></li>
<li class="toctree-l5"><a class="reference internal" href="#functions">Functions</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#dicee.dataset_classes.reload_dataset"><code class="docutils literal notranslate"><span class="pre">reload_dataset()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.dataset_classes.construct_dataset"><code class="docutils literal notranslate"><span class="pre">construct_dataset()</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.dataset_classes.BPE_NegativeSamplingDataset"><code class="docutils literal notranslate"><span class="pre">BPE_NegativeSamplingDataset</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.dataset_classes.MultiLabelDataset"><code class="docutils literal notranslate"><span class="pre">MultiLabelDataset</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.dataset_classes.MultiClassClassificationDataset"><code class="docutils literal notranslate"><span class="pre">MultiClassClassificationDataset</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.dataset_classes.OnevsAllDataset"><code class="docutils literal notranslate"><span class="pre">OnevsAllDataset</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.dataset_classes.KvsAll"><code class="docutils literal notranslate"><span class="pre">KvsAll</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.dataset_classes.AllvsAll"><code class="docutils literal notranslate"><span class="pre">AllvsAll</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.dataset_classes.KvsSampleDataset"><code class="docutils literal notranslate"><span class="pre">KvsSampleDataset</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.dataset_classes.NegSampleDataset"><code class="docutils literal notranslate"><span class="pre">NegSampleDataset</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.dataset_classes.TriplePredictionDataset"><code class="docutils literal notranslate"><span class="pre">TriplePredictionDataset</span></code></a></li>
<li class="toctree-l6"><a class="reference internal" href="#dicee.dataset_classes.CVDataModule"><code class="docutils literal notranslate"><span class="pre">CVDataModule</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../eval_static_funcs/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.eval_static_funcs</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../evaluator/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.evaluator</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../executer/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.executer</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../knowledge_graph/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.knowledge_graph</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../knowledge_graph_embeddings/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.knowledge_graph_embeddings</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../query_generator/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.query_generator</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../sanity_checkers/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.sanity_checkers</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../static_funcs/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.static_funcs</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../static_funcs_training/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.static_funcs_training</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../static_preprocess_funcs/index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.static_preprocess_funcs</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#package-contents">Package Contents</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">DICE Embeddings</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee</span></code></a></li>
      <li class="breadcrumb-item active"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.dataset_classes</span></code></li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/autoapi/dicee/dataset_classes/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-dicee.dataset_classes">
<span id="dicee-dataset-classes"></span><h1><a class="reference internal" href="#module-dicee.dataset_classes" title="dicee.dataset_classes"><code class="xref py py-mod docutils literal notranslate"><span class="pre">dicee.dataset_classes</span></code></a><a class="headerlink" href="#module-dicee.dataset_classes" title="Link to this heading"></a></h1>
<section id="module-contents">
<h2>Module Contents<a class="headerlink" href="#module-contents" title="Link to this heading"></a></h2>
<section id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Link to this heading"></a></h3>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.dataset_classes.BPE_NegativeSamplingDataset" title="dicee.dataset_classes.BPE_NegativeSamplingDataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">BPE_NegativeSamplingDataset</span></code></a></p></td>
<td><p>A PyTorch Dataset for handling negative sampling with Byte Pair Encoding (BPE) entities.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.dataset_classes.MultiLabelDataset" title="dicee.dataset_classes.MultiLabelDataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiLabelDataset</span></code></a></p></td>
<td><p>A dataset class for multi-label knowledge graph embedding tasks. This dataset is designed for models where</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.dataset_classes.MultiClassClassificationDataset" title="dicee.dataset_classes.MultiClassClassificationDataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">MultiClassClassificationDataset</span></code></a></p></td>
<td><p>A dataset class for multi-class classification tasks, specifically designed for the 1vsALL training strategy</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.dataset_classes.OnevsAllDataset" title="dicee.dataset_classes.OnevsAllDataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OnevsAllDataset</span></code></a></p></td>
<td><p>A dataset for the One-vs-All (1vsAll) training strategy designed for knowledge graph embedding tasks.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.dataset_classes.KvsAll" title="dicee.dataset_classes.KvsAll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KvsAll</span></code></a></p></td>
<td><p>Creates a dataset for K-vs-All training strategy, inheriting from torch.utils.data.Dataset.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.dataset_classes.AllvsAll" title="dicee.dataset_classes.AllvsAll"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AllvsAll</span></code></a></p></td>
<td><p>A dataset class for the All-versus-All (AllvsAll) training strategy suitable for knowledge graph embedding models.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.dataset_classes.KvsSampleDataset" title="dicee.dataset_classes.KvsSampleDataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">KvsSampleDataset</span></code></a></p></td>
<td><p>Constructs a dataset for KvsSample training strategy, specifically designed for knowledge graph embedding models.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.dataset_classes.NegSampleDataset" title="dicee.dataset_classes.NegSampleDataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NegSampleDataset</span></code></a></p></td>
<td><p>A dataset for training knowledge graph embedding models using negative sampling.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.dataset_classes.TriplePredictionDataset" title="dicee.dataset_classes.TriplePredictionDataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">TriplePredictionDataset</span></code></a></p></td>
<td><p>A dataset for triple prediction using negative sampling and label smoothing.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.dataset_classes.CVDataModule" title="dicee.dataset_classes.CVDataModule"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CVDataModule</span></code></a></p></td>
<td><p>A LightningDataModule for setting up data loaders for cross-validation training of knowledge graph embedding models.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="functions">
<h3>Functions<a class="headerlink" href="#functions" title="Link to this heading"></a></h3>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#dicee.dataset_classes.reload_dataset" title="dicee.dataset_classes.reload_dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">reload_dataset</span></code></a>(→ torch.utils.data.Dataset)</p></td>
<td><p>Reloads the dataset from disk and constructs a PyTorch dataset for training.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#dicee.dataset_classes.construct_dataset" title="dicee.dataset_classes.construct_dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">construct_dataset</span></code></a>(→ torch.utils.data.Dataset)</p></td>
<td><p>Constructs a dataset based on the specified parameters and returns a PyTorch Dataset object.</p></td>
</tr>
</tbody>
</table>
<dl class="py function">
<dt class="sig sig-object py" id="dicee.dataset_classes.reload_dataset">
<span class="sig-prename descclassname"><span class="pre">dicee.dataset_classes.</span></span><span class="sig-name descname"><span class="pre">reload_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">form_of_labelling</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring_technique</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_smoothing_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.utils.data.Dataset</span></span></span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#reload_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.reload_dataset" title="Link to this definition"></a></dt>
<dd><p>Reloads the dataset from disk and constructs a PyTorch dataset for training.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> (<em>str</em>) – The path to the directory where the dataset is stored.</p></li>
<li><p><strong>form_of_labelling</strong> (<em>str</em>) – The form of labelling used in the dataset. Determines how data points are represented.</p></li>
<li><p><strong>scoring_technique</strong> (<em>str</em>) – The scoring technique used for evaluating the embeddings.</p></li>
<li><p><strong>neg_ratio</strong> (<em>float</em>) – The ratio of negative samples to positive samples in the dataset.</p></li>
<li><p><strong>label_smoothing_rate</strong> (<em>float</em>) – The rate of label smoothing applied to the dataset.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A PyTorch dataset object ready for training.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.utils.data.Dataset</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="dicee.dataset_classes.construct_dataset">
<span class="sig-prename descclassname"><span class="pre">dicee.dataset_classes.</span></span><span class="sig-name descname"><span class="pre">construct_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">valid_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_set</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ordered_bpe_entities</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_target_indices</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entity_to_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relation_to_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">form_of_labelling</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scoring_technique</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_smoothing_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">byte_pair_encoding</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">block_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.utils.data.Dataset</span></span></span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#construct_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.construct_dataset" title="Link to this definition"></a></dt>
<dd><p>Constructs a dataset based on the specified parameters and returns a PyTorch Dataset object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_set</strong> (<em>Union</em><em>[</em><em>np.ndarray</em><em>, </em><em>list</em><em>]</em>) – The training set consisting of triples or tokens.</p></li>
<li><p><strong>valid_set</strong> (<em>Optional</em>) – The validation set. Not currently used in dataset construction.</p></li>
<li><p><strong>test_set</strong> (<em>Optional</em>) – The test set. Not currently used in dataset construction.</p></li>
<li><p><strong>ordered_bpe_entities</strong> (<em>Optional</em>) – Ordered byte pair encoding entities for the dataset.</p></li>
<li><p><strong>train_target_indices</strong> (<em>Optional</em>) – Indices of target entities or relations for training.</p></li>
<li><p><strong>target_dim</strong> (<em>int</em><em>, </em><em>optional</em>) – The dimension of target entities or relations.</p></li>
<li><p><strong>entity_to_idx</strong> (<em>dict</em>) – A dictionary mapping entity strings to indices.</p></li>
<li><p><strong>relation_to_idx</strong> (<em>dict</em>) – A dictionary mapping relation strings to indices.</p></li>
<li><p><strong>form_of_labelling</strong> (<em>str</em>) – Specifies the form of labelling, such as ‘EntityPrediction’ or ‘RelationPrediction’.</p></li>
<li><p><strong>scoring_technique</strong> (<em>str</em>) – The scoring technique used for generating negative samples or evaluating the model.</p></li>
<li><p><strong>neg_ratio</strong> (<em>int</em>) – The ratio of negative samples to positive samples.</p></li>
<li><p><strong>label_smoothing_rate</strong> (<em>float</em>) – The rate of label smoothing applied to labels.</p></li>
<li><p><strong>byte_pair_encoding</strong> (<em>Optional</em>) – Indicates if byte pair encoding is used.</p></li>
<li><p><strong>block_size</strong> (<em>int</em><em>, </em><em>optional</em>) – The block size for transformer-based models.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A PyTorch dataset object ready for model training.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.utils.data.Dataset</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.dataset_classes.BPE_NegativeSamplingDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.dataset_classes.</span></span><span class="sig-name descname"><span class="pre">BPE_NegativeSamplingDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ordered_shaped_bpe_entities</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#BPE_NegativeSamplingDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.BPE_NegativeSamplingDataset" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></p>
<p>A PyTorch Dataset for handling negative sampling with Byte Pair Encoding (BPE) entities.</p>
<p>This dataset extends the PyTorch Dataset class to provide functionality for negative sampling
in the context of knowledge graph embeddings. It uses byte pair encoding for entities
to handle large vocabularies efficiently.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_set</strong> (<em>torch.LongTensor</em>) – A tensor containing the training set triples with byte pair encoded entities and relations.
The shape of the tensor is [N, 3], where N is the number of triples.</p></li>
<li><p><strong>ordered_shaped_bpe_entities</strong> (<em>torch.LongTensor</em>) – A tensor containing the ordered and shaped byte pair encoded entities.</p></li>
<li><p><strong>neg_ratio</strong> (<em>int</em>) – The ratio of negative samples to generate per positive sample.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.BPE_NegativeSamplingDataset.num_bpe_entities">
<span class="sig-name descname"><span class="pre">num_bpe_entities</span></span><a class="headerlink" href="#dicee.dataset_classes.BPE_NegativeSamplingDataset.num_bpe_entities" title="Link to this definition"></a></dt>
<dd><p>The number of byte pair encoded entities.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.BPE_NegativeSamplingDataset.num_datapoints">
<span class="sig-name descname"><span class="pre">num_datapoints</span></span><a class="headerlink" href="#dicee.dataset_classes.BPE_NegativeSamplingDataset.num_datapoints" title="Link to this definition"></a></dt>
<dd><p>The number of data points (triples) in the training set.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.BPE_NegativeSamplingDataset.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#BPE_NegativeSamplingDataset.__len__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.BPE_NegativeSamplingDataset.__len__" title="Link to this definition"></a></dt>
<dd><p>Returns the total number of data points in the dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The number of data points.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.BPE_NegativeSamplingDataset.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#BPE_NegativeSamplingDataset.__getitem__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.BPE_NegativeSamplingDataset.__getitem__" title="Link to this definition"></a></dt>
<dd><p>Retrieves the BPE-encoded triple and its corresponding label at the specified index.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idx</strong> (<em>int</em>) – Index of the triple to retrieve.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A tuple containing the following elements:
- The BPE-encoded triple as a torch.Tensor of shape (3,).
- The label for the triple, where positive examples have a label of 1 and negative examples have a label</p>
<blockquote>
<div><p>of 0, as a torch.Tensor.</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.BPE_NegativeSamplingDataset.collate_fn">
<span class="sig-name descname"><span class="pre">collate_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch_shaped_bpe_triples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#BPE_NegativeSamplingDataset.collate_fn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.BPE_NegativeSamplingDataset.collate_fn" title="Link to this definition"></a></dt>
<dd><p>Collate function for the BPE_NegativeSamplingDataset. It processes a batch of byte pair encoded triples,
performs negative sampling, and returns the batch along with corresponding labels.</p>
<p>This function is designed to be used with a PyTorch DataLoader. It takes a list of byte pair encoded triples
as input and generates negative samples according to the specified negative sampling ratio. The function
ensures that the negative samples are combined with the original triples to form a single batch, which is
suitable for training a knowledge graph embedding model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch_shaped_bpe_triples</strong> (<em>List</em><em>[</em><em>Tuple</em><em>[</em><em>torch.Tensor</em><em>, </em><em>torch.Tensor</em><em>]</em><em>]</em>) – A list of tuples, where each tuple contains byte pair encoded representations of head entities, relations,
and tail entities for a batch of triples.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing two elements:
- The first element is a torch.Tensor of shape [N * (1 + neg_ratio), 3] that contains both the original
byte pair encoded triples and the generated negative samples. N is the original number of triples in the
batch, and neg_ratio is the negative sampling ratio.
- The second element is a torch.Tensor of shape [N * (1 + neg_ratio)] that contains the labels for each
triple in the batch. Positive samples are labeled as 1, and negative samples are labeled as 0.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.dataset_classes.MultiLabelDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.dataset_classes.</span></span><span class="sig-name descname"><span class="pre">MultiLabelDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_indices_target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">torch_ordered_shaped_bpe_entities</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.LongTensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#MultiLabelDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.MultiLabelDataset" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></p>
<p>A dataset class for multi-label knowledge graph embedding tasks. This dataset is designed for models where
the output involves predicting multiple labels (entities or relations) for a given input (e.g., predicting all
possible tail entities given a head entity and a relation).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_set</strong> (<em>torch.LongTensor</em>) – A tensor containing the training set triples with byte pair encoding, shaped as [num_triples, 3],
where each triple is [head, relation, tail].</p></li>
<li><p><strong>train_indices_target</strong> (<em>torch.LongTensor</em>) – A tensor where each row corresponds to the indices of the target labels for each training example.
The length of this tensor must match the number of triples in <cite>train_set</cite>.</p></li>
<li><p><strong>target_dim</strong> (<em>int</em>) – The dimensionality of the target space, typically the total number of possible labels (entities or relations).</p></li>
<li><p><strong>torch_ordered_shaped_bpe_entities</strong> (<em>torch.LongTensor</em>) – A tensor containing ordered byte pair encoded entities used for creating embeddings.
This tensor is not directly used in generating targets but may be utilized for additional processing
or embedding lookup.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.MultiLabelDataset.num_datapoints">
<span class="sig-name descname"><span class="pre">num_datapoints</span></span><a class="headerlink" href="#dicee.dataset_classes.MultiLabelDataset.num_datapoints" title="Link to this definition"></a></dt>
<dd><p>The number of data points (triples) in the dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.MultiLabelDataset.collate_fn">
<span class="sig-name descname"><span class="pre">collate_fn</span></span><a class="headerlink" href="#dicee.dataset_classes.MultiLabelDataset.collate_fn" title="Link to this definition"></a></dt>
<dd><p>Optional custom collate function to be used with a PyTorch DataLoader.
It’s set to None by default and can be specified after initializing the dataset if needed.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None or callable</p>
</dd>
</dl>
</dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This dataset is particularly suited for KvsAll (K entities vs. All entities) and AllvsAll training strategies
in knowledge graph embedding, where a model predicts a set of possible tail entities given a head entity
and a relation (or vice versa), and where each training example can have multiple correct labels.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.MultiLabelDataset.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#MultiLabelDataset.__len__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.MultiLabelDataset.__len__" title="Link to this definition"></a></dt>
<dd><p>Returns the total number of data points in the dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The number of data points.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.MultiLabelDataset.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#MultiLabelDataset.__getitem__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.MultiLabelDataset.__getitem__" title="Link to this definition"></a></dt>
<dd><p>Retrieves the knowledge graph triple and its corresponding multi-label target vector at the specified index.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idx</strong> (<em>int</em>) – Index of the triple to retrieve.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A tuple containing the following elements:
- The triple as a torch.Tensor of shape (3,).
- The multi-label target vector as a torch.Tensor of shape (<cite>target_dim</cite>,), where each element</p>
<blockquote>
<div><p>indicates the presence (1) or absence (0) of a label for the given triple.</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.dataset_classes.MultiClassClassificationDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.dataset_classes.</span></span><span class="sig-name descname"><span class="pre">MultiClassClassificationDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">subword_units</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">block_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">8</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#MultiClassClassificationDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.MultiClassClassificationDataset" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></p>
<p>A dataset class for multi-class classification tasks, specifically designed for the 1vsALL training strategy
in knowledge graph embedding models. This dataset supports tasks where the model predicts a single correct
label from all possible labels for a given input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>subword_units</strong> (<em>np.ndarray</em>) – An array of subword unit indices representing the training data. Each row in the array corresponds to a
sequence of subword units (e.g., Byte Pair Encoding tokens) that have been converted to their respective
numeric indices.</p></li>
<li><p><strong>block_size</strong> (<em>int</em><em>, </em><em>optional</em>) – The size of each sequence of subword units to be used as input to the model. This defines the length of
the sequences that the model will receive as input, by default 8.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.MultiClassClassificationDataset.num_of_data_points">
<span class="sig-name descname"><span class="pre">num_of_data_points</span></span><a class="headerlink" href="#dicee.dataset_classes.MultiClassClassificationDataset.num_of_data_points" title="Link to this definition"></a></dt>
<dd><p>The number of sequences or data points available in the dataset, calculated based on the length of the
<cite>subword_units</cite> array and the <cite>block_size</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.MultiClassClassificationDataset.collate_fn">
<span class="sig-name descname"><span class="pre">collate_fn</span></span><a class="headerlink" href="#dicee.dataset_classes.MultiClassClassificationDataset.collate_fn" title="Link to this definition"></a></dt>
<dd><p>An optional custom collate function to be used with a PyTorch DataLoader. It’s set to None by default
and can be specified after initializing the dataset if needed.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None or callable</p>
</dd>
</dl>
</dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This dataset is tailored for training knowledge graph embedding models on tasks where the output is a single
label out of many possible labels (1vsALL strategy). It is especially suited for models trained with subword
tokenization methods like Byte Pair Encoding (BPE), where inputs are sequences of subword unit indices.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.MultiClassClassificationDataset.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#MultiClassClassificationDataset.__len__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.MultiClassClassificationDataset.__len__" title="Link to this definition"></a></dt>
<dd><p>Returns the total number of sequences or data points available in the dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The number of sequences or data points.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.MultiClassClassificationDataset.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#MultiClassClassificationDataset.__getitem__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.MultiClassClassificationDataset.__getitem__" title="Link to this definition"></a></dt>
<dd><p>Retrieves an input sequence and its subsequent target sequence for next token prediction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idx</strong> (<em>int</em>) – The starting index for the sequence to be retrieved from the dataset.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A tuple containing two elements:
- <cite>x</cite>: The input sequence as a torch.Tensor of shape (<cite>block_size</cite>,).
- <cite>y</cite>: The target sequence as a torch.Tensor of shape (<cite>block_size</cite>,), offset by one position</p>
<blockquote>
<div><p>from the input sequence.</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.dataset_classes.OnevsAllDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.dataset_classes.</span></span><span class="sig-name descname"><span class="pre">OnevsAllDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entity_idxs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#OnevsAllDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.OnevsAllDataset" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></p>
<p>A dataset for the One-vs-All (1vsAll) training strategy designed for knowledge graph embedding tasks.
This dataset structure is particularly suited for models predicting a single correct label (entity) out of
all possible entities for a given pair of head entity and relation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_set_idx</strong> (<em>np.ndarray</em>) – An array containing indexed triples from the knowledge graph. Each row represents a triple consisting of
indices for the head entity, relation, and tail entity, respectively.</p></li>
<li><p><strong>entity_idxs</strong> (<em>dict</em>) – A dictionary mapping entity names to their corresponding unique integer indices. This is used to determine
the dimensionality of the target vector in the 1vsAll setting.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.OnevsAllDataset.train_data">
<span class="sig-name descname"><span class="pre">train_data</span></span><a class="headerlink" href="#dicee.dataset_classes.OnevsAllDataset.train_data" title="Link to this definition"></a></dt>
<dd><p>A tensor version of <cite>train_set_idx</cite>, prepared for use with PyTorch models.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.LongTensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.OnevsAllDataset.target_dim">
<span class="sig-name descname"><span class="pre">target_dim</span></span><a class="headerlink" href="#dicee.dataset_classes.OnevsAllDataset.target_dim" title="Link to this definition"></a></dt>
<dd><p>The dimensionality of the target vector, equivalent to the total number of unique entities in the dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.OnevsAllDataset.collate_fn">
<span class="sig-name descname"><span class="pre">collate_fn</span></span><a class="headerlink" href="#dicee.dataset_classes.OnevsAllDataset.collate_fn" title="Link to this definition"></a></dt>
<dd><p>An optional custom collate function for use with a PyTorch DataLoader. By default, it is set to None and can
be specified after initializing the dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None or callable</p>
</dd>
</dl>
</dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This dataset is optimized for training knowledge graph embedding models using the 1vsAll strategy, where the
model aims to correctly predict the tail entity from all possible entities given the head entity and relation.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.OnevsAllDataset.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#OnevsAllDataset.__len__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.OnevsAllDataset.__len__" title="Link to this definition"></a></dt>
<dd><p>Returns the total number of triples in the dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The total number of triples.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.OnevsAllDataset.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#OnevsAllDataset.__getitem__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.OnevsAllDataset.__getitem__" title="Link to this definition"></a></dt>
<dd><p>Retrieves the input data and target vector for the triple at index <cite>idx</cite>.</p>
<p>The input data consists of the indices for the head entity and relation, while the target vector is a
one-hot encoded vector with a <cite>1</cite> at the position corresponding to the tail entity’s index and <a href="#id1"><span class="problematic" id="id2">`</span></a>0`s elsewhere.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idx</strong> (<em>int</em>) – The index of the triple to retrieve.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing two elements:
- The input data as a torch.Tensor of shape (2,), containing the indices of the head entity and relation.
- The target vector as a torch.Tensor of shape (<cite>target_dim</cite>,), a one-hot encoded vector for the tail entity.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.dataset_classes.KvsAll">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.dataset_classes.</span></span><span class="sig-name descname"><span class="pre">KvsAll</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entity_idxs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relation_idxs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">form</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">store</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_smoothing_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#KvsAll"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.KvsAll" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></p>
<p>Creates a dataset for K-vs-All training strategy, inheriting from torch.utils.data.Dataset.
This dataset is tailored for training scenarios where a model predicts all valid tail entities
given a head entity and relation pair or vice versa. The labels are multi-hot encoded to represent
the presence of multiple valid entities.</p>
<p>Let (D) denote a dataset for KvsAll training and be defined as (D := {(x, y)_i}_{i=1}^{N}), where:
(x: (h, r)) is a unique tuple of an entity (h in E) and a relation (r in R) that has been seen in the input graph.
(y) denotes a multi-label vector (in [0, 1]^{<a href="#id3"><span class="problematic" id="id4">|E|</span></a>}) is a binary label. For all (y_i = 1) s.t. ((h, r, E_i) in KG).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_set_idx</strong> (<em>numpy.ndarray</em>) – A numpy array of shape <cite>(n, 3)</cite> representing <cite>n</cite> triples, where each triple consists of
integer indices corresponding to a head entity, a relation, and a tail entity.</p></li>
<li><p><strong>entity_idxs</strong> (<em>dict</em>) – A dictionary mapping entity names (strings) to their unique integer identifiers.</p></li>
<li><p><strong>relation_idxs</strong> (<em>dict</em>) – A dictionary mapping relation names (strings) to their unique integer identifiers.</p></li>
<li><p><strong>form</strong> (<em>str</em>) – A string indicating the prediction form, either ‘RelationPrediction’ or ‘EntityPrediction’.</p></li>
<li><p><strong>store</strong> (<em>dict</em><em>, </em><em>optional</em>) – A precomputed dictionary storing the training data points. If provided, it should map
tuples of entity and relation indices to lists of entity indices. If <cite>None</cite>, the store
will be constructed from <cite>train_set_idx</cite>.</p></li>
<li><p><strong>label_smoothing_rate</strong> (<em>float</em><em>, </em><em>default=0.0</em>) – A float representing the rate of label smoothing to be applied. A value of 0 means no
label smoothing is applied.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.KvsAll.train_data">
<span class="sig-name descname"><span class="pre">train_data</span></span><a class="headerlink" href="#dicee.dataset_classes.KvsAll.train_data" title="Link to this definition"></a></dt>
<dd><p>Tensor containing the input features for the model, typically consisting of pairs of
entity and relation indices.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.LongTensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.KvsAll.train_target">
<span class="sig-name descname"><span class="pre">train_target</span></span><a class="headerlink" href="#dicee.dataset_classes.KvsAll.train_target" title="Link to this definition"></a></dt>
<dd><p>Tensor containing the target labels for the model, multi-hot encoded to indicate the
presence of multiple valid entities.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.LongTensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.KvsAll.target_dim">
<span class="sig-name descname"><span class="pre">target_dim</span></span><a class="headerlink" href="#dicee.dataset_classes.KvsAll.target_dim" title="Link to this definition"></a></dt>
<dd><p>The dimensionality of the target labels, corresponding to the number of unique entities
or relations, depending on the <cite>form</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.KvsAll.collate_fn">
<span class="sig-name descname"><span class="pre">collate_fn</span></span><a class="headerlink" href="#dicee.dataset_classes.KvsAll.collate_fn" title="Link to this definition"></a></dt>
<dd><p>Placeholder for a custom collate function to be used with a PyTorch DataLoader. This is
typically set to <cite>None</cite> and can be overridden as needed.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The K-vs-All training strategy is used in scenarios where the task is to predict multiple
valid entities given a single entity and relation pair. This dataset supports both predicting
multiple valid tail entities given a head entity and relation (EntityPrediction) and predicting
multiple valid relations given a pair of entities (RelationPrediction).</p>
<p>The label smoothing rate can be adjusted to control the degree of smoothing applied to the
target labels, which can help with regularization and model generalization.</p>
</div>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.KvsAll.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#KvsAll.__len__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.KvsAll.__len__" title="Link to this definition"></a></dt>
<dd><p>Returns the number of items in the dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The total number of items.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.KvsAll.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#KvsAll.__getitem__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.KvsAll.__getitem__" title="Link to this definition"></a></dt>
<dd><p>Retrieves the input pair (head entity, relation) and the corresponding multi-label target vector for the
item at index <cite>idx</cite>.</p>
<p>The target vector is a binary vector of length <cite>target_dim</cite>, where each element indicates the presence or
absence of a tail entity for the given input pair.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idx</strong> (<em>int</em>) – The index of the item to retrieve.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A tuple containing two elements:
- The input pair as a torch.Tensor of shape (2,), containing the indices of the head entity and relation.
- The multi-label target vector as a torch.Tensor of shape (<cite>target_dim</cite>,), indicating the presence or</p>
<blockquote>
<div><p>absence of each possible tail entity.</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.dataset_classes.AllvsAll">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.dataset_classes.</span></span><span class="sig-name descname"><span class="pre">AllvsAll</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">entity_idxs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">relation_idxs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_smoothing_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#AllvsAll"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.AllvsAll" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></p>
<blockquote>
<div><p>A dataset class for the All-versus-All (AllvsAll) training strategy suitable for knowledge graph embedding models.
This strategy considers all possible pairs of entities and relations, regardless of whether they exist in the
knowledge graph, to predict the associated tail entities.</p>
<p>Let D denote a dataset for AllvsAll training and be defined as D:= {(x,y)_i}_i ^N, where
x: (h,r) is a possible unique tuple of an entity h in E and a relation r in R. Hence N = <a href="#id5"><span class="problematic" id="id6">|E|</span></a> x <a href="#id7"><span class="problematic" id="id8">|R|</span></a>
y: denotes a multi-label vector in [0,1]^{<a href="#id9"><span class="problematic" id="id10">|E|</span></a>} is a binary label.</p>
</div></blockquote>
<dl>
<dt>orall y_i =1 s.t. (h, r, E_i) in KG.</dt><dd><p>This setup extends beyond observed triples to include all possible combinations of entities and relations,
marking non-existent combinations as negatives. It aims to enrich the training data with hard negatives.</p>
<dl class="simple">
<dt>train_set_idx<span class="classifier">numpy.ndarray</span></dt><dd><p>An array of shape <cite>(n, 3)</cite>, where each row represents a triple (head entity index, relation index,
tail entity index).</p>
</dd>
<dt>entity_idxs<span class="classifier">dict</span></dt><dd><p>A dictionary mapping entity names to their unique integer indices.</p>
</dd>
<dt>relation_idxs<span class="classifier">dict</span></dt><dd><p>A dictionary mapping relation names to their unique integer indices.</p>
</dd>
<dt>label_smoothing_rate<span class="classifier">float, default=0.0</span></dt><dd><p>A parameter for label smoothing to mitigate overfitting by softening the hard labels.</p>
</dd>
</dl>
<dl class="simple">
<dt>train_data<span class="classifier">torch.LongTensor</span></dt><dd><p>A tensor containing all possible pairs of entities and relations derived from the input triples.</p>
</dd>
<dt>train_target<span class="classifier">Union[np.ndarray, list]</span></dt><dd><p>A target structure (either a Numpy array or a list) indicating the existence of a tail entity for
each head entity and relation pair. It supports multi-label classification where a pair can have
multiple correct tail entities.</p>
</dd>
<dt>target_dim<span class="classifier">int</span></dt><dd><p>The dimension of the target vector, equal to the total number of unique entities.</p>
</dd>
<dt>collate_fn<span class="classifier">None or callable</span></dt><dd><p>An optional function to merge a list of samples into a batch for loading. If not provided, the default
collate function of PyTorch’s DataLoader will be used.</p>
</dd>
</dl>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.AllvsAll.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#AllvsAll.__len__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.AllvsAll.__len__" title="Link to this definition"></a></dt>
<dd><p>Returns the number of items in the dataset, including both existing and potential triples.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The total number of items.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.AllvsAll.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#AllvsAll.__getitem__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.AllvsAll.__getitem__" title="Link to this definition"></a></dt>
<dd><p>Retrieves the input pair (head entity, relation) and the corresponding multi-label target vector for the
item at index <cite>idx</cite>. The target vector is a binary vector of length <cite>target_dim</cite>, where each element indicates
the presence or absence of a tail entity for the given input pair, including negative samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idx</strong> (<em>int</em>) – The index of the item to retrieve.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A tuple containing two elements:
- The input pair as a torch.Tensor of shape (2,), containing the indices of the head entity and relation.
- The multi-label target vector as a torch.Tensor of shape (<cite>target_dim</cite>,), indicating the presence or</p>
<blockquote>
<div><p>absence of each possible tail entity, including negative samples.</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.dataset_classes.KvsSampleDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.dataset_classes.</span></span><span class="sig-name descname"><span class="pre">KvsSampleDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_entities</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_relations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_sample_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_smoothing_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#KvsSampleDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.KvsSampleDataset" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></p>
<p>Constructs a dataset for KvsSample training strategy, specifically designed for knowledge graph embedding models.
This dataset formulation is aimed at handling the imbalance between positive and negative examples for each
(head, relation) pair by subsampling tail entities. The subsampling ensures a balanced representation of positive
and negative examples in each training batch, according to the specified negative sampling ratio.</p>
<dl class="simple">
<dt>The dataset is defined as (D:= {(x,y)_i}_{i=1}^{N}), where:</dt><dd><ul class="simple">
<li><p>(x: (h,r)) is a unique head entity (h in E) and a relation (r in R).</p></li>
<li><p>(y in [0,1]^{<a href="#id11"><span class="problematic" id="id12">|E|</span></a>}) is a binary label vector. For all (y_i = 1) such that ((h, r, E_i) in KG).</p></li>
</ul>
</dd>
</dl>
<p>At each mini-batch construction, we subsample (y), hence (<a href="#id13"><span class="problematic" id="id14">|new_y|</span></a> ll <a href="#id15"><span class="problematic" id="id16">|E|</span></a>).
The new (y) contains all 1’s if (sum(y) &lt;) neg_sample_ratio, otherwise, it contains a balanced mix of 1’s and 0’s.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_set</strong> (<em>np.ndarray</em>) – An array of shape ((n, 3)), where (n) is the number of triples in the dataset. Each row in the array
represents a triple ((h, r, t)), consisting of head entity index (h), relation index (r), and
tail entity index (t).</p></li>
<li><p><strong>num_entities</strong> (<em>int</em>) – The total number of unique entities in the dataset.</p></li>
<li><p><strong>num_relations</strong> (<em>int</em>) – The total number of unique relations in the dataset.</p></li>
<li><p><strong>neg_sample_ratio</strong> (<em>int</em>) – The ratio of negative samples to positive samples for each (head, relation) pair. If the number of
available positive samples is less than this ratio, additional negative samples are generated to meet the ratio.</p></li>
<li><p><strong>label_smoothing_rate</strong> (<em>float</em><em>, </em><em>default=0.0</em>) – A parameter for label smoothing, aiming to mitigate overfitting by softening the hard labels. The labels
are adjusted towards a uniform distribution, with the smoothing rate determining the degree of softening.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.KvsSampleDataset.train_data">
<span class="sig-name descname"><span class="pre">train_data</span></span><a class="headerlink" href="#dicee.dataset_classes.KvsSampleDataset.train_data" title="Link to this definition"></a></dt>
<dd><p>A tensor containing the (head, relation) pairs derived from the input triples, used to index the training set.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.IntTensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.KvsSampleDataset.train_target">
<span class="sig-name descname"><span class="pre">train_target</span></span><a class="headerlink" href="#dicee.dataset_classes.KvsSampleDataset.train_target" title="Link to this definition"></a></dt>
<dd><p>A list where each element corresponds to the tail entity indices associated with a given (head, relation) pair.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of numpy.ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.KvsSampleDataset.collate_fn">
<span class="sig-name descname"><span class="pre">collate_fn</span></span><a class="headerlink" href="#dicee.dataset_classes.KvsSampleDataset.collate_fn" title="Link to this definition"></a></dt>
<dd><p>A function to merge a list of samples to form a batch. If None, PyTorch’s default collate function is used.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>None or callable</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.KvsSampleDataset.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#KvsSampleDataset.__len__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.KvsSampleDataset.__len__" title="Link to this definition"></a></dt>
<dd><p>Returns the total number of unique (head, relation) pairs in the dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The number of unique (head, relation) pairs.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.KvsSampleDataset.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#KvsSampleDataset.__getitem__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.KvsSampleDataset.__getitem__" title="Link to this definition"></a></dt>
<dd><p>Retrieves the data for the given index, including the (head, relation) pair, selected tail entity indices,
and their labels. Positive examples are sampled from the training set, and negative examples are generated
by randomly selecting tail entities not associated with the (head, relation) pair.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idx</strong> (<em>int</em>) – The index of the (head, relation) pair in the dataset.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><p>A tuple containing the following elements:
- x: The (head, relation) pair as a torch.Tensor.
- y_idx: The indices of selected tail entities, both positive and negative, as a torch.IntTensor.
- y_vec: The labels for the selected tail entities, with 1s indicating positive and 0s indicating negative</p>
<blockquote>
<div><p>examples, as a torch.Tensor.</p>
</div></blockquote>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.dataset_classes.NegSampleDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.dataset_classes.</span></span><span class="sig-name descname"><span class="pre">NegSampleDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_entities</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_relations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_sample_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#NegSampleDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.NegSampleDataset" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></p>
<p>A dataset for training knowledge graph embedding models using negative sampling.
For each positive triple from the knowledge graph, a negative triple is generated by corrupting either
the head or the tail entity with a randomly selected entity.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_set</strong> (<em>np.ndarray</em>) – The training set of triples, where each triple consists of indices of the head entity, relation, and tail entity.</p></li>
<li><p><strong>num_entities</strong> (<em>int</em>) – The total number of unique entities in the knowledge graph.</p></li>
<li><p><strong>num_relations</strong> (<em>int</em>) – The total number of unique relations in the knowledge graph.</p></li>
<li><p><strong>neg_sample_ratio</strong> (<em>int</em><em>, </em><em>default=1</em>) – The ratio of negative samples to positive samples. Currently, it generates one negative sample per positive sample.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.NegSampleDataset.train_set">
<span class="sig-name descname"><span class="pre">train_set</span></span><a class="headerlink" href="#dicee.dataset_classes.NegSampleDataset.train_set" title="Link to this definition"></a></dt>
<dd><p>The training set converted to a PyTorch tensor and expanded to include a batch dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.NegSampleDataset.length">
<span class="sig-name descname"><span class="pre">length</span></span><a class="headerlink" href="#dicee.dataset_classes.NegSampleDataset.length" title="Link to this definition"></a></dt>
<dd><p>The total number of triples in the training set.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.NegSampleDataset.num_entities">
<span class="sig-name descname"><span class="pre">num_entities</span></span><a class="headerlink" href="#dicee.dataset_classes.NegSampleDataset.num_entities" title="Link to this definition"></a></dt>
<dd><p>A tensor containing the total number of entities.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.NegSampleDataset.num_relations">
<span class="sig-name descname"><span class="pre">num_relations</span></span><a class="headerlink" href="#dicee.dataset_classes.NegSampleDataset.num_relations" title="Link to this definition"></a></dt>
<dd><p>A tensor containing the total number of relations.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="dicee.dataset_classes.NegSampleDataset.neg_sample_ratio">
<span class="sig-name descname"><span class="pre">neg_sample_ratio</span></span><a class="headerlink" href="#dicee.dataset_classes.NegSampleDataset.neg_sample_ratio" title="Link to this definition"></a></dt>
<dd><p>A tensor containing the ratio of negative to positive samples.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.NegSampleDataset.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#NegSampleDataset.__len__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.NegSampleDataset.__len__" title="Link to this definition"></a></dt>
<dd><p>Returns the total number of triples in the dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The total number of triples.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.NegSampleDataset.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#NegSampleDataset.__getitem__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.NegSampleDataset.__getitem__" title="Link to this definition"></a></dt>
<dd><p>Retrieves a pair consisting of a positive triple and a generated negative triple along with their labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idx</strong> (<em>int</em>) – The index of the triple to retrieve.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple where the first element is a tensor containing a pair of positive and negative triples,
and the second element is a tensor containing their respective labels (1 for positive, 0 for negative).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.dataset_classes.TriplePredictionDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.dataset_classes.</span></span><span class="sig-name descname"><span class="pre">TriplePredictionDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_entities</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_relations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_sample_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_smoothing_rate</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#TriplePredictionDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.TriplePredictionDataset" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code></p>
<blockquote>
<div><p>A dataset for triple prediction using negative sampling and label smoothing.</p>
<p>D:= {(x)_i}_i ^N, where
- x:(h,r, t) in KG is a unique h in E and a relation r in R and
- collact_fn =&gt; Generates negative triples</p>
<p>collect_fn:</p>
</div></blockquote>
<p>orall (h,r,t) in G obtain, create negative triples{(h,r,x),(,r,t),(h,m,t)}</p>
<blockquote>
<div><p>y: labels are represented in torch.float16</p>
<p>This dataset generates negative triples by corrupting either the head or the tail of each positive triple
from the training set. The corruption is performed by randomly replacing the head or the tail with another entity
from the entity set. The dataset supports label smoothing to soften the target labels, which can help improve
generalization.</p>
<dl class="simple">
<dt>train_set<span class="classifier">np.ndarray</span></dt><dd><p>The training set consisting of triples in the form of (head, relation, tail) indices.</p>
</dd>
<dt>num_entities<span class="classifier">int</span></dt><dd><p>The total number of unique entities in the knowledge graph.</p>
</dd>
<dt>num_relations<span class="classifier">int</span></dt><dd><p>The total number of unique relations in the knowledge graph.</p>
</dd>
<dt>neg_sample_ratio<span class="classifier">int, optional</span></dt><dd><p>The ratio of negative samples to generate for each positive sample. Default is 1.</p>
</dd>
<dt>label_smoothing_rate<span class="classifier">float, optional</span></dt><dd><p>The rate of label smoothing to apply to the target labels. Default is 0.0.</p>
</dd>
</dl>
<p>The <cite>collate_fn</cite> should be passed to the DataLoader’s <cite>collate_fn</cite> argument to ensure proper
batch processing and negative sample generation.</p>
</div></blockquote>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.TriplePredictionDataset.__len__">
<span class="sig-name descname"><span class="pre">__len__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#TriplePredictionDataset.__len__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.TriplePredictionDataset.__len__" title="Link to this definition"></a></dt>
<dd><p>Returns the total number of triples in the dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The total number of triples.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.TriplePredictionDataset.__getitem__">
<span class="sig-name descname"><span class="pre">__getitem__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#TriplePredictionDataset.__getitem__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.TriplePredictionDataset.__getitem__" title="Link to this definition"></a></dt>
<dd><p>Retrieves a triple for the given index.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>idx</strong> (<em>int</em>) – The index of the triple to retrieve.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The triple at the specified index.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.TriplePredictionDataset.collate_fn">
<span class="sig-name descname"><span class="pre">collate_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#TriplePredictionDataset.collate_fn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.TriplePredictionDataset.collate_fn" title="Link to this definition"></a></dt>
<dd><p>Custom collate function to generate a batch of positive and negative triples along with their labels.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>batch</strong> (<em>List</em><em>[</em><em>torch.Tensor</em><em>]</em>) – A list of tensors representing triples.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple containing a tensor of triples and a tensor of corresponding labels.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Tuple[torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="dicee.dataset_classes.CVDataModule">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">dicee.dataset_classes.</span></span><span class="sig-name descname"><span class="pre">CVDataModule</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_set_idx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">numpy.ndarray</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_entities</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_relations</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg_sample_ratio</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_workers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#CVDataModule"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.CVDataModule" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">pytorch_lightning.LightningDataModule</span></code></p>
<p>A LightningDataModule for setting up data loaders for cross-validation training of knowledge graph embedding models.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_set_idx</strong> (<em>np.ndarray</em>) – An array of indexed triples for training, where each triple consists of indices of the head entity, relation,
and tail entity.</p></li>
<li><p><strong>num_entities</strong> (<em>int</em>) – The total number of unique entities in the knowledge graph.</p></li>
<li><p><strong>num_relations</strong> (<em>int</em>) – The total number of unique relations in the knowledge graph.</p></li>
<li><p><strong>neg_sample_ratio</strong> (<em>int</em>) – The ratio of negative samples to positive samples for each positive triple.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – The number of samples in each batch of data.</p></li>
<li><p><strong>num_workers</strong> (<em>int</em>) – The number of subprocesses to use for data loading. <a class="reference external" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader</a></p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A PyTorch DataLoader for the training dataset.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>DataLoader</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.CVDataModule.train_dataloader">
<span class="sig-name descname"><span class="pre">train_dataloader</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.utils.data.DataLoader</span></span></span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#CVDataModule.train_dataloader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.CVDataModule.train_dataloader" title="Link to this definition"></a></dt>
<dd><p>Creates a DataLoader for the training dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>A DataLoader object that loads the training data.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>DataLoader</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.CVDataModule.setup">
<span class="sig-name descname"><span class="pre">setup</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#CVDataModule.setup"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.CVDataModule.setup" title="Link to this definition"></a></dt>
<dd><p>Called at the beginning of fit (train + validate), validate, test, or predict. This is a good hook when you
need to build models dynamically or adjust something about them. This hook is called on every process when
using DDP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>stage</strong> – either <code class="docutils literal notranslate"><span class="pre">'fit'</span></code>, <code class="docutils literal notranslate"><span class="pre">'validate'</span></code>, <code class="docutils literal notranslate"><span class="pre">'test'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'predict'</span></code></p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LitModel</span><span class="p">(</span><span class="o">...</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">download_data</span><span class="p">()</span>
        <span class="n">tokenize</span><span class="p">()</span>

        <span class="c1"># don&#39;t do this</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">something</span> <span class="o">=</span> <span class="k">else</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">num_classes</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.CVDataModule.transfer_batch_to_device">
<span class="sig-name descname"><span class="pre">transfer_batch_to_device</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#CVDataModule.transfer_batch_to_device"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.CVDataModule.transfer_batch_to_device" title="Link to this definition"></a></dt>
<dd><p>Override this hook if your <code class="xref py py-class docutils literal notranslate"><span class="pre">DataLoader</span></code> returns tensors wrapped in a custom data
structure.</p>
<p>The data types listed below (and any arbitrary nesting of them) are supported out of the box:</p>
<ul class="simple">
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.Tensor</span></code> or anything that implements <cite>.to(…)</cite></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">dict</span></code></p></li>
<li><p><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></p></li>
</ul>
<p>For anything else, you need to define how the data is moved to the target device (CPU, GPU, TPU, …).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This hook should only transfer the data and not modify it, nor should it move the data to
any other device than the one passed in as argument (unless you know what you are doing).
To check the current state of execution of this hook you can use
<code class="docutils literal notranslate"><span class="pre">self.trainer.training/testing/validating/predicting</span></code> so that you can
add different logic as per your requirement.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>batch</strong> – A batch of data that needs to be transferred to a new device.</p></li>
<li><p><strong>device</strong> – The target device as defined in PyTorch.</p></li>
<li><p><strong>dataloader_idx</strong> – The index of the dataloader to which the batch belongs.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A reference to the data on the new device.</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">transfer_batch_to_device</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">CustomBatch</span><span class="p">):</span>
        <span class="c1"># move all tensors in your custom data structure to the device</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">samples</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">samples</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">batch</span><span class="o">.</span><span class="n">targets</span> <span class="o">=</span> <span class="n">batch</span><span class="o">.</span><span class="n">targets</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">dataloader_idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># skip device transfer for the first dataloader or anything you wish</span>
        <span class="k">pass</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">transfer_batch_to_device</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">dataloader_idx</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">batch</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Raises<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>MisconfigurationException</strong> – If using IPUs, <code class="docutils literal notranslate"><span class="pre">Trainer(accelerator='ipu')</span></code>.</p>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<ul class="simple">
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">move_data_to_device()</span></code></p></li>
<li><p><code class="xref py py-meth docutils literal notranslate"><span class="pre">apply_to_collection()</span></code></p></li>
</ul>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="dicee.dataset_classes.CVDataModule.prepare_data">
<span class="sig-name descname"><span class="pre">prepare_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/dicee/dataset_classes.html#CVDataModule.prepare_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#dicee.dataset_classes.CVDataModule.prepare_data" title="Link to this definition"></a></dt>
<dd><p>Use this to download and prepare data. Downloading and saving data with multiple processes (distributed
settings) will result in corrupted data. Lightning ensures this method is called only within a single process,
so you can safely add your downloading logic within.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>DO NOT set state to the model (use <code class="docutils literal notranslate"><span class="pre">setup</span></code> instead)
since this is NOT called on every device</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># good</span>
    <span class="n">download_data</span><span class="p">()</span>
    <span class="n">tokenize</span><span class="p">()</span>
    <span class="n">etc</span><span class="p">()</span>

    <span class="c1"># bad</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="n">data_split</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">some_state</span> <span class="o">=</span> <span class="n">some_other_state</span><span class="p">()</span>
</pre></div>
</div>
<p>In a distributed environment, <code class="docutils literal notranslate"><span class="pre">prepare_data</span></code> can be called in two ways
(using <span class="xref std std-ref">prepare_data_per_node</span>)</p>
<ol class="arabic simple">
<li><p>Once per node. This is the default and is only called on LOCAL_RANK=0.</p></li>
<li><p>Once in total. Only called on GLOBAL_RANK=0.</p></li>
</ol>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># DEFAULT</span>
<span class="c1"># called once per node on LOCAL_RANK=0 of that node</span>
<span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">True</span>


<span class="c1"># call on GLOBAL_RANK=0 (great for shared file systems)</span>
<span class="k">class</span> <span class="nc">LitDataModule</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prepare_data_per_node</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
<p>This is called before requesting the dataloaders:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">prepare_data</span><span class="p">()</span>
<span class="n">initialize_distributed</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">stage</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">val_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">test_dataloader</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict_dataloader</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../config/index.html" class="btn btn-neutral float-left" title="dicee.config" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../eval_static_funcs/index.html" class="btn btn-neutral float-right" title="dicee.eval_static_funcs" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Caglar Demir.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>